import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
import os
import requests
from bs4 import BeautifulSoup
import json
import re
import time
from urllib.parse import quote_plus
import plotly.express as px
import plotly.graph_objects as go
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as ReportLabImage, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.lib import colors as rl_colors
from reportlab.graphics.shapes import Drawing
from reportlab.graphics.charts.barcharts import VerticalBarChart
import traceback
import base64
from typing import Optional, List, Dict, Any

# Import data validation module
from data_validator import healthcare_validator
from iso_certification_scraper import get_iso_certifications
from international_quality_methods import (
    _calculate_international_quality_initiatives_score,
    _calculate_international_quality_metrics,
    _calculate_regional_adaptation_bonus,
    generate_international_improvement_recommendations
)
from international_scoring_algorithm import InternationalHealthcareScorer
from reportlab.graphics.charts.piecharts import Pie
from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image as PILImage
import io
import base64
warnings.filterwarnings('ignore')

# Fallback to avoid NameError after removing Quick Mode
qm = False

# Page configuration
st.set_page_config(
    page_title="Global Healthcare Quality Grid",
    page_icon="assets/QuXAT Logo Facebook.png",
    layout="wide",
    initial_sidebar_state="collapsed"
)

def compute_quality_grade(score: float):
    """Return (grade, grade_color, grade_desc) for the given score.
    Defined early so it‚Äôs available when the main scorecard renders.
    """
    try:
        s = float(score if score is not None else 0)
    except Exception:
        s = 0.0

    if s >= 75:
        grade = "A+"
        grade_color = "üü¢"
        grade_desc = "Outstanding quality; aligns with international benchmarks"
    elif s >= 65:
        grade = "A"
        grade_color = "üü¢"
        grade_desc = "High quality with strong accreditation portfolio"
    elif s >= 55:
        grade = "B+"
        grade_color = "üü°"
        grade_desc = "Solid quality; address identified gaps to improve"
    elif s >= 45:
        grade = "B"
        grade_color = "üü°"
        grade_desc = "Acceptable quality; needs targeted improvements"
    else:
        grade = "C"
        grade_color = "üî¥"
        grade_desc = "Needs attention; critical improvements required"

    return grade, grade_color, grade_desc

def compute_ranking_quality(score: float):
    """Return display styling and labels for ranking quality cards.
    Defined early to avoid NameError when the rankings section renders.
    Returns (color_hex, label_text, emoji, quality_level, description).
    """
    try:
        s = float(score if score is not None else 0)
    except Exception:
        s = 0.0

    if s >= 80:
        return ('#28a745', 'Exceptional (80-100)', 'üèÜ', 'Outstanding Quality', 'Outstanding healthcare quality with exceptional standards')
    elif s >= 70:
        return ('#20c997', 'Very Good (70-79)', '‚≠ê', 'High Quality', 'Excellent healthcare quality with high standards')
    elif s >= 60:
        return ('#ffc107', 'Good (60-69)', 'üëç', 'Good Quality', 'Good healthcare quality meeting standard requirements')
    elif s >= 50:
        return ('#fd7e14', 'Fair (50-59)', 'üëå', 'Fair Quality', 'Fair healthcare quality requiring some improvements')
    elif s >= 40:
        return ('#dc3545', 'Poor (40-49)', 'WARNINGÔ∏è', 'Scope for Improvement', 'Poor healthcare quality requiring significant improvements')
    else:
        return ('#6f42c1', 'Scope for Improvement (0-39)', '', 'Below International Quality Scoring Average - Needs Improvement', '')

# Dynamic logo function for consistent display across all pages
def display_dynamic_logo():
    """Display the Global Healthcare Quality Grid logo dynamically by loading from assets folder"""
    
    # Path to the PNG logo file
    logo_path = os.path.join("assets", "QuXAT Logo Facebook.png")
    
    try:
        # Check if logo file exists
        if os.path.exists(logo_path):
            # Load and display the PNG image
            logo_image = PILImage.open(logo_path)
            
            # Create a properly centered container with ultra-minimal spacing
            st.markdown("""
            <div style="
                display: flex; 
                justify-content: center; 
                align-items: center; 
                padding: 0; 
                margin: 0;
                border-bottom: 1px solid #e8e8e8;
                background: #ffffff;
                width: 100%;
                text-align: center;
            ">
            """, unsafe_allow_html=True)
            
            # Use perfectly centered columns for optimal alignment
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                # Display the image with perfect centering
                st.markdown(
                    f'<div style="display: flex; justify-content: center; align-items: center; width: 100%;">'
                    f'<img src="data:image/png;base64,{base64.b64encode(open(logo_path, "rb").read()).decode()}" '
                    f'style="width: 200px; height: auto; display: block; margin: 0 auto;" />'
                    f'</div>',
                    unsafe_allow_html=True
                )
            
            st.markdown("</div>", unsafe_allow_html=True)
        else:
            # Fallback if logo file doesn't exist
            st.markdown("""
            <div style="
                display: flex; 
                justify-content: center; 
                align-items: center; 
                padding: 0; 
                margin: 0;
                border-bottom: 1px solid #e8e8e8;
                background: #ffffff;
                text-align: center;
                width: 100%;
            ">
                <div style="
                    text-align: center; 
                    padding: 2px;
                    color: #2c3e50;
                    font-size: 24px;
                    font-weight: bold;
                    margin: 0 auto;
                ">
                    Global Healthcare Quality Grid
                </div>
            </div>
            """, unsafe_allow_html=True)
            
    except Exception as e:
        # Error fallback
        st.markdown(f"""
        <div style="
            display: flex; 
            justify-content: center; 
            align-items: center; 
            padding: 0; 
            margin: 0;
            border-bottom: 1px solid #e8e8e8;
            background: #ffffff;
            text-align: center;
            width: 100%;
        ">
            <div style="
                text-align: center; 
                padding: 2px;
                color: #e74c3c;
                font-size: 14px;
                margin: 0 auto;
            ">
                WARNINGÔ∏è Logo loading error: {str(e)}
            </div>
        </div>
        """, unsafe_allow_html=True)

# Admin Authentication System
def admin_login():
    """Admin login interface"""
    st.markdown("### üîê Admin Login")
    
    # Simple admin credentials (in production, use proper authentication)
    ADMIN_USERNAME = "admin"
    ADMIN_PASSWORD = "GHQA2024!"
    
    with st.form("admin_login_form"):
        username = st.text_input("Username")
        password = st.text_input("Password", type="password")
        login_button = st.form_submit_button("Login")
        
        if login_button:
            if username == ADMIN_USERNAME and password == ADMIN_PASSWORD:
                st.session_state.admin_authenticated = True
                st.session_state.admin_username = username
                st.success("‚úÖ Login successful!")
                st.rerun()
            else:
                st.error("‚ùå Invalid credentials")

def admin_logout():
    """Admin logout function"""
    if st.button("üö™ Logout"):
        st.session_state.admin_authenticated = False
        st.session_state.admin_username = None
        st.success("‚úÖ Logged out successfully!")
        st.rerun()

def is_admin_authenticated():
    """Check if admin is authenticated"""
    return st.session_state.get('admin_authenticated', False)

# Data Upload Management System
def init_upload_storage():
    """Initialize upload storage in session state"""
    if 'pending_uploads' not in st.session_state:
        st.session_state.pending_uploads = []
    if 'approved_uploads' not in st.session_state:
        st.session_state.approved_uploads = []
    if 'rejected_uploads' not in st.session_state:
        st.session_state.rejected_uploads = []

def add_pending_upload(upload_data):
    """Add new upload to pending queue"""
    init_upload_storage()
    upload_data['upload_id'] = len(st.session_state.pending_uploads) + 1
    upload_data['upload_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    upload_data['status'] = 'pending'
    st.session_state.pending_uploads.append(upload_data)

def approve_upload(upload_id):
    """Approve a pending upload"""
    init_upload_storage()
    for i, upload in enumerate(st.session_state.pending_uploads):
        if upload['upload_id'] == upload_id:
            upload['status'] = 'approved'
            upload['approved_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            st.session_state.approved_uploads.append(upload)
            st.session_state.pending_uploads.pop(i)
            break

def reject_upload(upload_id, reason=""):
    """Reject a pending upload"""
    init_upload_storage()
    for i, upload in enumerate(st.session_state.pending_uploads):
        if upload['upload_id'] == upload_id:
            upload['status'] = 'rejected'
            upload['rejected_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            upload['rejection_reason'] = reason
            st.session_state.rejected_uploads.append(upload)
            st.session_state.pending_uploads.pop(i)
            break

# Hospital Management System
def init_hospital_storage():
    """Initialize hospital storage in session state"""
    if 'custom_hospitals' not in st.session_state:
        st.session_state.custom_hospitals = []

def add_hospital(hospital_data):
    """Add new hospital to the database"""
    init_hospital_storage()
    hospital_data['hospital_id'] = len(st.session_state.custom_hospitals) + 1
    hospital_data['added_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    st.session_state.custom_hospitals.append(hospital_data)

def delete_hospital(hospital_id):
    """Delete hospital from the database"""
    init_hospital_storage()
    st.session_state.custom_hospitals = [h for h in st.session_state.custom_hospitals if h['hospital_id'] != hospital_id]

def update_hospital(hospital_id, updated_data):
    """Update hospital information"""
    init_hospital_storage()
    for i, hospital in enumerate(st.session_state.custom_hospitals):
        if hospital['hospital_id'] == hospital_id:
            st.session_state.custom_hospitals[i].update(updated_data)
            st.session_state.custom_hospitals[i]['updated_date'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            break

# Healthcare Organization Data Integration System
class HealthcareOrgAnalyzer:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # Load unified healthcare database
        self.unified_database = self.load_unified_database()
        
        # Load precomputed scored rankings (unique ranks with tie-breaking)
        self.scored_index = {}
        self.scored_entries = []
        try:
            # Resolve path robustly: try CWD first, then script directory
            scored_path = 'scored_organizations_complete.json'
            try:
                base_dir = os.path.dirname(__file__)
            except Exception:
                base_dir = os.getcwd()
            candidates = [scored_path, os.path.join(base_dir, scored_path)]
            open_path = None
            for p in candidates:
                if os.path.exists(p):
                    open_path = p
                    break
            if open_path is None:
                # Fall through to except to initialize empty structures
                raise FileNotFoundError('scored_organizations_complete.json not found')
            with open(open_path, 'r', encoding='utf-8') as f:
                scored = json.load(f)
            self.scored_entries = [e for e in scored if isinstance(e, dict)]
            for entry in self.scored_entries:
                name = entry.get('name') or entry.get('organization_name')
                if not name:
                    continue
                # Use the same normalization as lookup to ensure consistent keys
                key = self._normalize_name(name)
                if key in self.scored_index:
                    existing = self.scored_index[key]
                    if entry.get('total_score', 0) > existing.get('total_score', 0):
                        self.scored_index[key] = entry
                else:
                    self.scored_index[key] = entry
        except Exception:
            # Fallback gracefully if precomputed file is missing or invalid
            self.scored_index = {}
            self.scored_entries = []
        
        # Bind international quality methods to this class
        self.calculate_international_quality_initiatives = _calculate_international_quality_initiatives_score.__get__(self, HealthcareOrgAnalyzer)
        self.calculate_international_quality_metrics = _calculate_international_quality_metrics.__get__(self, HealthcareOrgAnalyzer)
        self.calculate_regional_adaptation_bonus = _calculate_regional_adaptation_bonus.__get__(self, HealthcareOrgAnalyzer)
        self.generate_international_improvement_recommendations = generate_international_improvement_recommendations.__get__(self, HealthcareOrgAnalyzer)
        # Initialize international scorer
        self.international_scorer = InternationalHealthcareScorer()

    def _normalize_name(self, name: str) -> str:
        """Normalize organization name for consistent scored index lookup."""
        if not name:
            return ''
        n = str(name).lower().strip()
        n = re.sub(r"[\-_,.&'\"]", " ", n)
        n = re.sub(r"\s+", " ", n).strip()
        return n

    def _country_to_region_type(self, country: str) -> str:
        """Map country to a simple region type for context adjustments"""
        developed = {
            'UNITED STATES', 'USA', 'CANADA', 'UNITED KINGDOM', 'UK', 'GERMANY', 'FRANCE',
            'JAPAN', 'AUSTRALIA', 'NEW ZEALAND', 'SINGAPORE', 'SWEDEN', 'NORWAY', 'DENMARK',
            'NETHERLANDS', 'SWITZERLAND'
        }
        if not country:
            return 'developed'
        c = str(country).strip().upper()
        return 'developed' if c in developed else 'developing'

    def _country_to_region(self, country: str) -> str:
        """Map country to broad region name"""
        if not country:
            return 'Global'
        c = str(country).strip().upper()
        if c in {'UNITED STATES', 'USA', 'CANADA'}:
            return 'North America'
        if c in {'UNITED KINGDOM', 'UK', 'GERMANY', 'FRANCE', 'NETHERLANDS', 'SWITZERLAND', 'SWEDEN', 'NORWAY', 'DENMARK'}:
            return 'Europe'
        if c in {'JAPAN', 'SINGAPORE', 'AUSTRALIA', 'NEW ZEALAND', 'INDIA'}:
            return 'Asia-Pacific'
        if c in {'SAUDI ARABIA', 'UAE', 'UNITED ARAB EMIRATES'}:
            return 'Middle East'
        return 'Global'

    def get_official_site_details(self, org_name: str) -> dict:
        """Fetch website, address, phone, and email from the organization's official site.

        This method looks up the organization in the unified database to find a website URL,
        then fetches the homepage and, if available, a contact page to extract contact details.

        Returns a dict with keys: website, address, phone, email. Missing fields are None.
        """
        details = {"website": None, "address": None, "phone": None, "email": None}
        try:
            if not org_name:
                return details

            # Locate org record and website field (STRICT match only)
            org_record = None
            org_lower = org_name.lower().strip()
            for org in (self.unified_database or []):
                if not isinstance(org, dict):
                    continue
                name = org.get("name", "").lower().strip()
                if org_lower == name:
                    org_record = org
                    break

            website = None
            if org_record:
                website = (
                    org_record.get("website")
                    or org_record.get("web")
                    or org_record.get("url")
                    or org_record.get("official_website")
                )

            # If no website, return early
            if not website or not isinstance(website, str):
                return details

            details["website"] = website.strip()

            urls_to_try = [details["website"]]
            # Attempt common contact page patterns
            if details["website"].endswith("/"):
                base = details["website"][:-1]
            else:
                base = details["website"]
            for suffix in ("/contact", "/contact-us", "/contactus", "/about", "/about-us"):
                urls_to_try.append(base + suffix)

            html_text = ""
            for u in urls_to_try:
                try:
                    resp = self.session.get(u, timeout=8)
                    if resp.status_code == 200 and resp.text:
                        html_text = resp.text
                        break
                except Exception:
                    continue

            if not html_text:
                return details

            # Parse HTML for address, phone, email
            soup = BeautifulSoup(html_text, "html.parser")
            page_text = soup.get_text(" ", strip=True)

            # Email
            email_match = re.search(r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}", page_text)
            if email_match:
                details["email"] = email_match.group(0)

            # Phone: match international formats
            phone_match = re.search(r"\+?\d[\d\s\-()]{7,}\d", page_text)
            if phone_match:
                details["phone"] = phone_match.group(0).strip()

            # Address heuristics: prefer concise, structured patterns; avoid dumping raw JSON
            address = None
            # Try finding a line following an 'Address' label
            address_label = re.search(r"Address[:\s]+([^\n]+)", page_text, re.IGNORECASE)
            if address_label:
                address = address_label.group(1).strip()
            else:
                # Generic pattern: capture street + country + postal code
                addr_match = re.search(r"([A-Za-z0-9 .,'/\-]+\bSingapore\b[, ]+\d{6})", page_text, re.IGNORECASE)
                if addr_match:
                    address = addr_match.group(1).strip()

            if address:
                # Sanitize overly long or script-like content
                address = re.sub(r"\s+", " ", address)
                # Trim if too long
                if len(address) > 180:
                    # Keep up to last comma within limit
                    cut = address[:180]
                    comma_idx = cut.rfind(',')
                    address = (cut[:comma_idx] if comma_idx > 0 else cut).strip()
                # Remove obvious JSON fragments
                if '{' in address or '}' in address or '"' in address:
                    address = re.sub(r"[\{\}\"]", "", address).strip()

            if address:
                details["address"] = address

        except Exception:
            # Silent failure, return whatever we gathered
            pass

        return details
        
        # Enhanced certification databases and scoring weights
        # Comprehensive Global Healthcare Quality Certifications (Updated with 100+ standards)
        self.certification_weights = {
            # International Gold Standards (Top Tier - 25-35 points)
            'JCI': 35,  # Joint Commission International - Global gold standard
            'Joint Commission': 30,  # US Joint Commission - Highest US standard
        'Magnet': 32,  # Magnet Recognition - Nursing excellence gold standard (boosted)
            'DNV GL Healthcare': 25,  # International healthcare accreditation
            'WHO-FIC Collaborating Centre': 25,  # WHO standards
            
            # Major International Standards (Second Tier - 18-25 points)
            'HIMSS EMRAM Level 6-7': 25,  # Advanced health IT maturity
            'NCQA': 22,  # National Committee for Quality Assurance
            'AAAHC': 20,  # Ambulatory care accreditation
            'CARF': 20,  # Rehabilitation accreditation
            'CAP': 20,  # College of American Pathologists
            'CLIA': 18,  # Clinical Laboratory Improvement Amendments
            'RTAC': 18,  # Reproductive Technology Accreditation Committee
            
            # Regional Excellence Standards (Third Tier - 12-18 points)
            'NABH': 18,  # Indian hospital accreditation
            'NABL': 15,  # Indian laboratory accreditation
            'Accreditation Canada': 18,  # Canadian healthcare accreditation
            'TGA': 20,  # Australia Therapeutic Goods Administration
            'HSA': 18,  # Singapore Health Sciences Authority
            'PMDA': 22,  # Japan Pharmaceuticals and Medical Devices Agency
            'MHRA': 22,  # UK Medicines and Healthcare products Regulatory Agency
            'EMA': 25,  # European Medicines Agency
            'TFDA': 15,  # Taiwan Food and Drug Administration
            'KFDA': 15,  # South Korea Food and Drug Administration
            
            # ISO Standards (Fourth Tier - 8-15 points)
            'ISO 9001': 15, 'ISO 14001': 12, 'ISO 45001': 12, 'ISO 27001': 10,
            'ISO 15189': 20,  # Medical laboratory standard
            'ISO 13485': 18,  # Medical device quality
            'ISO 17025': 15,  # Testing and calibration laboratories
            'IEC 62304': 10,  # Medical device software
            
            # European Standards (12-22 points)
            'CE Marking': 20,  # Medical device compliance
            'NICE': 18,  # UK Health Technology Assessment
            'HAS': 15,  # France Health Technology Assessment
            'G-BA': 15,  # Germany Healthcare Quality Assessment
            'Swissmedic': 20,  # Switzerland drug regulation
            'ANSM': 15,  # France drug safety
            'BfArM': 20,  # Germany medical devices
            'AIFA': 15,  # Italy drug regulation
            'AEMPS': 15,  # Spain pharmaceutical regulation
            
            # North American Standards (10-25 points)
            'HIMSS EMRAM': 18,  # Health IT maturity
            'HFAP': 12,  # Healthcare Facilities Accreditation Program
            'CHAP': 10,  # Community Health Accreditation Partner
            'ACHC': 12,  # Accreditation Commission for Health Care
            'URAC': 15,  # Healthcare quality
            'CPSO': 15,  # College of Physicians and Surgeons Ontario
            'Health Canada GMP': 12,  # Good Manufacturing Practices
            
            # Asia-Pacific Standards (6-20 points)
            'QCI Healthcare': 12,  # India Quality Council
            'MHLW': 15,  # Japan Health & Welfare
            'Medsafe': 12,  # New Zealand medicine safety
            'NMPA': 15,  # China drug administration
            'DOH Philippines': 10,  # Philippines Department of Health
            'MOH Malaysia': 10,  # Malaysia Ministry of Health
            'FDA Thailand': 10,  # Thailand Food and Drug Administration
            'BPOM': 10,  # Indonesia drug control
            'SFDA': 12,  # Saudi Arabia Food and Drug Authority
            'NHRA': 8,   # Bahrain Health Regulation Authority
            'MOH UAE': 8, 'Kuwait MOH': 8, 'Oman MOH': 8, 'Qatar MOH': 8,
            
            # Middle East & Africa Standards (6-15 points)
            'SAHPRA': 15,  # South Africa health products regulation
            'MCC': 15,     # South Africa medicines control
            'NAFDAC': 10,  # Nigeria food and drug administration
            'FDB': 10,     # Ghana Food and Drugs Board
            'PPB': 8,      # Kenya Pharmacy and Poisons Board
            'Israeli MOH': 12, 'Turkish MOH': 10, 'Egyptian MOH': 10,
            'Moroccan MOH': 10, 'Tunisian MOH': 10, 'Jordanian MOH': 8,
            
            # Latin American Standards (6-15 points)
            'ANVISA': 15,    # Brazil health surveillance
            'ANMAT': 15,     # Argentina medicine administration
            'ISP': 15,       # Chile public health institute
            'INVIMA': 10,    # Colombia drug surveillance
            'DIGEMID': 10,   # Peru medicine directorate
            'COFEPRIS': 12,  # Mexico health risk protection
            'CECMED': 8,     # Cuba medicine control
            'DINAMED': 8,    # Uruguay medicine directorate
            'MSP Ecuador': 8, 'MINSA Panama': 8, 'MINSA Costa Rica': 8,
            
            # Specialized Certifications (Fifth Tier - 5-12 points)
            'AABB': 10,  # Blood bank accreditation
            'FACT': 12,  # Cellular therapy accreditation
            'JACIE': 12,  # European cellular therapy
            'OSHA VPP': 8,  # Occupational safety
            'Green Guide for Health Care': 6,  # Environmental sustainability
            'LEED Healthcare': 8,  # Green building certification
            'Energy Star': 6,  # Energy efficiency
        }
        
        # Hospital reputation and ranking multipliers (reduced for more realistic scoring)
        self.reputation_multipliers = {
            # US News & World Report Rankings (Reduced multipliers)
            'us_news_top_5': 1.10,    # 10% boost for top 5 hospitals (reduced from 25%)
            'us_news_top_10': 1.08,   # 8% boost for top 10 hospitals (reduced from 20%)
            'us_news_top_20': 1.05,   # 5% boost for top 20 hospitals (reduced from 15%)
            'us_news_honor_roll': 1.03, # 3% boost for Honor Roll hospitals (reduced from 10%)
            
            # International Recognition (Reduced multipliers)
            'newsweek_world_best': 1.08,  # Newsweek World's Best Hospitals (reduced from 20%)
            'forbes_global': 1.05,        # Forbes Global 2000 Healthcare (reduced from 15%)
            'academic_medical_center': 1.03, # Major teaching hospitals (reduced from 10%)
            'research_intensive': 1.02,   # High research output (reduced from 8%)
        }
        
        # Global hospital reputation database (simplified for demo)
        self.global_hospital_rankings = {
            # US Top Hospitals
            'mayo clinic': {'us_news_rank': 1, 'newsweek_rank': 1, 'academic': True, 'research_intensive': True},
            'cleveland clinic': {'us_news_rank': 2, 'newsweek_rank': 3, 'academic': True, 'research_intensive': True},
            'johns hopkins': {'us_news_rank': 3, 'newsweek_rank': 2, 'academic': True, 'research_intensive': True},
            'massachusetts general': {'us_news_rank': 4, 'newsweek_rank': 4, 'academic': True, 'research_intensive': True},
            'cedars-sinai': {'us_news_rank': 8, 'newsweek_rank': 12, 'academic': True, 'research_intensive': True},
            
            # International Top Hospitals
            'singapore general hospital': {'newsweek_rank': 15, 'academic': True, 'research_intensive': True},
            'toronto general hospital': {'newsweek_rank': 18, 'academic': True, 'research_intensive': True},
            'karolinska university hospital': {'newsweek_rank': 22, 'academic': True, 'research_intensive': True},
            
            # Indian Hospitals (Regional leaders but not global top tier)
            'apollo hospitals': {'regional_leader': True, 'academic': False, 'research_intensive': False},
            'fortis healthcare': {'regional_leader': True, 'academic': False, 'research_intensive': False},
            'yashoda hospitals': {'regional_leader': True, 'academic': False, 'research_intensive': False},
            'aiims delhi': {'academic': True, 'research_intensive': True, 'government': True},
        }
        
        # Quality initiative keywords and their impact scores
        self.quality_keywords = {
            'patient safety': 8, 'quality improvement': 6, 'accreditation': 10,
            'certification': 8, 'digital health': 5, 'telemedicine': 4,
            'infection control': 7, 'staff training': 5, 'research': 6,
            'innovation': 5, 'transparency': 4, 'community health': 5
        }
        
        # Load JCI accredited organizations data
        self.jci_organizations = self.load_jci_data()

    def load_jci_data(self):
        """Load JCI accredited organizations data from JSON file"""
        try:
            
            jci_file_path = 'jci_accredited_organizations.json'
            
            if os.path.exists(jci_file_path):
                with open(jci_file_path, 'r', encoding='utf-8') as f:
                    jci_data = json.load(f)
                
                # Create a lookup dictionary for faster searches
                jci_lookup = {}
                for org in jci_data:
                    org_name = org.get('name', '').lower().strip()
                    if org_name:
                        jci_lookup[org_name] = {
                            'name': org.get('name', ''),
                            'country': org.get('country', ''),
                            'type': org.get('type', ''),
                            'accreditation_date': org.get('accreditation_date', ''),
                            'region': org.get('region', ''),
                            'source': org.get('source', 'JCI Database'),
                            'jci_accredited': True
                        }
                
                # Removed JCI loading message for cleaner UI
                return jci_lookup
            else:
                st.warning("WARNINGÔ∏è JCI data file not found. Using default JCI certification weights.")
                return {}
                
        except Exception as e:
            st.error(f"Error loading JCI data: {str(e)}")
            return {}

    def check_jci_accreditation(self, org_name):
        """Check if an organization is JCI accredited"""
        if not self.jci_organizations:
            return None
            
        org_name_lower = org_name.lower().strip()
        
        # Direct match
        if org_name_lower in self.jci_organizations:
            return self.jci_organizations[org_name_lower]
        
        # Partial match - check if organization name contains JCI org name or vice versa
        for jci_org_name, jci_data in self.jci_organizations.items():
            if (jci_org_name in org_name_lower or 
                org_name_lower in jci_org_name or
                any(word in jci_org_name for word in org_name_lower.split() if len(word) > 3)):
                return jci_data
        
        return None

    def generate_organization_suggestions(self, partial_input, max_suggestions=10):
        """Generate autocomplete suggestions with aggressive de-duplication and smart ranking."""
        if not partial_input or len(partial_input) < 2:
            return []

        partial_lower = partial_input.lower().strip()

        def _norm_text(text: str) -> str:
            t = (text or '').lower().strip()
            t = re.sub(r"\s+", " ", t)
            # Normalize common company suffixes to reduce duplicates
            t = t.replace("private limited", "pvt. ltd.")
            t = t.replace("pvt ltd", "pvt. ltd.")
            # Normalize separators
            t = re.sub(r"\s*[-‚Äì‚Äî]\s*", " ", t)
            t = re.sub(r"\s*,\s*", ", ", t)
            return t

        def _strip_parentheses(text: str) -> str:
            # Remove descriptive parentheses (e.g., branches or unit notes)
            return re.sub(r"\([^)]*\)", "", text or "").strip()

        def _normalize_location(location: str) -> str:
            loc = _norm_text(location or '')
            # Drop country tokens
            tokens = [t for t in re.split(r"[,\-\s]+", loc) if t and t not in {"india"}]
            return " ".join(sorted(tokens))

        def _canonicalize_name(name: str, location: str) -> str:
            # Build a canonical version of the name for deduping
            n = _strip_parentheses(name or "")
            n = re.sub(r"\s+", " ", n).strip()
            loc = _norm_text(location or '')

            # Remove trailing tokens that are part of the location (order-agnostic)
            name_parts = [p for p in re.split(r"[,\-\s]+", _norm_text(n)) if p]
            loc_tokens = set([p for p in re.split(r"[,\-\s]+", loc) if p])
            while name_parts and (name_parts[-1] in loc_tokens or name_parts[-1] in {"india"}):
                name_parts.pop()

            n = " ".join(name_parts)
            # Clean up redundant commas/spaces
            n = re.sub(r"\s*,\s*", ", ", n)
            n = re.sub(r"\s+", " ", n).strip()
            return n

        def _dedupe_key(display_name: str, location: str) -> str:
            # Combine canonicalized name and normalized location for robust deduplication
            return f"{_norm_text(_canonicalize_name(display_name, location))}|{_normalize_location(location)}"

        candidates = []
        if self.unified_database:
            for org in self.unified_database:
                org_name = (org.get('name', '') or '').strip()
                if not org_name:
                    continue

                original_name = (org.get('original_name', '') or '').strip()
                name_lower = org_name.lower().strip()
                location = self._extract_location_from_org(org)

                match_type = None
                if name_lower.startswith(partial_lower):
                    match_type = 'name_start'
                elif partial_lower in name_lower:
                    match_type = 'name_contains'
                elif original_name and partial_lower in original_name.lower().strip():
                    match_type = 'original_name'

                if match_type:
                    candidates.append({
                        'display_name': org_name,
                        'full_name': original_name if original_name else org_name,
                        'location': location,
                        'type': org.get('type', 'Healthcare Organization'),
                        'match_type': match_type
                    })

        # Deduplicate by normalized name+location; prefer better matches and shorter names
        best_by_key = {}
        rank_map = {'name_start': 0, 'name_contains': 1, 'original_name': 2}

        for s in candidates:
            key = _dedupe_key(s['display_name'], s.get('location', ''))
            cur = best_by_key.get(key)
            if not cur:
                best_by_key[key] = s
                continue
            # Prefer stronger match_type, then shorter display_name
            cur_rank = rank_map.get(cur['match_type'], 99)
            new_rank = rank_map.get(s['match_type'], 99)
            if new_rank < cur_rank or (new_rank == cur_rank and len(s['display_name']) < len(cur['display_name'])):
                best_by_key[key] = s

        suggestions = list(best_by_key.values())
        suggestions.sort(key=lambda x: (
            rank_map.get(x['match_type'], 99),
            _norm_text(x['display_name'])
        ))

        return suggestions[:max_suggestions]

    def canonicalize_name(self, name: str, location: str) -> str:
        """Canonicalize organization name by stripping branch/location tokens.

        This mirrors the logic used in suggestion deduplication so UI display
        and database matching stay consistent.
        """
        n = (name or "").strip()
        # Remove descriptive parentheses
        n = re.sub(r"\([^)]*\)", "", n).strip()
        # Normalize whitespace and separators
        def _norm(text: str) -> str:
            t = (text or '').lower().strip()
            t = re.sub(r"\s+", " ", t)
            t = re.sub(r"\s*[-‚Äì‚Äî]\s*", " ", t)
            t = re.sub(r"\s*,\s*", ", ", t)
            return t
        loc = _norm(location or '')
        name_parts = [p for p in re.split(r"[,\-\s]+", _norm(n)) if p]
        loc_tokens = set([p for p in re.split(r"[,\-\s]+", loc) if p])
        # Drop country tokens as well
        loc_tokens.update({"india", "bharat"})
        while name_parts and name_parts[-1].lower() in loc_tokens:
            name_parts.pop()
        n = " ".join(name_parts)
        n = re.sub(r"\s*,\s*", ", ", n)
        n = re.sub(r"\s+", " ", n).strip()
        return n
    
    def _extract_location_from_org(self, org):
        """Extract location information from organization data"""
        def _sanitize_location(location_str: str) -> str:
            if not location_str:
                return 'Unknown Location'
            # Split on common separators and clean tokens
            raw_tokens = re.split(r"[,\-\|/]+|\s+-\s+", str(location_str))
            tokens = []
            seen = set()
            for tok in raw_tokens:
                t = tok.strip()
                if not t:
                    continue
                # Drop country and generic tokens
                t_low = t.lower()
                # Remove HTML-escaped artefacts like \u003cbr\u003e, \u003e, etc.
                if re.search(r"u003c|u003e", t_low):
                    continue
                if t_low in {"india", "bharat", "country", "unknown"}:
                    continue
                # De-duplicate while preserving order (case-insensitive)
                if t_low in seen:
                    continue
                seen.add(t_low)
                tokens.append(t)
            # Prefer the most specific end tokens: City, State
            if len(tokens) >= 2:
                return f"{tokens[-2]}, {tokens[-1]}"
            elif len(tokens) == 1:
                return tokens[0]
            return 'Unknown Location'

        # Try different location fields in order of reliability
        if org.get('city') and org.get('state'):
            return _sanitize_location(f"{org['city']}, {org['state']}")
        if org.get('location'):
            return _sanitize_location(org['location'])
        if org.get('address'):
            return _sanitize_location(org['address'])
        if org.get('original_name'):
            return _sanitize_location(org['original_name'])

        return _sanitize_location(org.get('country', 'Unknown Location'))
    
    def format_suggestion_display(self, suggestion):
        """Format suggestion for display in the UI with clean location."""
        # Support dict and string suggestion types
        if isinstance(suggestion, dict):
            display_name = suggestion.get('display_name', '')
            location = suggestion.get('location', '')
        elif isinstance(suggestion, str):
            display_name = suggestion
            location = ''
        else:
            display_name = str(suggestion) if suggestion is not None else ''
            location = ''

        # Use the same canonicalization used for de-duplication to avoid name+location repetition
        try:
            name_clean = self.canonicalize_name(display_name, location)
        except Exception:
            name_clean = display_name

        # Sanitize location presentation
        def _sanitize_location_for_display(loc: str) -> str:
            raw = loc or ''
            parts = [p.strip() for p in re.split(r"[,\-\|/]+|\s+-\s+", raw) if p.strip()]
            parts = [p for p in parts if p.lower() not in {"india", "bharat"}]
            if len(parts) >= 2:
                return f"{parts[-2]}, {parts[-1]}"
            elif parts:
                return parts[-1]
            return ''

        loc_clean = _sanitize_location_for_display(location)

        if loc_clean:
            return f"{name_clean} - {loc_clean}"
        return name_clean

    def enhance_certification_with_jci(self, certifications, org_name):
        """
        DEPRECATED: This method previously auto-assigned JCI certification.
        Now returns certifications as-is to prevent simulated results.
        Only validated certifications from official sources should be displayed.
        """
        # Return certifications without automatic JCI enhancement
        # JCI certification should only come from validated official sources
        return certifications
    
    def load_unified_database(self):
        # Return cached result if already loaded to avoid repeated IO and processing
        try:
            if hasattr(self, "_unified_db_cache") and isinstance(self._unified_db_cache, list) and self._unified_db_cache:
                return self._unified_db_cache
        except Exception:
            pass
        def _safe_load_list_or_dict(path):
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, dict) and 'organizations' in data:
                    return data['organizations']
                elif isinstance(data, list):
                    return data
                elif isinstance(data, dict):
                    # Single org object
                    return [data]
                else:
                    return []
            except FileNotFoundError:
                return []
            except Exception:
                # Attempt minimal recovery for loosely formatted JSON files (e.g., scraped content)
                try:
                    with open(path, 'r', encoding='utf-8') as f:
                        text = f.read()
                    # Simple heuristic extraction
                    name_match = re.search(r'"name"\s*:\s*"([^"]+)"', text)
                    website_match = re.search(r'"website"\s*:\s*"([^"]+)"', text)
                    address_match = re.search(r'"address"\s*:\s*"([^"]+)"', text)
                    if website_match or address_match:
                        recovered = {
                            'name': name_match.group(1) if name_match else '',
                            'website': website_match.group(1) if website_match else '',
                            'address': address_match.group(1) if address_match else ''
                        }
                        return [recovered]
                except Exception:
                    pass
                return []

        def _normalize_key(name: str, country: str) -> str:
            base = (name or '').lower().strip()
            base = re.sub(r'[^a-z0-9\s]', '', base)
            base = re.sub(r'\s+', ' ', base)
            return f"{base}|{(country or '').lower().strip()}"

        def _strip_parentheses(text: str) -> str:
            return re.sub(r"\([^)]*\)", "", text or "").strip()

        # Resolve file paths robustly across working dir and script dir
        def _resolve_path(path: str) -> str:
            try:
                base_dir = os.path.dirname(__file__)
            except Exception:
                base_dir = os.getcwd()
            candidates = [path, os.path.join(base_dir, path)]
            for c in candidates:
                if os.path.exists(c):
                    return c
            return path

        def canonicalize_org_name(name: str, city: str = '', state: str = '', country: str = '') -> str:
            """Canonical base name for deduping across branches and variants."""
            n = _strip_parentheses(name or '')
            n = re.sub(r"\s+", " ", n).strip()
            # Normalize company suffixes
            n = re.sub(r"\bprivate\s+limited\b", "pvt. ltd.", n, flags=re.IGNORECASE)
            n = re.sub(r"\bpvt\.?\s*ltd\b", "pvt. ltd.", n, flags=re.IGNORECASE)

            # Remove trailing location tokens if they match provided fields
            def _strip_tail(token: str, s: str) -> str:
                if not token:
                    return s
                tl = token.lower().strip()
                sl = s.lower()
                if sl.endswith(tl):
                    idx = sl.rfind(tl)
                    return s[:idx].rstrip(" ,-/")
                return s

            n = _strip_tail(country, n)
            n = _strip_tail(state, n)
            n = _strip_tail(city, n)
            # Common countries to strip even if not provided explicitly
            for c in ["india", "united states", "usa"]:
                n = _strip_tail(c, n)

            # Clean residual punctuation
            n = re.sub(r"\s*,\s*", ", ", n)
            return n.strip()

        try:
            merged: list = []
            # Primary source (preferred)
            primary = _safe_load_list_or_dict(_resolve_path('unified_healthcare_organizations_with_mayo_cap.json'))
            if not primary:
                # Fallback to legacy file
                primary = _safe_load_list_or_dict(_resolve_path('unified_healthcare_organizations.json'))
                if primary:
                    st.warning("WARNINGÔ∏è Using legacy unified database as fallback.")
            merged.extend(primary)

            # Optional global sources
            merged.extend(_safe_load_list_or_dict(_resolve_path('global_healthcare_organizations.json')))
            merged.extend(_safe_load_list_or_dict(_resolve_path('validation_discovered_organizations.json')))

            # External directory: external_organizations/*.json
            external_dir = _resolve_path('external_organizations')
            if os.path.isdir(external_dir):
                for fname in os.listdir(external_dir):
                    if not fname.lower().endswith('.json'):
                        continue
                    merged.extend(_safe_load_list_or_dict(os.path.join(external_dir, fname)))

            # Removed ad-hoc file injection to prevent cross-organization contamination
            # (tmc_details.json contained partial address-only data that could leak into other matches)

            # Deduplicate by canonical base name + country (for grouping)
            deduped = {}
            for org in merged:
                if not isinstance(org, dict):
                    continue
                name = org.get('name', '')
                key = canonicalize_org_name(name, org.get('city', ''), org.get('state', ''), org.get('country', '')).lower()
                # Prefer entries with richer data
                if key in deduped:
                    # Keep the one with more non-empty fields
                    existing = deduped[key]
                    existing_fields = sum(1 for k, v in existing.items() if v)
                    new_fields = sum(1 for k, v in org.items() if v)
                    if new_fields > existing_fields:
                        deduped[key] = org
                else:
                    deduped[key] = org

            final_list = list(deduped.values())
            if not final_list:
                st.warning("WARNINGÔ∏è Unified healthcare database not found or empty. Some search features may be limited.")
            # Cache and return
            try:
                self._unified_db_cache = final_list
            except Exception:
                pass
            return final_list
        except Exception as e:
            st.error(f"Error loading unified database: {str(e)}")
            return []

    def aggregate_unified_records(self, org_name: str) -> Optional[dict]:
        """Aggregate all unified database records that represent the same base organization."""
        if not self.unified_database:
            return None
        input_name = org_name or ''
        canon_input = re.sub(r"\s+", " ", input_name).strip().lower()

        def canonicalize(name: str, city: str = '', state: str = '', country: str = '') -> str:
            # Mirror loader canonicalization
            n = re.sub(r"\([^)]*\)", "", (name or '')).strip()
            n = re.sub(r"\s+", " ", n)
            n = re.sub(r"\bprivate\s+limited\b", "pvt. ltd.", n, flags=re.IGNORECASE)
            n = re.sub(r"\bpvt\.?\s*ltd\b", "pvt. ltd.", n, flags=re.IGNORECASE)
            def _strip_tail(token: str, s: str) -> str:
                if not token:
                    return s
                tl = token.lower().strip()
                sl = s.lower()
                if sl.endswith(tl):
                    idx = sl.rfind(tl)
                    return s[:idx].rstrip(" ,-/")
                return s
            s = _strip_tail(country, n)
            s = _strip_tail(state, s)
            s = _strip_tail(city, s)
            for c in ["india", "united states", "usa"]:
                s = _strip_tail(c, s)
            return re.sub(r"\s+", " ", s).strip().lower()

        # Collect matching records by canonical name comparison
        matches = []
        for org in self.unified_database:
            if not isinstance(org, dict):
                continue
            canon_org = canonicalize(org.get('name', ''), org.get('city', ''), org.get('state', ''), org.get('country', ''))
            if canon_org == canonicalize(org_name):
                matches.append(org)

        if not matches:
            return None

        # Aggregate certifications and prefer richer fields
        agg = {}
        best = max(matches, key=lambda o: sum(1 for k, v in o.items() if v))
        agg.update(best)
        agg['name'] = best.get('name', org_name)
        agg['merged_from'] = [m.get('name', '') for m in matches]

        # Union certifications with deduplication by normalized title
        # Harden against string items and unexpected types
        certs = []
        seen = set()
        for m in matches:
            cert_list = m.get('certifications', []) or []
            for c in cert_list:
                if isinstance(c, dict):
                    title = (c.get('name') or c.get('issuer') or '').lower().strip()
                    if not title:
                        continue
                    if title in seen:
                        continue
                    certs.append(c)
                    seen.add(title)
                elif isinstance(c, str):
                    title = c.lower().strip()
                    if not title:
                        continue
                    if title in seen:
                        continue
                    certs.append({'name': c})
                    seen.add(title)
                else:
                    # Skip unsupported certification item types
                    continue
        agg['certifications'] = certs
        return agg

    def search_organization_info_from_suggestion(self, suggestion_data):
        """Search for organization information using complete suggestion data from QuXAT database.

        Canonicalizes the suggestion display name by stripping location tokens so
        unified database matching works reliably (e.g., "Mayo Clinic - Rochester, Minnesota" -> "Mayo Clinic").
        """
        try:
            # Ensure suggestion_data is usable as a dictionary
            # Coerce string inputs and other types into a safe dict or fall back to regular search
            if isinstance(suggestion_data, str):
                suggestion_data = {
                    'display_name': suggestion_data,
                    'full_name': suggestion_data,
                    'location': '',
                    'type': 'Healthcare Organization'
                }
            elif suggestion_data is None:
                return None
            elif not isinstance(suggestion_data, dict):
                # Best-effort coercion; otherwise, use normal search
                try:
                    suggestion_str = str(suggestion_data)
                except Exception:
                    suggestion_str = ''
                if suggestion_str:
                    return self.search_organization_info(suggestion_str)
                return None
            
            org_name = suggestion_data.get('display_name', '')
            full_name = suggestion_data.get('full_name', '')
            location = suggestion_data.get('location', '')

            # Canonicalize the organization name using the provided location to remove suffixes
            try:
                base_name = self.canonicalize_name(org_name, location)
            except Exception:
                base_name = org_name
            
            # If no display_name, try to use the suggestion_data as a fallback
            if not org_name:
                # Check if suggestion_data has other name fields
                org_name = suggestion_data.get('name', '') or suggestion_data.get('full_name', '')
                if not org_name:
                    st.error("No organization name found in suggestion data")
                    return None
            
            # Initialize results structure
            results = {
                'name': base_name,
                'display_name': org_name,
                'full_name': full_name,
                'location': location,
                'type': suggestion_data.get('type', 'Healthcare Organization'),
                'certifications': [],
                'quality_initiatives': [],
                'iso_certifications': None,
                'branch_info': None,
                'score_breakdown': {},
                'total_score': 0,
                'data_source': 'QuXAT_Database_Suggestion'
            }
            
            # Search in unified database using the canonical base name
            unified_org = self.search_unified_database(base_name)
            # Extra safety: ensure we only treat dictionaries as unified org records
            if unified_org and not isinstance(unified_org, dict):
                unified_org = None
            # Fallback: try exact display name or full_name if canonical fails
            if not unified_org:
                try:
                    unified_org = self.search_unified_database(org_name)
                except Exception:
                    pass
            if not unified_org and full_name:
                try:
                    unified_org = self.search_unified_database(full_name)
                except Exception:
                    pass
            if unified_org:
                # Use complete data from unified database
                results['certifications'] = unified_org.get('certifications', [])
                results['unified_data'] = unified_org
                
                # Update with additional fields from unified database
                results['city'] = unified_org.get('city', results['location'])
                results['state'] = unified_org.get('state', '')
                results['country'] = unified_org.get('country', '')
                results['address'] = unified_org.get('address', '')
                results['website'] = unified_org.get('website', '')
                results['phone'] = unified_org.get('phone', '')
                results['email'] = unified_org.get('email', '')
                
                # Use original name if available
                if unified_org.get('original_name'):
                    results['original_name'] = unified_org['original_name']
            else:
                # Fallback to regular certification search
                certifications = self.search_certifications(base_name)
                results['certifications'] = certifications
            
            # Apply comprehensive deduplication to all certifications
            results['certifications'] = self._comprehensive_deduplicate_certifications(results['certifications'])
            
            # Search for quality initiatives
            initiatives = self.search_quality_initiatives(base_name)
            results['quality_initiatives'] = initiatives

            # Get branch info from healthcare validator
            branch_info = None
            try:
                validation_result = healthcare_validator.validate_organization_certifications(base_name)
                if validation_result and 'branches' in validation_result:
                    branch_info = validation_result['branches']
                    results['branch_info'] = branch_info
            except Exception as e:
                pass
            
            # Calculate quality score using the unified batch methodology for consistency
            # Align suggestion-based searches with the main search scoring
            patient_feedback_data = []
            score_data = self.calculate_quality_score(results['certifications'], initiatives, base_name)
            results['score_breakdown'] = score_data
            results['total_score'] = score_data['total_score']
            
            # Generate improvement recommendations
            recommendations = self.generate_improvement_recommendations(
                base_name, 
                score_data, 
                results['certifications'], 
                initiatives, 
                branch_info
            )
            results['improvement_recommendations'] = recommendations
            
            # Add score to history for trend tracking
            add_score_to_history(base_name, score_data)
            
            return results
            
        except Exception:
            # Fail gracefully without surfacing low-level errors to the UI
            st.info("üîç Organization search did not yield results using the suggestion. You can refine the name or try the regular search.")
            return None

    def search_organization_info(self, org_name):
        """Search for organization information from multiple sources including unified database"""
        try:
            # Initialize results
            results = {
                'name': org_name,
                'certifications': [],
                'quality_initiatives': [],
                'news_mentions': [],
                'website_info': {},
                'score_breakdown': {},
                'total_score': 0
            }
            
            # First, search in unified database
            unified_org = self.search_unified_database(org_name)
            if unified_org:
                # Use data from unified database
                results['certifications'] = unified_org.get('certifications', [])
                results['unified_data'] = unified_org
                
                # Defensive: remove any unvalidated JCI entries from unified data
                # Only retain JCI if validator confirms exact accreditation for this org
                validated_jci = []
                try:
                    validation_result = healthcare_validator.validate_organization_certifications(org_name)
                    if validation_result and 'certifications' in validation_result:
                        for cert in validation_result['certifications']:
                            if isinstance(cert, dict):
                                nm = cert.get('name', '').upper()
                                if 'JCI' in nm or 'JOINT COMMISSION' in nm:
                                    validated_jci.append(cert)
                except Exception:
                    validated_jci = []

                cleaned_certs = []
                for cert in results['certifications']:
                    if isinstance(cert, dict):
                        nm = cert.get('name', '').upper()
                    else:
                        nm = str(cert).upper()
                    # Skip any JCI-like entries unless they are validated above
                    if 'JCI' in nm or 'JOINT COMMISSION' in nm:
                        continue
                    cleaned_certs.append(cert)
                # Add validated JCI back, if present
                cleaned_certs.extend(validated_jci)
                results['certifications'] = cleaned_certs

                # Sanitize quality indicators based on validated JCI presence
                qi = unified_org.get('quality_indicators', {}) if isinstance(unified_org, dict) else {}
                if qi.get('jci_accredited') and not validated_jci:
                    qi['jci_accredited'] = False
                    qi['international_accreditation'] = False
                results['quality_indicators'] = qi
                # Removed success message for cleaner UI
            else:
                # Fallback to original search methods
                certifications = self.search_certifications(org_name)
                results['certifications'] = certifications
                
                # If no certifications found, try public domain fallback
                if not certifications:
                    try:
                        from public_domain_fallback_system import PublicDomainFallbackSystem
                        fallback_system = PublicDomainFallbackSystem()
                        # Use the generator to obtain structured fallback data
                        fallback_org = fallback_system.generate_fallback_organization_data(org_name)

                        if fallback_org:
                            results['certifications'] = fallback_org.get('certifications', [])
                            results['public_domain_data'] = fallback_org
                            results['data_source'] = 'public_domain'
                            # Add a note about the data source
                            results['source_note'] = "Data gathered from public domain sources"
                    except Exception:
                        # If fallback system fails, continue with empty certifications
                        pass
            
            # Enrich with official site details (website/address/phone/email)
            try:
                site_details = self.get_official_site_details(org_name)
                if isinstance(site_details, dict):
                    results['website_info'] = site_details
            except Exception:
                # If enrichment fails, continue without website info
                pass
            
            # Apply comprehensive deduplication to all certifications
            results['certifications'] = self._comprehensive_deduplicate_certifications(results['certifications'])
            
            # Search for quality initiatives and news
            initiatives = self.search_quality_initiatives(org_name)
            results['quality_initiatives'] = initiatives
            
            # ISO certifications disabled - only use validated certifications from official sources
            # The ISO certification scraper generates simulated data and should not be used for scoring
            try:
                # iso_certifications = get_iso_certifications(org_name, location="")
                results['iso_certifications'] = None
                
                # NOTE: ISO certifications will only be included if they come from validated official sources
                # through the healthcare_validator.validate_organization_certifications() method
                        
            except Exception as e:
                # If ISO certification scraping fails, continue without it
                results['iso_certifications'] = None
                pass
            
            # Get branch info from healthcare validator
            branch_info = None
            try:
                validation_result = healthcare_validator.validate_organization_certifications(org_name)
                if validation_result and 'branches' in validation_result:
                    branch_info = validation_result['branches']
                    results['branch_info'] = branch_info
            except Exception as e:
                # If branch info generation fails, continue without it
                pass
            
            # Calculate quality score using the unified batch methodology for consistency
            # This aligns the UI score with ranking_summary/scored_organizations data
            score_data = self.calculate_quality_score(results['certifications'], initiatives, org_name)
            results['score_breakdown'] = score_data
            results['total_score'] = score_data['total_score']

            # Enrich with precomputed unique rank and percentile if available
            try:
                pre_key = self._normalize_name(results.get('name', org_name))
                pre = self.scored_index.get(pre_key)
                if pre:
                    results['overall_rank'] = pre.get('overall_rank')
                    results['percentile'] = pre.get('percentile')
                    results['certification_count'] = pre.get('certification_count')
                    results['tie_breaking_info'] = pre.get('tie_breaking_info')
                    # Prefer precomputed total_score for display consistency if it differs
                    pre_score = pre.get('total_score')
                    if isinstance(pre_score, (int, float)):
                        results['total_score'] = pre_score
                    results['scoring_source'] = 'precomputed_exact'
                else:
                    # Fallback: attempt partial match against precomputed entries
                    best = None
                    q = pre_key
                    if self.scored_entries:
                        for entry in self.scored_entries:
                            nm = self._normalize_name(entry.get('name') or entry.get('organization_name'))
                            if not nm:
                                continue
                            if q in nm or nm in q:
                                if best is None or (entry.get('total_score', 0) > best.get('total_score', 0)):
                                    best = entry
                    if best:
                        results['overall_rank'] = best.get('overall_rank')
                        results['percentile'] = best.get('percentile')
                        results['certification_count'] = best.get('certification_count')
                        results['tie_breaking_info'] = best.get('tie_breaking_info')
                        pre_score = best.get('total_score')
                        if isinstance(pre_score, (int, float)):
                            results['total_score'] = pre_score
                        results['scoring_source'] = 'precomputed_partial'
                    else:
                        results['scoring_source'] = 'live'
            except Exception:
                # If enrichment fails, continue with live-computed values
                results['scoring_source'] = 'live'
            
            # Generate improvement recommendations
            recommendations = self.generate_improvement_recommendations(
                org_name, 
                score_data, 
                results['certifications'], 
                initiatives, 
                branch_info
            )
            results['improvement_recommendations'] = recommendations
            
            # Add score to history for trend tracking
            add_score_to_history(org_name, score_data)
            
            return results
            
        except Exception as e:
            st.error(f"Error searching for organization: {str(e)}")
            return None
    
    def search_unified_database(self, org_name):
        """Search for organization in the unified healthcare database with fuzzy matching"""
        if not self.unified_database:
            return None
            
        org_name_lower = org_name.lower().strip()
        
        # Direct name match (case-insensitive)
        for org in self.unified_database:
            # Skip if org is not a dictionary
            if not isinstance(org, dict):
                continue
            if org.get('name', '').lower().strip() == org_name_lower:
                aggregated = self.aggregate_unified_records(org.get('name', org_name))
                return aggregated or org
        
        # Partial name match (case-insensitive)
        for org in self.unified_database:
            # Skip if org is not a dictionary
            if not isinstance(org, dict):
                continue
            org_name_db = org.get('name', '').lower().strip()
            if org_name_lower in org_name_db or org_name_db in org_name_lower:
                aggregated = self.aggregate_unified_records(org.get('name', org_name))
                return aggregated or org
        
        # Search in original names for NABH organizations (case-insensitive)
        for org in self.unified_database:
            # Skip if org is not a dictionary
            if not isinstance(org, dict):
                continue
            original_name = org.get('original_name', '')
            if original_name:
                original_name_lower = original_name.lower().strip()
                if org_name_lower in original_name_lower or original_name_lower in org_name_lower:
                    aggregated = self.aggregate_unified_records(org.get('name', org_name))
                    return aggregated or org
        
        # Fuzzy matching for typos and variations (case-insensitive)
        from difflib import SequenceMatcher
        
        def similarity_score(a, b):
            return SequenceMatcher(None, a.lower().strip(), b.lower().strip()).ratio()
        
        def word_overlap_score(search_words, target_words):
            search_set = set(word.lower().strip() for word in search_words)
            target_set = set(word.lower().strip() for word in target_words)
            if not search_set or not target_set:
                return 0.0
            intersection = search_set.intersection(target_set)
            return len(intersection) / len(search_set)
        
        search_words = org_name_lower.split()
        best_match = None
        best_score = 0.0
        threshold = 0.6  # Minimum similarity threshold
        
        for org in self.unified_database:
            if not isinstance(org, dict):
                continue
                
            org_name_db = org.get('name', '')
            if not org_name_db:
                continue
            
            # Calculate multiple similarity scores (case-insensitive)
            scores = []
            
            # 1. Direct similarity
            direct_score = similarity_score(org_name_lower, org_name_db)
            scores.append(direct_score * 0.4)
            
            # 2. Word overlap score
            org_words = org_name_db.lower().strip().split()
            overlap_score = word_overlap_score(search_words, org_words)
            scores.append(overlap_score * 0.6)
            
            # Calculate final score
            final_score = sum(scores)
            
            # Special boost for common typos (case-insensitive)
            # Handle "john hopkins" -> "johns hopkins" case
            if 'john hopkins' in org_name_lower and 'johns hopkins' in org_name_db.lower():
                final_score = max(final_score, 0.9)
            
            if final_score > best_score and final_score >= threshold:
                best_score = final_score
                best_match = org
        
        # If we found a best match, also aggregate duplicates under the same canonical base
        if best_match:
            aggregated = self.aggregate_unified_records(best_match.get('name', org_name))
            return aggregated or best_match

        # As last resort, try aggregation by input name
        return self.aggregate_unified_records(org_name)

    def search_certifications(self, org_name):
        """Search for organization certifications using only validated official sources"""
        org_name_lower = org_name.lower().strip()
        
        # Use web validator to get real certification data from official sources only
        try:
            validation_result = healthcare_validator.validate_organization_certifications(org_name)
            
            # Extract certifications from the validation result
            if validation_result and 'certifications' in validation_result:
                certifications = validation_result['certifications']
                
                # NO automatic JCI enhancement - only use validated certifications
                # enhanced_certifications = self.enhance_certification_with_jci(certifications, org_name)
                
                # COMPREHENSIVE DEDUPLICATION: Remove all duplicates
                final_certifications = self._deduplicate_jci_certifications(certifications)
                
                # If no validated data found, show disclaimer
                if not final_certifications:
                    st.warning(f"WARNINGÔ∏è No validated certification data found for '{org_name}'. Please verify organization name or check official certification databases.")
                    return []
                
                return final_certifications
            else:
                # No automatic JCI assignment - only show validated certifications
                st.warning(f"WARNINGÔ∏è No validated certification data found for '{org_name}'. Please verify organization name or check official certification databases.")
                return []
            
        except Exception as e:
            st.error(f"Error validating certification data: {str(e)}")
            st.info("üí° Please check the organization name and try again. Only validated data from official sources is displayed.")
            return []
    
    def _comprehensive_deduplicate_certifications(self, certifications):
        """
        Enhanced comprehensive deduplication to prevent all types of certification duplicates
        """
        if not certifications:
            return certifications
        
        # Sanitize input: convert string items to dicts and skip invalid types
        sanitized = []
        for cert in certifications:
            if isinstance(cert, dict):
                sanitized.append(cert)
            elif isinstance(cert, str):
                name = cert.strip()
                if name:
                    sanitized.append({'name': name, 'status': 'Active'})
            else:
                # Skip unsupported certification item types
                continue

        # Track unique certifications by normalized name
        unique_certs = {}
        
        for cert in sanitized:
            cert_name = cert.get('name', '').strip()
            if not cert_name:
                continue
                
            # Normalize certification name for comparison
            normalized_name = self._normalize_cert_name(cert_name)
            
            # Skip empty normalized names
            if not normalized_name:
                continue
            
            # If this is a new certification, add it
            if normalized_name not in unique_certs:
                unique_certs[normalized_name] = cert
            else:
                # If duplicate found, keep the one with more information
                existing_cert = unique_certs[normalized_name]
                if self._is_better_cert(cert, existing_cert):
                    unique_certs[normalized_name] = cert
        
        # Additional pass to catch similar certifications that might have been missed
        final_certs = list(unique_certs.values())
        
        # Check for similar certifications using fuzzy matching
        import difflib
        to_remove = set()
        
        for i, cert1 in enumerate(final_certs):
            if i in to_remove:
                continue
            for j, cert2 in enumerate(final_certs[i+1:], i+1):
                if j in to_remove:
                    continue
                
                # Check similarity between original names
                similarity = difflib.SequenceMatcher(None, 
                    cert1.get('name', '').upper(), 
                    cert2.get('name', '').upper()).ratio()
                
                if similarity > 0.8:  # 80% similarity threshold
                    # Keep the better certification
                    if self._is_better_cert(cert2, cert1):
                        to_remove.add(i)
                    else:
                        to_remove.add(j)
        
        # Remove duplicates identified by fuzzy matching
        final_certs = [cert for i, cert in enumerate(final_certs) if i not in to_remove]
        
        return final_certs
    
    def _normalize_cert_name(self, cert_name):
        """Enhanced normalization for comprehensive duplicate detection"""
        import re
        
        # Convert to uppercase and remove common variations
        normalized = cert_name.upper().strip()
        
        # Handle common organization variations
        normalized = normalized.replace('JOINT COMMISSION INTERNATIONAL', 'JCI')
        normalized = normalized.replace('JOINT COMMISSION', 'JCI')
        normalized = normalized.replace('NATIONAL ACCREDITATION BOARD FOR HOSPITALS', 'NABH')
        normalized = normalized.replace('NATIONAL ACCREDITATION BOARD FOR HOSPITALS & HEALTHCARE PROVIDERS', 'NABH')
        normalized = normalized.replace('COLLEGE OF AMERICAN PATHOLOGISTS', 'CAP')
        normalized = normalized.replace('INTERNATIONAL ORGANIZATION FOR STANDARDIZATION', 'ISO')
        normalized = normalized.replace('INTERNATIONAL STANDARDS ORGANIZATION', 'ISO')
        
        # Handle ISO variations
        normalized = re.sub(r'ISO\s*(\d+)', r'ISO\1', normalized)  # ISO 9001 -> ISO9001
        normalized = re.sub(r'ISO\s*-\s*(\d+)', r'ISO\1', normalized)  # ISO-9001 -> ISO9001
        
        # Remove common words that don't add meaning
        words_to_remove = [
            'ACCREDITATION', 'ACCREDITED', 'CERTIFICATION', 'CERTIFIED', 'CERTIFICATE',
            'STANDARD', 'STANDARDS', 'QUALITY', 'MANAGEMENT', 'SYSTEM', 'SYSTEMS',
            'HEALTHCARE', 'HOSPITAL', 'MEDICAL', 'CLINICAL', 'LABORATORY', 'LAB',
            'INTERNATIONAL', 'NATIONAL', 'BOARD', 'COMMISSION', 'ORGANIZATION',
            'THE', 'OF', 'FOR', 'AND', '&', 'IN', 'ON', 'AT', 'BY', 'WITH'
        ]
        
        for word in words_to_remove:
            normalized = normalized.replace(word, ' ')
        
        # Remove punctuation and special characters
        normalized = re.sub(r'[^\w\s]', ' ', normalized)
        
        # Remove extra spaces and join
        normalized = ' '.join(normalized.split())
        
        # Handle specific cases
        if 'JCI' in normalized:
            normalized = 'JCI'
        elif 'NABH' in normalized:
            normalized = 'NABH'
        elif 'CAP' in normalized:
            normalized = 'CAP'
        elif re.search(r'ISO\s*\d+', normalized):
            # Extract ISO number
            iso_match = re.search(r'ISO\s*(\d+)', normalized)
            if iso_match:
                normalized = f'ISO{iso_match.group(1)}'
        
        return normalized.strip()
    
    def _is_better_cert(self, cert1, cert2):
        """Determine which certification has more complete information"""
        # Prefer certification with organization_info
        if 'organization_info' in cert1 and 'organization_info' not in cert2:
            return True
        if 'organization_info' in cert2 and 'organization_info' not in cert1:
            return False
            
        # Prefer certification with higher score impact
        score1 = cert1.get('score_impact', 0)
        score2 = cert2.get('score_impact', 0)
        if score1 != score2:
            return score1 > score2
            
        # Prefer certification with certificate number
        if cert1.get('certificate_number') and not cert2.get('certificate_number'):
            return True
        if cert2.get('certificate_number') and not cert1.get('certificate_number'):
            return False
            
        # Prefer more detailed certification (more fields)
        return len(str(cert1)) > len(str(cert2))
    
    def _deduplicate_jci_certifications(self, certifications):
        """
        Comprehensive JCI deduplication to prevent multiple JCI entries from different sources
        """
        if not certifications:
            return certifications
        
        # Sanitize input: convert string items to dicts and skip invalid types
        sanitized = []
        for cert in certifications:
            if isinstance(cert, dict):
                sanitized.append(cert)
            elif isinstance(cert, str):
                name = cert.strip()
                if name:
                    sanitized.append({'name': name, 'status': 'Active'})
            else:
                # Skip unsupported certification item types
                continue

        # Separate JCI and non-JCI certifications
        jci_certs = []
        other_certs = []
        
        for cert in sanitized:
            cert_name = cert.get('name', '').upper()
            if ('JCI' in cert_name or 
                'JOINT COMMISSION INTERNATIONAL' in cert_name):
                jci_certs.append(cert)
            else:
                other_certs.append(cert)
        
        # If multiple JCI certifications found, keep the most comprehensive one
        if len(jci_certs) > 1:
            # Priority: 1) Has organization_info, 2) Highest score_impact, 3) Most recent
            best_jci = max(jci_certs, key=lambda x: (
                'organization_info' in x,  # Prefer JCI with org info
                x.get('score_impact', 0),  # Prefer higher score
                x.get('certificate_number', ''),  # Prefer with cert number
                len(str(x))  # Prefer more detailed entry
            ))
            
            # Log deduplication for debugging
            st.info(f"üîß Removed {len(jci_certs) - 1} duplicate JCI certification(s)")
            
            return other_certs + [best_jci]
        
        return sanitized
    
    def search_quality_initiatives(self, org_name):
        """Search for quality initiatives using web-validated data"""
        try:
            validation_result = healthcare_validator.validate_quality_initiatives(org_name)
            
            # Extract initiatives from the validation result
            if validation_result and 'initiatives' in validation_result:
                initiatives = validation_result['initiatives']
                
                # If no validated data found, show disclaimer
                if not initiatives:
                    # Removed info message for cleaner UI
                    return []
                
                return initiatives
            else:
                # Removed info message for cleaner UI
                return []
            
        except Exception as e:
            st.error(f"Error validating quality initiative data: {str(e)}")
            st.info("üí° Please check the organization name and try again. Only validated data from official sources is displayed.")
            return []
    
    def calculate_quality_score(self, certifications, initiatives, org_name="", branch_info=None, patient_feedback_data=None):
        """Calculate quality score based on weighted certification system with international certifications having higher weights"""
        score_breakdown = {
            'certification_score': 0,
            'quality_initiatives_score': 0,
            'patient_feedback_score': 0,
            'total_score': 0,
            'compliance_check': None
        }

        # Robust input sanitization: ensure certifications and initiatives are dicts
        if certifications is None:
            certifications = []
        # Sanitize and deduplicate certifications to prevent string items
        certifications = self._comprehensive_deduplicate_certifications(certifications)

        if initiatives is None:
            initiatives = []
        # Convert any string initiatives to minimal dicts and drop unsupported types
        sanitized_initiatives = []
        for init in initiatives:
            if isinstance(init, dict):
                sanitized_initiatives.append(init)
            elif isinstance(init, str):
                name = init.strip()
                if name:
                    sanitized_initiatives.append({'name': name, 'status': 'Active', 'impact_score': 5, 'category': 'Other'})
        initiatives = sanitized_initiatives
        
        # Normalize certification statuses to be uniform and encouraging
        try:
            status_active_synonyms = {
                'ACTIVE', 'ACCREDITED', 'ACCREDITATION', 'VALID', 'CURRENT', 'COMPLIANT', 'CERTIFIED'
            }
            status_progress_synonyms = {
                'IN PROGRESS', 'PENDING', 'APPLIED', 'UNDER REVIEW'
            }
            for c in certifications:
                if isinstance(c, dict):
                    raw = str(c.get('status', '')).strip().upper()
                    if raw in status_active_synonyms:
                        c['status'] = 'Active'
                    elif raw in status_progress_synonyms:
                        c['status'] = 'In Progress'
        except Exception:
            pass

        # MANDATORY: Validate compliance with required certifications before score generation
        compliance_summary = self._validate_mandatory_certifications(certifications)
        score_breakdown['compliance_check'] = compliance_summary
        
        # EQUIVALENCY LOGIC: NABL accreditation implies ISO 15189 accreditation
        certifications = self._apply_nabl_iso_equivalency(certifications)
        
        # BALANCED SCORING METHODOLOGY - REBALANCED FOR MANDATORY ISO STANDARDS
        # Certification weights optimized for balanced improvement opportunities
        certification_weights = {
            # TIER 1: International Excellence Standards (Premium Weight)
            'JCI': {'weight': 4.5, 'base_score': 35, 'description': 'Joint Commission International - Global Healthcare Excellence', 'region': 'International'},
            'MAGNET': {'weight': 4.0, 'base_score': 32, 'description': 'Magnet Recognition Program - International Nursing Excellence', 'region': 'International'},
            
            # TIER 2: International ISO Standards (High Weight) - MANDATORY STANDARDS
            'ISO_9001': {'weight': 3.5, 'base_score': 28, 'description': 'Quality Management Systems - MANDATORY', 'region': 'International'},
            'ISO_13485': {'weight': 3.5, 'base_score': 28, 'description': 'Medical Devices Quality Management - MANDATORY', 'region': 'International'},
            'ISO_15189': {'weight': 3.8, 'base_score': 30, 'description': 'Medical Laboratory Quality - MANDATORY', 'region': 'International'},
            'ISO_27001': {'weight': 4.0, 'base_score': 32, 'description': 'Information Security Management - MANDATORY', 'region': 'International'},
            'ISO_45001': {'weight': 3.6, 'base_score': 29, 'description': 'Occupational Health & Safety - MANDATORY', 'region': 'International'},
            'ISO_14001': {'weight': 3.2, 'base_score': 26, 'description': 'Environmental Management - MANDATORY', 'region': 'International'},
            'ISO_50001': {'weight': 2.8, 'base_score': 22, 'description': 'Energy Management - RECOMMENDED', 'region': 'International'},
            'ISO_GENERAL': {'weight': 2.5, 'base_score': 20, 'description': 'Other ISO Certifications', 'region': 'International'},
            
            # TIER 3: National Excellence Standards (High Weight) - MANDATORY FOR LABS
            'CAP': {'weight': 4.2, 'base_score': 34, 'description': 'College of American Pathologists - MANDATORY', 'region': 'North America', 'mandatory': True},
            'NABH': {'weight': 3.8, 'base_score': 30, 'description': 'National Accreditation Board for Hospitals', 'region': 'India'},
            'NABL': {'weight': 3.6, 'base_score': 28, 'description': 'National Accreditation Board for Testing and Calibration Laboratories (NABL)', 'region': 'India'},
            
            # TIER 4: Regional Standards (Medium Weight)
            'STATE': {'weight': 2.2, 'base_score': 18, 'description': 'State/Provincial Accreditation', 'region': 'Regional'},
            'LOCAL': {'weight': 1.8, 'base_score': 15, 'description': 'Local Healthcare Certification', 'region': 'Local'}
        }
        
        # Calculate weighted certification score with enhanced logic
        total_weighted_score = 0
        certification_count = 0
        certification_breakdown = {}  # Track individual certification contributions
        
        if certifications is None:
            certifications = []
        
        # Process each certification with weighted scoring (robust against missing status)
        for cert in certifications:
            status_val = str(cert.get('status', '')).strip()
            if status_val not in ['Active', 'In Progress']:
                continue
                
            cert_name = cert.get('name', '').upper()
            cert_type = self._determine_certification_type(cert_name)
            
            if cert_type in certification_weights:
                weight_info = certification_weights[cert_type]
                base_score = cert.get('score_impact', weight_info['base_score'])
                weight = weight_info['weight']
                
                # Apply status multiplier
                status_multiplier = 1.0 if status_val == 'Active' else 0.5
                
                # Calculate weighted score
                weighted_score = base_score * weight * status_multiplier
                total_weighted_score += weighted_score
                certification_count += 1
                
                # Track certification breakdown for transparency
                if cert_type not in certification_breakdown:
                    certification_breakdown[cert_type] = {
                        'count': 0,
                        'total_score': 0,
                        'weight': weight,
                        'description': weight_info['description']
                    }
                certification_breakdown[cert_type]['count'] += 1
                certification_breakdown[cert_type]['total_score'] += weighted_score
        
        # Store certification breakdown in score_breakdown for transparency
        score_breakdown['certification_breakdown'] = certification_breakdown
        
        # Apply performance bonuses for multiple certifications
        if certification_count > 1:
            # Bonus for having multiple certification types
            diversity_bonus = min(certification_count * 2, 10)  # Up to 10 points
            total_weighted_score += diversity_bonus
            score_breakdown['diversity_bonus'] = diversity_bonus
        
        # Apply international certification premium (JCI and specific ISO certifications)
        international_certs = self._count_international_certifications(certifications)
        if international_certs > 0:
            international_bonus = min(international_certs * 3, 12)  # Reduced bonus since weights are higher
            total_weighted_score += international_bonus
            score_breakdown['international_bonus'] = international_bonus
        
        # Cap the certification score at 75 (increased from 70 to accommodate higher weights)
        certification_score = min(total_weighted_score, 75)
        
        score_breakdown['certification_score'] = max(0, certification_score)
        
        # Calculate quality initiatives score
        quality_initiatives_score = self._calculate_quality_initiatives_score(initiatives)
        score_breakdown['quality_initiatives_score'] = quality_initiatives_score
        
        # Calculate total score with MANDATORY ISO STANDARDS PENALTY ENFORCEMENT
        base_total_score = score_breakdown['certification_score'] + score_breakdown['quality_initiatives_score']

        # Apply MANDATORY ISO STANDARDS penalties (CRITICAL for healthcare quality assurance)
        mandatory_penalty = compliance_summary.get('total_penalty', 0)

        # Weight alignment: soften penalties when strong historical performance exists (precomputed)
        try:
            precomputed_entry = None
            if isinstance(org_name, str) and org_name.strip():
                norm = self._normalize_name(org_name)
                precomputed_entry = self.scored_index.get(norm)
                if not precomputed_entry and hasattr(self, 'scored_entries'):
                    best = None
                    for entry in self.scored_entries:
                        name_norm = self._normalize_name(str(entry.get('name', '')))
                        if norm in name_norm or name_norm in norm:
                            if best is None or float(entry.get('total_score', 0)) > float(best.get('total_score', 0)):
                                best = entry
                    precomputed_entry = best

            if precomputed_entry and float(precomputed_entry.get('total_score', 0)) >= 70:
                reduction_factor = 0.4  # reduce penalties by 60% for high performers
                adjusted_penalty = int(mandatory_penalty * reduction_factor)
                score_breakdown['mandatory_penalty_aligned'] = adjusted_penalty
                score_breakdown['alignment_note'] = 'Penalties softened based on precomputed high performance context.'
                mandatory_penalty = adjusted_penalty
        except Exception:
            # If alignment context lookup fails, keep original penalties
            pass
        if mandatory_penalty > 0:
            score_breakdown['mandatory_penalty'] = mandatory_penalty
            score_breakdown['penalty_breakdown'] = compliance_summary.get('penalty_breakdown', {})
            score_breakdown['missing_critical_standards'] = compliance_summary.get('missing_critical_standards', [])
            
            # Enhanced penalty reason with specific missing MANDATORY standards
            missing_standards = [std['standard'] for std in compliance_summary.get('missing_critical_standards', [])]
            if missing_standards:
                score_breakdown['penalty_reason'] = f"MANDATORY ISO STANDARDS MISSING: {', '.join(missing_standards)} - Total penalty: {mandatory_penalty} points"
            else:
                score_breakdown['penalty_reason'] = "All mandatory ISO standards are compliant"
        else:
            score_breakdown['mandatory_penalty'] = 0
            score_breakdown['penalty_breakdown'] = {}
            score_breakdown['missing_critical_standards'] = []
            score_breakdown['penalty_reason'] = "‚úÖ All mandatory ISO standards are compliant"
        
        # Final score calculation with MANDATORY ISO penalties applied BEFORE final score
        final_score = max(0, base_total_score - mandatory_penalty)

        # Encouraging baseline: ensure non-zero score when recognized accreditation exists
        try:
            recognized_keywords = ['NABH', 'JCI', 'CAP', 'ISO', 'NABL']
            recognized_count = 0
            for c in certifications:
                if isinstance(c, dict):
                    name = str(c.get('name', '')).upper()
                    if any(k in name for k in recognized_keywords):
                        recognized_count += 1
            baseline_floor = 12.0
            if recognized_count > 0 and final_score < baseline_floor:
                score_breakdown['baseline_adjustment'] = baseline_floor - final_score
                final_score = baseline_floor
            else:
                score_breakdown['baseline_adjustment'] = 0.0
        except Exception:
            # In case of unexpected data issues, keep existing score
            score_breakdown['baseline_adjustment'] = 0.0

        score_breakdown['total_score'] = final_score
        
        # Add comprehensive compliance status
        total_mandatory_standards = len([cert for cert in compliance_summary.get('missing_critical_standards', []) if cert.get('mandatory', False)])
        if total_mandatory_standards > 0:
            score_breakdown['compliance_status'] = f"‚ö†Ô∏è CRITICAL: {total_mandatory_standards} mandatory ISO standards missing. Immediate action required for quality assurance."
        else:
            score_breakdown['compliance_status'] = "‚úÖ EXCELLENT: All mandatory ISO standards are compliant. Organization meets international healthcare quality requirements."
        
        # Add CAP compliance warning if not compliant (use dynamic penalty value)
        if not compliance_summary.get('cap_compliant', False):
            cap_penalty = compliance_summary.get('details', {}).get('CAP', {}).get('penalty', 0)
            score_breakdown['cap_warning'] = f"‚ö†Ô∏è CRITICAL: CAP accreditation is MANDATORY for laboratory services. {cap_penalty}-point penalty applied."
        else:
            score_breakdown['cap_warning'] = "‚úÖ CAP accreditation is compliant."
        
        return score_breakdown

    def calculate_quality_score_international(self, certifications, initiatives, org_name="", branch_info=None, patient_feedback_data=None):
        """Calculate quality score using InternationalHealthcareScorer and return a mapped breakdown for UI"""
        score_breakdown = {
            'certification_score': 0,
            'quality_initiatives_score': 0,
            'patient_feedback_score': 0,
            'total_score': 0,
            'compliance_check': None
        }

        # Ensure lists are present
        certifications = certifications or []
        initiatives = initiatives or []

        # Normalize certification statuses
        try:
            status_active_synonyms = {'ACTIVE', 'ACCREDITED', 'ACCREDITATION', 'VALID', 'CURRENT', 'COMPLIANT', 'CERTIFIED'}
            status_progress_synonyms = {'IN PROGRESS', 'PENDING', 'APPLIED', 'UNDER REVIEW'}
            for c in certifications:
                if isinstance(c, dict):
                    raw = str(c.get('status', '')).strip().upper()
                    if raw in status_active_synonyms:
                        c['status'] = 'Active'
                    elif raw in status_progress_synonyms:
                        c['status'] = 'In Progress'
        except Exception:
            pass

        # Build context from unified database
        context = None
        try:
            org_data = self.search_unified_database(org_name)
            if org_data:
                country = org_data.get('country', '')
                context = {
                    'region': self._country_to_region(country),
                    'region_type': self._country_to_region_type(country),
                    'hospital_type': org_data.get('hospital_type', 'Hospital')
                }
        except Exception:
            context = None

        # Use international scorer
        intl = self.international_scorer.calculate_international_quality_score(
            certifications=certifications,
            quality_metrics=None,
            hospital_context=context
        )

        # Map results to UI-friendly structure
        score_breakdown['certification_score'] = intl.get('certification_score', 0)
        score_breakdown['quality_initiatives_score'] = intl.get('quality_metrics_score', 0)
        score_breakdown['patient_feedback_score'] = 0
        score_breakdown['total_score'] = intl.get('total_score', 0)
        score_breakdown['certification_breakdown'] = intl.get('certification_breakdown', {})
        score_breakdown['international_details'] = {
            'international_recognition': intl.get('international_recognition', {}),
            'regional_context': intl.get('regional_context', {}),
            'recommendations': intl.get('recommendations', [])
        }

        # Optional: include compliance/penalty fields if present
        for key in ['mandatory_penalty', 'penalty_breakdown', 'missing_critical_standards', 'compliance_status', 'cap_warning']:
            if key in intl:
                score_breakdown[key] = intl[key]

        return score_breakdown
    
    def _determine_certification_type(self, cert_name):
        """Determine specific certification type based on name with detailed ISO recognition"""
        cert_name = cert_name.upper()
        
        # JCI Accreditation
        if 'JCI' in cert_name or 'JOINT COMMISSION' in cert_name:
            return 'JCI'
        
        # Magnet Recognition Program
        elif 'MAGNET' in cert_name:
            return 'MAGNET'
        
        # Specific ISO Certifications (Healthcare Critical)
        elif 'ISO 9001' in cert_name or 'ISO9001' in cert_name:
            return 'ISO_9001'
        elif 'ISO 13485' in cert_name or 'ISO13485' in cert_name:
            return 'ISO_13485'
        elif 'ISO 15189' in cert_name or 'ISO15189' in cert_name:
            return 'ISO_15189'
        elif 'ISO 27001' in cert_name or 'ISO27001' in cert_name:
            return 'ISO_27001'
        elif 'ISO 45001' in cert_name or 'ISO45001' in cert_name:
            return 'ISO_45001'
        elif 'ISO 14001' in cert_name or 'ISO14001' in cert_name:
            return 'ISO_14001'
        elif 'ISO 50001' in cert_name or 'ISO50001' in cert_name:
            return 'ISO_50001'
        
        # General ISO (for other ISO certifications not specifically listed)
        elif 'ISO' in cert_name:
            return 'ISO_GENERAL'
        
        # National/Regional Accreditation Bodies
        elif 'CAP' in cert_name or 'COLLEGE OF AMERICAN PATHOLOGISTS' in cert_name:
            return 'CAP'
        elif 'NABH' in cert_name:
            return 'NABH'
        elif 'NABL' in cert_name:
            return 'NABL'
        
        # Regional/Local Certifications
        elif 'STATE' in cert_name or 'PROVINCIAL' in cert_name:
            return 'STATE'
        else:
            return 'LOCAL'
    
    def _determine_international_certification_type(self, cert_name):
        """Determine certification tier and type for international scoring"""
        cert_name = cert_name.upper()
        
        # Tier 1: Global Gold Standards
        if 'JCI' in cert_name or 'JOINT COMMISSION INTERNATIONAL' in cert_name:
            return 'GLOBAL_GOLD', 'JCI'
        elif 'WHO COLLABORATING' in cert_name or 'WORLD HEALTH ORGANIZATION' in cert_name:
            return 'GLOBAL_GOLD', 'WHO_COLLABORATING'
        elif 'MAGNET' in cert_name:
            return 'GLOBAL_GOLD', 'MAGNET'
        elif 'PLANETREE' in cert_name:
            return 'GLOBAL_GOLD', 'PLANETREE'
        
        # Tier 2: International ISO Standards
        elif 'ISO 9001' in cert_name or 'ISO9001' in cert_name:
            return 'ISO_STANDARDS', 'ISO_9001'
        elif 'ISO 13485' in cert_name or 'ISO13485' in cert_name:
            return 'ISO_STANDARDS', 'ISO_13485'
        elif 'ISO 15189' in cert_name or 'ISO15189' in cert_name:
            return 'ISO_STANDARDS', 'ISO_15189'
        elif 'ISO 27001' in cert_name or 'ISO27001' in cert_name:
            return 'ISO_STANDARDS', 'ISO_27001'
        elif 'ISO 45001' in cert_name or 'ISO45001' in cert_name:
            return 'ISO_STANDARDS', 'ISO_45001'
        elif 'ISO 14001' in cert_name or 'ISO14001' in cert_name:
            return 'ISO_STANDARDS', 'ISO_14001'
        elif 'ISO 50001' in cert_name or 'ISO50001' in cert_name:
            return 'ISO_STANDARDS', 'ISO_50001'
        
        # Tier 3: Regional Excellence Standards
        elif 'JOINT COMMISSION' in cert_name and 'INTERNATIONAL' not in cert_name:
            return 'REGIONAL_EXCELLENCE', 'JOINT_COMMISSION'
        elif 'CQC' in cert_name or 'CARE QUALITY COMMISSION' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'CQC'
        elif 'ACHS' in cert_name or 'AUSTRALIAN COUNCIL ON HEALTHCARE' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'ACHS'
        elif 'CCHSA' in cert_name or 'CANADIAN COUNCIL ON HEALTH' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'CCHSA'
        elif 'HAS' in cert_name or 'HAUTE AUTORIT√â' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'HAS'
        elif 'NIAHO' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'NIAHO'
        elif 'ACHSI' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'ACHSI'
        elif 'GAHAR' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'GAHAR'
        elif 'COHSASA' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'COHSASA'
        elif 'JCAHO' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'JCAHO'
        elif 'MSQH' in cert_name:
            return 'REGIONAL_EXCELLENCE', 'MSQH'
        
        # Tier 4: National/Regional Standards (Equal Treatment)
        elif 'NABH' in cert_name:
            return 'NATIONAL_REGIONAL', 'NABH'
        elif 'NABL' in cert_name:
            return 'NATIONAL_REGIONAL', 'NABL'
        elif 'CAP' in cert_name or 'COLLEGE OF AMERICAN PATHOLOGISTS' in cert_name:
            return 'NATIONAL_REGIONAL', 'CAP'
        elif 'AABB' in cert_name:
            return 'NATIONAL_REGIONAL', 'AABB'
        elif 'CLIA' in cert_name:
            return 'NATIONAL_REGIONAL', 'CLIA'
        elif 'RTAC' in cert_name:
            return 'NATIONAL_REGIONAL', 'RTAC'
        elif 'JACIE' in cert_name:
            return 'NATIONAL_REGIONAL', 'JACIE'
        elif 'FACT' in cert_name:
            return 'NATIONAL_REGIONAL', 'FACT'
        elif 'AACI' in cert_name:
            return 'NATIONAL_REGIONAL', 'AACI'
        elif 'STATE' in cert_name or 'PROVINCIAL' in cert_name:
            return 'NATIONAL_REGIONAL', 'STATE_REGIONAL'
        
        # Tier 5: Specialty Certifications
        elif 'HIMSS' in cert_name:
            return 'SPECIALTY', 'HIMSS'
        elif 'AAAHC' in cert_name:
            return 'SPECIALTY', 'AAAHC'
        elif 'AAAASF' in cert_name:
            return 'SPECIALTY', 'AAAASF'
        elif 'ACHC' in cert_name:
            return 'SPECIALTY', 'ACHC'
        elif 'CHAP' in cert_name:
            return 'SPECIALTY', 'CHAP'
        elif 'URAC' in cert_name:
            return 'SPECIALTY', 'URAC'
        elif 'NCQA' in cert_name:
            return 'SPECIALTY', 'NCQA'
        elif 'AAPL' in cert_name:
            return 'SPECIALTY', 'AAPL'
        else:
            return 'SPECIALTY', 'LOCAL'
    
    def _count_international_certifications(self, certifications):
        """Count international certifications (JCI, ISO)"""
        international_count = 0
        for cert in certifications:
            if cert['status'] == 'Active':
                cert_name = cert.get('name', '').upper()
                if 'JCI' in cert_name or 'ISO' in cert_name or 'JOINT COMMISSION' in cert_name or 'MAGNET' in cert_name:
                    international_count += 1
        return international_count
    
    def _apply_nabl_iso_equivalency(self, certifications):
        """
        Apply NABL-ISO 15189 equivalency logic: When a healthcare organization has NABL accreditation,
        it automatically implies ISO 15189 accreditation for scoring purposes.
        """
        if not certifications:
            return certifications
        
        # Check if NABL accreditation exists and is active
        has_active_nabl = False
        nabl_cert = None
        
        for cert in certifications:
            cert_name = cert.get('name', '').upper()
            if 'NABL' in cert_name and cert.get('status') == 'Active':
                has_active_nabl = True
                nabl_cert = cert
                break
        
        # If NABL is found, check if ISO 15189 already exists
        if has_active_nabl:
            has_iso_15189 = False
            for cert in certifications:
                cert_name = cert.get('name', '').upper()
                if 'ISO 15189' in cert_name or 'ISO15189' in cert_name:
                    has_iso_15189 = True
                    break
            
            # If ISO 15189 doesn't exist, add it as an implied certification
            if not has_iso_15189:
                implied_iso_cert = {
                    'name': 'ISO 15189 (Implied by NABL)',
                    'status': 'Active',
                    'score_impact': 22,  # Same as ISO 15189 base score
                    'description': 'Medical Laboratories Quality and Competence - Implied by NABL Accreditation',
                    'validity': nabl_cert.get('validity', 'Valid'),
                    'issuer': 'ISO (Implied)',
                    'certificate_number': f"IMPLIED-{nabl_cert.get('certificate_number', 'N/A')}",
                    'equivalency_note': '‚öñÔ∏è Automatically granted due to NABL accreditation equivalency'
                }
                certifications.append(implied_iso_cert)
        
        return certifications
    
    def _validate_mandatory_certifications(self, certifications):
        """
        Validate compliance with mandatory certification requirements before QuXAT score generation.
        MANDATORY ISO STANDARDS FRAMEWORK FOR HEALTHCARE QUALITY ASSURANCE.
        
        All healthcare organizations MUST have the following ISO standards:
        - ISO 9001 Quality Management [MANDATORY - 8 point penalty]
        - ISO 15189 Medical Laboratory Quality [MANDATORY - 10 point penalty]
        - ISO 27001 Information Security [MANDATORY - 12 point penalty]
        - ISO 45001 Occupational Health & Safety [MANDATORY - 10 point penalty]
        - ISO 13485 Medical Device Quality [MANDATORY - 8 point penalty]
        - ISO 14001 Environmental Management [MANDATORY - 6 point penalty]
        - College of American Pathologists (CAP) [MANDATORY - 15 point penalty]
        
        BALANCED SCORING APPROACH:
        - Total possible penalty: 69 points (ensures organizations can still achieve positive scores)
        - Penalties are proportional to the importance of each standard
        - Organizations without any ISO standards will face significant but not devastating penalties
        - Room for improvement through quality initiatives and other certifications
        """
        required_certifications = {
            'CAP': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 8, 'category': 'Laboratory Standards', 'importance': 'Critical'},
            'JCI': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 10, 'category': 'Hospital Accreditation', 'importance': 'Critical'},
            'ISO 9001': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 4, 'category': 'Quality Management', 'importance': 'Critical'},
            'ISO 15189': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 5, 'category': 'Laboratory Quality', 'importance': 'Critical'},
            'ISO 27001': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 6, 'category': 'Information Security', 'importance': 'Critical'},
            'ISO 45001': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 5, 'category': 'Occupational Safety', 'importance': 'Critical'},
            'ISO 13485': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 4, 'category': 'Medical Devices', 'importance': 'Critical'},
            'ISO 14001': {'found': False, 'status': None, 'name': None, 'mandatory': True, 'penalty': 3, 'category': 'Environmental Management', 'importance': 'Critical'},
            'ISO 50001': {'found': False, 'status': None, 'name': None, 'mandatory': False, 'penalty': 0, 'category': 'Energy Management', 'importance': 'Critical'}
        }

        # Regional adjustments: soften ISO penalties when strong US-equivalent standards are present
        # Detect presence of U.S. Joint Commission (non-international) and CAP
        has_us_joint_commission = False
        has_cap = False
        if certifications:
            for cert in certifications:
                name_upper = str(cert.get('name', '')).upper()
                if 'JOINT COMMISSION' in name_upper and 'INTERNATIONAL' not in name_upper:
                    has_us_joint_commission = True
                if 'CAP' in name_upper or 'COLLEGE OF AMERICAN PATHOLOGISTS' in name_upper:
                    has_cap = True

        if has_us_joint_commission or has_cap:
            # Softening ISO penalties to reflect US equivalency (TJC/CAP)
            # ISO 15189 is lab-specific: if CAP is present, do not penalize for missing ISO 15189
            if has_cap:
                required_certifications['ISO 15189']['penalty'] = 0
            else:
                required_certifications['ISO 15189']['penalty'] = max(1, int(required_certifications['ISO 15189']['penalty'] * 0.5))

            for iso_key in ['ISO 9001', 'ISO 27001', 'ISO 45001', 'ISO 13485', 'ISO 14001']:
                required_certifications[iso_key]['penalty'] = max(1, int(required_certifications[iso_key]['penalty'] * 0.5))
        
        compliance_summary = {
            'total_required': len(required_certifications),
            'compliant_count': 0,
            'non_compliant_count': 0,
            'compliance_percentage': 0,
            'details': required_certifications,
            'is_fully_compliant': False,
            'cap_compliant': False,  # Track CAP compliance specifically
            'total_penalty': 0,  # Track total penalty for missing mandatory certifications
            'penalty_breakdown': {},  # Track penalties by category
            'missing_critical_standards': []  # Track missing critical international standards
        }
        
        if not certifications:
            # No certifications provided: treat all mandatory standards as missing
            compliance_summary['compliant_count'] = 0
            compliance_summary['non_compliant_count'] = len(required_certifications)
            compliance_summary['compliance_percentage'] = 0
            compliance_summary['is_fully_compliant'] = False
            compliance_summary['cap_compliant'] = False

            total_penalty = 0
            for cert_key, cert_info in required_certifications.items():
                # Record missing mandatory standards with penalties
                if cert_info.get('mandatory', False) and cert_info.get('penalty', 0) > 0:
                    total_penalty += cert_info['penalty']
                    category = cert_info.get('category', 'Other')
                    # Track penalty breakdown by category
                    if category not in compliance_summary['penalty_breakdown']:
                        compliance_summary['penalty_breakdown'][category] = 0
                    compliance_summary['penalty_breakdown'][category] += cert_info['penalty']

                    compliance_summary['missing_critical_standards'].append({
                        'standard': cert_key,
                        'category': category,
                        'penalty': cert_info['penalty'],
                        'impact': cert_info.get('importance', 'Critical'),
                        'mandatory': True,
                        'description': f"Missing {cert_key} certification - {cert_info['penalty']} point penalty applied"
                    })

            compliance_summary['total_penalty'] = total_penalty
            return compliance_summary
        
        # Check each certification against requirements
        for cert in certifications:
            cert_name = cert.get('name', '').upper()
            cert_status = cert.get('status', 'Unknown')
            
            # Check for ISO certifications
            for iso_standard in ['9001', '14001', '45001', '27001', '13485', '50001', '15189']:
                if f'ISO {iso_standard}' in cert_name or f'ISO{iso_standard}' in cert_name:
                    key = f'ISO {iso_standard}'
                    required_certifications[key]['found'] = True
                    required_certifications[key]['status'] = cert_status
                    required_certifications[key]['name'] = cert.get('name', '')
                    break
            
            # Check for CAP accreditation
            if 'CAP' in cert_name or 'COLLEGE OF AMERICAN PATHOLOGISTS' in cert_name:
                required_certifications['CAP']['found'] = True
                required_certifications['CAP']['status'] = cert_status
                required_certifications['CAP']['name'] = cert.get('name', '')

            # Check for JCI accreditation (mandatory) and equivalency for US Joint Commission
            if 'JOINT COMMISSION INTERNATIONAL' in cert_name or 'JCI' in cert_name:
                required_certifications['JCI']['found'] = True
                required_certifications['JCI']['status'] = cert_status
                required_certifications['JCI']['name'] = cert.get('name', '')
            elif 'JOINT COMMISSION' in cert_name and 'INTERNATIONAL' not in cert_name:
                # Treat US Joint Commission as equivalent to JCI for mandatory compliance
                required_certifications['JCI']['found'] = True
                required_certifications['JCI']['status'] = cert_status
                required_certifications['JCI']['name'] = cert.get('name', '')
        
        # Calculate compliance metrics with MANDATORY ISO STANDARDS PENALTY SYSTEM
        for cert_key, cert_info in required_certifications.items():
            if cert_info['found'] and cert_info['status'] in ['Active', 'Valid', 'Current']:
                compliance_summary['compliant_count'] += 1
                # Check CAP compliance specifically
                if cert_key == 'CAP':
                    compliance_summary['cap_compliant'] = True
            else:
                compliance_summary['non_compliant_count'] += 1
                # Apply penalty for missing MANDATORY certifications
                penalty = cert_info.get('penalty', 0)
                category = cert_info.get('category', 'Other')
                importance = cert_info.get('importance', 'Recommended')
                
                # ONLY apply penalties for MANDATORY certifications
                if cert_info.get('mandatory', False) and penalty > 0:
                    compliance_summary['total_penalty'] += penalty
                    
                    # Track penalty breakdown by category
                    if category not in compliance_summary['penalty_breakdown']:
                        compliance_summary['penalty_breakdown'][category] = 0
                    compliance_summary['penalty_breakdown'][category] += penalty
                    
                    # Track missing critical standards (ALL mandatory standards are critical)
                    compliance_summary['missing_critical_standards'].append({
                        'standard': cert_key,
                        'category': category,
                        'penalty': penalty,
                        'impact': importance,
                        'mandatory': True,
                        'description': f"Missing {cert_key} certification - {penalty} point penalty applied"
                    })
        
        compliance_summary['compliance_percentage'] = (
            compliance_summary['compliant_count'] / compliance_summary['total_required'] * 100
        )
        compliance_summary['is_fully_compliant'] = compliance_summary['compliant_count'] == compliance_summary['total_required']
        
        return compliance_summary
    
    def _calculate_quality_initiatives_score(self, initiatives):
        """Calculate score based on quality initiatives with BALANCED WEIGHTED IMPACT for improvement opportunities"""
        if not initiatives or initiatives == 'no_official_data_available':
            return 0
        
        total_score = 0
        initiative_count = 0
        
        # REBALANCED Category weights for different types of initiatives - MORE GENEROUS SCORING
        category_weights = {
            'Patient Safety': 1.2,          # Increased from 1.0
            'Quality Improvement': 1.1,     # Increased from 0.9
            'Clinical Excellence': 1.0,     # Increased from 0.8
            'Technology Innovation': 0.9,   # Increased from 0.7
            'Staff Development': 0.8,       # Increased from 0.6
            'Community Health': 0.7,        # Increased from 0.5
            'Research': 0.6,                # Increased from 0.4
            'Other': 0.5                    # Increased from 0.3
        }
        
        for initiative in initiatives:
            if isinstance(initiative, dict):
                # Get initiative details
                category = initiative.get('category', 'Other')
                impact_score = initiative.get('impact_score', 6)  # Increased default from 5 to 6
                status = initiative.get('status', 'Active')
                
                # Apply category weight
                category_weight = category_weights.get(category, 0.5)
                
                # Apply status multiplier - MORE GENEROUS
                status_multiplier = 1.0 if status == 'Active' else 0.8 if status == 'In Progress' else 0.5  # Increased multipliers
                
                # Calculate weighted score
                weighted_score = impact_score * category_weight * status_multiplier
                total_score += weighted_score
                initiative_count += 1
        
        # Apply diversity bonus for multiple initiatives - INCREASED BONUS
        if initiative_count > 1:
            diversity_bonus = min(initiative_count * 0.8, 8)  # Increased from 0.5 to 0.8, max from 5 to 8
            total_score += diversity_bonus
        
        # INCREASED Cap for quality initiatives score from 30 to 35 for better improvement opportunities
        return min(total_score, 35)
    
    def generate_improvement_recommendations(self, org_name, score_breakdown, certifications, initiatives, branch_info=None):
        """Generate actionable improvement recommendations based on scoring analysis"""
        recommendations = {
            'priority_actions': [],
            'certification_gaps': [],
            'quality_initiatives': [],
            'operational_improvements': [],
            'strategic_recommendations': [],
            'score_potential': {}
        }
        
        current_total = score_breakdown.get('total_score', 0)
        cert_score = score_breakdown.get('certification_score', 0)
        quality_score = score_breakdown.get('quality_initiatives_score', 0)
        
        # Calculate potential score improvements - UPDATED FOR REBALANCED SCORING
        max_possible_score = 110  # 75 (cert) + 35 (quality initiatives) - UPDATED
        improvement_potential = max_possible_score - current_total
        
        recommendations['score_potential'] = {
            'current_score': current_total,
            'maximum_possible': max_possible_score,
            'improvement_potential': improvement_potential,
            'certification_potential': max(0, 75 - cert_score),  # Updated from 70 to 75
            'quality_initiatives_potential': max(0, 35 - quality_score)  # Updated from 30 to 35
        }
        
        # Priority Actions (High Impact, Quick Wins)
        if cert_score < 50:
            recommendations['priority_actions'].append({
                'action': 'Pursue JCI Accreditation',
                'impact': 'High',
                'timeline': '12-18 months',
                'score_increase': '15-25 points',
                'description': 'Joint Commission International accreditation provides the highest certification score boost and international recognition.',
                'steps': [
                    'Conduct gap analysis against JCI standards',
                    'Develop implementation timeline',
                    'Train staff on JCI requirements',
                    'Implement quality management systems',
                    'Schedule JCI survey'
                ]
            })
        
        if quality_score < 15:
            recommendations['priority_actions'].append({
                'action': 'Implement Patient Safety Initiatives',
                'impact': 'High',
                'timeline': '3-6 months',
                'score_increase': '8-12 points',
                'description': 'Patient safety initiatives have the highest weight in quality scoring.',
                'steps': [
                    'Establish patient safety committee',
                    'Implement medication safety protocols',
                    'Deploy infection control measures',
                    'Create incident reporting system',
                    'Conduct regular safety audits'
                ]
            })
        
        # Certification Gap Analysis - INCLUDING ALL MANDATORY ISO STANDARDS
        active_certs = [cert.get('name') for cert in certifications if str(cert.get('status', '')).strip() == 'Active']
        
        # Check for missing key certifications - COMPREHENSIVE LIST INCLUDING ALL MANDATORY ISO STANDARDS
        key_certifications = {
            # MANDATORY ISO STANDARDS (Critical Priority)
            'CAP': {
                'name': 'College of American Pathologists (CAP) Laboratory Accreditation',
                'priority': 'Critical',
                'score_impact': '15 points penalty if missing',
                'description': 'MANDATORY: International laboratory quality standard - highest penalty for missing',
                'prerequisites': ['Laboratory quality management system', 'Proficiency testing', 'Quality control procedures', 'Staff competency assessment']
            },
            'ISO 9001': {
                'name': 'ISO 9001:2015 Quality Management System',
                'priority': 'Critical',
                'score_impact': '8 points penalty if missing',
                'description': 'MANDATORY: International quality management standard - foundation for healthcare quality',
                'prerequisites': ['Quality management system', 'Process documentation', 'Internal audits', 'Management review']
            },
            'ISO 15189': {
                'name': 'ISO 15189:2012 Medical Laboratory Quality and Competence',
                'priority': 'Critical',
                'score_impact': '10 points penalty if missing',
                'description': 'MANDATORY: Specific standard for medical laboratory quality and competence',
                'prerequisites': ['Laboratory quality system', 'Technical competence', 'Quality control', 'Proficiency testing']
            },
            'ISO 27001': {
                'name': 'ISO 27001:2013 Information Security Management',
                'priority': 'Critical',
                'score_impact': '12 points penalty if missing',
                'description': 'MANDATORY: Information security management system - critical for patient data protection',
                'prerequisites': ['Information security policy', 'Risk assessment', 'Security controls', 'Incident management']
            },
            'ISO 45001': {
                'name': 'ISO 45001:2018 Occupational Health and Safety Management',
                'priority': 'Critical',
                'score_impact': '10 points penalty if missing',
                'description': 'MANDATORY: Occupational health and safety management system for healthcare workers',
                'prerequisites': ['OH&S policy', 'Hazard identification', 'Risk assessment', 'Emergency procedures']
            },
            'ISO 13485': {
                'name': 'ISO 13485:2016 Medical Devices Quality Management',
                'priority': 'Critical',
                'score_impact': '8 points penalty if missing',
                'description': 'MANDATORY: Quality management system for medical devices and equipment',
                'prerequisites': ['Medical device quality system', 'Design controls', 'Risk management', 'Post-market surveillance']
            },
            'ISO 14001': {
                'name': 'ISO 14001:2015 Environmental Management System',
                'priority': 'Critical',
                'score_impact': '6 points penalty if missing',
                'description': 'MANDATORY: Environmental management system for sustainable healthcare operations',
                'prerequisites': ['Environmental policy', 'Waste management system', 'Energy efficiency measures', 'Environmental monitoring']
            },
            # RECOMMENDED HIGH-VALUE CERTIFICATIONS
            'JCI': {
                'name': 'Joint Commission International Hospital Accreditation',
                'priority': 'Critical',
                'score_impact': '12 points penalty if missing',
                'description': 'MANDATORY: Global gold standard for healthcare quality and patient safety',
                'prerequisites': ['Strong quality management system', 'Staff training programs', 'Patient safety protocols', 'Performance improvement']
            },
            'NABH': {
                'name': 'National Accreditation Board for Hospitals & Healthcare Providers',
                'priority': 'Critical',
                'score_impact': '15-20 points bonus',
                'description': 'RECOMMENDED: National standard for healthcare quality in India',
                'prerequisites': ['Quality policy', 'Patient rights charter', 'Infection control protocols', 'Clinical governance']
            },
            'NABL': {
                'name': 'National Accreditation Board for Testing and Calibration Laboratories',
                'priority': 'Critical',
                'score_impact': '10 points penalty if missing',
                'description': 'MANDATORY: Laboratory accreditation for diagnostic services',
                'prerequisites': ['Laboratory quality system', 'Calibrated equipment', 'Trained technicians', 'Quality control']
            },
            'ISO 50001': {
                'name': 'ISO 50001:2018 Energy Management System',
                'priority': 'Critical',
                'score_impact': '6 points penalty if missing',
                'description': 'MANDATORY: Energy management system for operational efficiency',
                'prerequisites': ['Energy policy', 'Energy planning', 'Energy monitoring', 'Continuous improvement']
            }
        }
        
        for cert_key, cert_info in key_certifications.items():
            if not any(cert_key.upper() in cert_name.upper() for cert_name in active_certs):
                recommendations['certification_gaps'].append(cert_info)
        
        # Quality Initiatives Recommendations
        if quality_score < 20:
            quality_recommendations = [
                {
                    'initiative': 'Clinical Excellence Program',
                    'category': 'Clinical Excellence',
                    'impact_score': 8,
                    'timeline': '6-12 months',
                    'description': 'Implement evidence-based clinical protocols and outcome tracking',
                    'key_components': ['Clinical pathways', 'Outcome metrics', 'Physician engagement', 'Continuous improvement']
                },
                {
                    'initiative': 'Technology Innovation Initiative',
                    'category': 'Technology Innovation',
                    'impact_score': 6,
                    'timeline': '3-9 months',
                    'description': 'Deploy healthcare technology solutions for improved patient care',
                    'key_components': ['Electronic health records', 'Telemedicine capabilities', 'AI-assisted diagnostics', 'Mobile health apps']
                },
                {
                    'initiative': 'Staff Development Program',
                    'category': 'Staff Development',
                    'impact_score': 5,
                    'timeline': 'Ongoing',
                    'description': 'Comprehensive training and development for healthcare staff',
                    'key_components': ['Continuing education', 'Skills assessment', 'Leadership development', 'Performance management']
                }
            ]
            recommendations['quality_initiatives'].extend(quality_recommendations)
        
        # Operational Improvements
        operational_improvements = []
        
        if len(active_certs) < 3:
            operational_improvements.append({
                'area': 'Quality Management System',
                'recommendation': 'Establish comprehensive quality management framework',
                'benefit': 'Foundation for multiple certifications and improved patient outcomes',
                'implementation': 'Hire quality manager, develop policies, train staff'
            })
        
        if current_total < 80:
            operational_improvements.append({
                'area': 'Performance Monitoring',
                'recommendation': 'Implement real-time quality metrics dashboard',
                'benefit': 'Continuous monitoring and rapid response to quality issues',
                'implementation': 'Deploy analytics platform, define KPIs, train staff on data interpretation'
            })
        
        if branch_info and branch_info.get('has_branches'):
            operational_improvements.append({
                'area': 'Multi-location Quality Standardization',
                'recommendation': 'Standardize quality protocols across all locations',
                'benefit': 'Consistent quality delivery and improved overall scoring',
                'implementation': 'Develop standard operating procedures, conduct cross-location audits'
            })
        
        recommendations['operational_improvements'] = operational_improvements
        
        # Strategic Recommendations
        strategic_recommendations = []
        
        if current_total >= 80:
            strategic_recommendations.append({
                'strategy': 'Excellence Recognition Program',
                'description': 'Pursue national and international healthcare awards',
                'timeline': '12-24 months',
                'expected_outcome': 'Enhanced reputation and market positioning'
            })
        
        if current_total < 70:
            strategic_recommendations.append({
                'strategy': 'Quality Transformation Initiative',
                'description': 'Comprehensive organizational quality transformation',
                'timeline': '18-36 months',
                'expected_outcome': 'Significant improvement in quality scores and patient outcomes'
            })
        
        # Check for international presence potential
        org_name_lower = org_name.lower()
        if any(city in org_name_lower for city in ['chennai', 'bangalore', 'mumbai', 'delhi']):
            strategic_recommendations.append({
                'strategy': 'International Expansion Readiness',
                'description': 'Prepare for international healthcare market entry',
                'timeline': '24-36 months',
                'expected_outcome': 'Access to global healthcare markets and partnerships'
            })
        
        recommendations['strategic_recommendations'] = strategic_recommendations
        
        return recommendations
    
    def calculate_location_adjustment(self, org_name, branch_info):
        """Calculate location-specific quality score adjustments based on branch type and regional factors"""
        if not branch_info or not branch_info.get('has_branches'):
            return 0
        
        org_name_lower = org_name.lower().strip()
        adjustment = 0
        
        # Location-specific adjustments based on branch type and regional healthcare infrastructure
        location_factors = {
            # Indian Cities - Healthcare Infrastructure Quality
            'chennai': {'adjustment': 3, 'reason': 'Major medical hub with advanced infrastructure'},
            'bangalore': {'adjustment': 3, 'reason': 'Leading healthcare destination with research facilities'},
            'mumbai': {'adjustment': 2, 'reason': 'Metropolitan healthcare center with specialized services'},
            'delhi': {'adjustment': 2, 'reason': 'National capital with premier medical institutions'},
            'hyderabad': {'adjustment': 2, 'reason': 'Emerging healthcare hub with modern facilities'},
            'pune': {'adjustment': 1, 'reason': 'Growing healthcare sector with quality infrastructure'},
            'kolkata': {'adjustment': 1, 'reason': 'Established medical center with academic institutions'},
            'gurgaon': {'adjustment': 2, 'reason': 'Modern healthcare infrastructure and corporate hospitals'},
            'noida': {'adjustment': 1, 'reason': 'Developing healthcare sector with quality facilities'},
            'mohali': {'adjustment': 1, 'reason': 'Regional healthcare center with specialized services'},
            
            # International Cities - Global Healthcare Standards
            'rochester': {'adjustment': 5, 'reason': 'World-renowned medical destination (Mayo Clinic)'},
            'cleveland': {'adjustment': 4, 'reason': 'Leading medical center with research excellence'},
            'baltimore': {'adjustment': 4, 'reason': 'Academic medical center hub (Johns Hopkins)'},
            'phoenix': {'adjustment': 2, 'reason': 'Major healthcare destination in Southwest US'},
            'jacksonville': {'adjustment': 2, 'reason': 'Regional medical center with specialized care'},
            'weston': {'adjustment': 3, 'reason': 'Premium healthcare facility in South Florida'},
            'las vegas': {'adjustment': 1, 'reason': 'Growing healthcare sector with modern facilities'},
            'london': {'adjustment': 4, 'reason': 'International healthcare excellence (NHS and private)'},
            'abu dhabi': {'adjustment': 3, 'reason': 'Premium healthcare destination in Middle East'},
            'toronto': {'adjustment': 3, 'reason': 'Leading Canadian healthcare center'},
            'singapore': {'adjustment': 4, 'reason': 'World-class healthcare hub in Asia'},
            'dhahran': {'adjustment': 2, 'reason': 'Specialized healthcare for expatriate community'}
        }
        
        # Check for specific location in organization name
        for location, data in location_factors.items():
            if location in org_name_lower:
                adjustment += data['adjustment']
                break
        
        # Branch type adjustments
        if branch_info.get('search_type') == 'multi_location':
            # Find specific branch information
            available_locations = branch_info.get('available_locations', [])
            for location in available_locations:
                location_name = location.get('name', '').lower()
                if any(word in org_name_lower for word in location_name.split()):
                    # Branch type bonus
                    branch_type = location.get('type', '')
                    if branch_type == 'Flagship':
                        adjustment += 3  # Flagship locations get highest bonus
                    elif branch_type == 'Major Branch':
                        adjustment += 2  # Major branches get moderate bonus
                    elif branch_type == 'International Branch':
                        adjustment += 2  # International branches get moderate bonus
                    elif branch_type == 'Specialty Branch':
                        adjustment += 1  # Specialty branches get small bonus
                    
                    # Specialty-based adjustments
                    specialties = location.get('specialties', [])
                    if 'Transplant' in specialties:
                        adjustment += 2  # Transplant capability is premium
                    if 'Cardiac' in specialties and 'Oncology' in specialties:
                        adjustment += 1  # Multi-specialty excellence
                    
                    break
        
        elif branch_info.get('search_type') == 'specific_location':
            # Bonus for specific location searches (more targeted assessment)
            adjustment += 1
        
        # Regional healthcare infrastructure adjustments
        regions_served = branch_info.get('regions_served', [])
        if 'South India' in regions_served and any(city in org_name_lower for city in ['chennai', 'bangalore', 'hyderabad']):
            adjustment += 1  # South India healthcare excellence bonus
        elif 'North India' in regions_served and any(city in org_name_lower for city in ['delhi', 'gurgaon', 'noida']):
            adjustment += 1  # North India healthcare hub bonus
        elif any(region in regions_served for region in ['Midwest USA', 'Mid-Atlantic USA']):
            adjustment += 2  # US medical excellence regions
        
        # Cap the adjustment to prevent excessive scoring
        return min(adjustment, 8)
    
    def calculate_reputation_bonus(self, org_name):
        """Calculate reputation bonus points based on global rankings (reduced for realistic scoring)"""
        org_name_lower = org_name.lower().strip()
        bonus = 0
        
        # Check if hospital is in our reputation database
        for hospital_key, data in self.global_hospital_rankings.items():
            if hospital_key in org_name_lower:
                # US News ranking bonus (reduced)
                if 'us_news_rank' in data:
                    rank = data['us_news_rank']
                    if rank <= 5:
                        bonus += 3  # Top 5 hospitals get 3 bonus points (reduced from 8)
                    elif rank <= 10:
                        bonus += 2  # Top 10 get 2 bonus points (reduced from 6)
                    elif rank <= 20:
                        bonus += 1  # Top 20 get 1 bonus point (reduced from 4)
                
                # Newsweek World's Best bonus (reduced)
                if 'newsweek_rank' in data:
                    rank = data['newsweek_rank']
                    if rank <= 10:
                        bonus += 2  # Top 10 globally get 2 bonus points (reduced from 5)
                    elif rank <= 25:
                        bonus += 1  # Top 25 get 1 bonus point (reduced from 3)
                
                # Academic medical center bonus (reduced)
                if data.get('academic', False):
                    bonus += 1  # Reduced from 2
                
                # Research intensive bonus (reduced)
                if data.get('research_intensive', False):
                    bonus += 1  # Reduced from 2
                
                # Regional leader bonus (reduced)
                if data.get('regional_leader', False) and 'us_news_rank' not in data:
                    bonus += 0.5  # Reduced from 1
                
                break
        
        return min(bonus, 5)  # Cap at 5 bonus points (reduced from 10)
    
    def calculate_missing_certification_penalty(self, certifications):
        """Calculate penalty for missing key certifications"""
        penalty = 0
        
        # Check for key certifications using 'name' field instead of 'type'
        cert_names = [cert.get('name', '') for cert in certifications if cert['status'] == 'Active']
        
        # Penalty for missing NABH (for Indian hospitals)
        if 'NABH' not in cert_names:
            penalty += 3
        
        # Penalty for missing JCI (for international recognition)
        if 'JCI' not in cert_names:
            penalty += 2
        
        # Penalty for missing NABL (for diagnostic services)
        if 'NABL' not in cert_names:
            penalty += 1
        
        # Penalty for having very few certifications
        if len(cert_names) < 3:
            penalty += 2
        
        return penalty
    
    def get_reputation_multiplier(self, org_name):
        """Get reputation multiplier for the hospital"""
        org_name_lower = org_name.lower().strip()
        
        # Check if hospital is in our reputation database
        for hospital_key, data in self.global_hospital_rankings.items():
            if hospital_key in org_name_lower:
                # US News ranking multiplier
                if 'us_news_rank' in data:
                    rank = data['us_news_rank']
                    if rank <= 5:
                        return self.reputation_multipliers['us_news_top_5']
                    elif rank <= 10:
                        return self.reputation_multipliers['us_news_top_10']
                    elif rank <= 20:
                        return self.reputation_multipliers['us_news_top_20']
                
                # Newsweek World's Best multiplier
                if 'newsweek_rank' in data and data['newsweek_rank'] <= 25:
                    return self.reputation_multipliers['newsweek_world_best']
                
                # Academic medical center multiplier
                if data.get('academic', False):
                    return self.reputation_multipliers['academic_medical_center']
                
                break
        
        return 1.0  # No multiplier for unknown hospitals
    
    def calculate_organization_rankings(self, current_org_name, current_score):
        """Calculate rankings and percentiles for the current organization against all others in database"""
        try:
            # Get all organizations from unified database
            all_orgs = []
            
            # Calculate scores for all organizations in the database
            for org in self.unified_database:
                # Skip if org is not a dictionary or is None
                if not isinstance(org, dict) or org is None:
                    continue
                
                # Safely get organization name
                org_name = org.get('name', '')
                if not org_name:
                    continue
                
                # Skip if it's the current organization
                if org_name.lower() == current_org_name.lower():
                    continue
                
                # Get certifications from unified database
                certifications = []
                org_certifications = org.get('certifications', [])
                if isinstance(org_certifications, list):
                    for cert in org_certifications:
                        if isinstance(cert, dict):
                            certifications.append({
                                'name': cert.get('name', ''),
                                'status': cert.get('status', 'Active'),
                                'score_impact': cert.get('score_impact', 0)
                            })
                
                # Calculate basic quality initiatives (simplified for ranking)
                initiatives = []
                quality_indicators = org.get('quality_indicators', {})
                if isinstance(quality_indicators, dict):
                    if quality_indicators.get('jci_accredited'):
                        initiatives.append({'name': 'JCI Quality Standards', 'score_impact': 5})
                    if quality_indicators.get('nabh_accredited'):
                        initiatives.append({'name': 'NABH Quality Standards', 'score_impact': 3})
                
                # Calculate score for this organization
                try:
                    score_data = self.calculate_quality_score(certifications, initiatives, org_name, None, [])
                    
                    all_orgs.append({
                        'name': org_name,
                        'total_score': score_data.get('total_score', 0),
                        'country': org.get('country', 'Unknown'),
                        'region': org.get('region', 'Unknown'),
                        'hospital_type': org.get('hospital_type', 'Hospital'),
                        'certifications': len(certifications),
                        'certification_score': score_data.get('certification_score', 0),
                        'quality_score': score_data.get('certification_score', 0),
                        'score_breakdown': score_data
                    })
                except Exception as e:
                    # Skip organizations that cause scoring errors
                    print(f"Skipping organization {org_name} due to scoring error: {str(e)}")
                    continue
            
            # Add current organization to the list for proper ranking
            all_orgs.append({
                'name': current_org_name,
                'total_score': current_score,
                'country': 'Current',
                'region': 'Current',
                'hospital_type': 'Current',
                'certifications': 0,
                'certification_score': current_score,
                'quality_score': current_score,
                'score_breakdown': {}
            })
            
            # Sort organizations by total score (descending)
            all_orgs.sort(key=lambda x: x['total_score'], reverse=True)
            
            # Find the rank of the current organization
            rank = 1
            for i, org in enumerate(all_orgs):
                if org['name'] == current_org_name:
                    rank = i + 1
                    break
            
            # Remove current organization from the list for other calculations
            all_orgs = [org for org in all_orgs if org['name'] != current_org_name]
            
            # Calculate percentile
            total_orgs = len(all_orgs) + 1  # +1 for current organization
            percentile = ((total_orgs - rank) / total_orgs) * 100
            
            # Category-specific rankings
            category_rankings = self.calculate_category_rankings(all_orgs, current_score, current_org_name)
            
            return {
                'overall_rank': rank,
                'total_organizations': total_orgs,
                'percentile': percentile,
                'category_rankings': category_rankings,
                'top_performers': all_orgs[:5],  # Top 5 organizations
                'similar_performers': self.get_similar_performers(all_orgs, current_score),
                'top_performers_benchmark': self.get_top_performers_benchmark(all_orgs, current_org_name, current_score),
                'regional_ranking': self.get_regional_ranking(all_orgs, current_org_name, current_score)
            }
            
        except Exception as e:
            # Log error silently without displaying to user
            print(f"Error calculating rankings: {str(e)}")
            # Return a default structure to prevent crashes
            return {
                'overall_rank': 1,
                'total_organizations': 1,
                'percentile': 100.0,
                'category_rankings': {},
                'top_performers': [],
                'similar_performers': [],
                'top_performers_benchmark': {'performers_above': [], 'performers_below': []},
                'regional_ranking': {}
            }
    
    def calculate_category_rankings(self, all_orgs, current_score, current_org_name):
        """Calculate rankings for specific categories"""
        try:
            # Calculate current organization's component scores
            current_org_info = self.search_organization_info(current_org_name)
            
            # Handle case where search_organization_info returns None or invalid data
            if not current_org_info or not isinstance(current_org_info, dict):
                print(f"Warning: No valid organization info found for {current_org_name}")
                return {}
            
            # Safely get score_breakdown with proper null checking
            current_breakdown = current_org_info.get('score_breakdown', {})
            
            if not current_breakdown or not isinstance(current_breakdown, dict):
                print(f"Warning: No valid score breakdown found for {current_org_name}")
                return {}
            
            # Define categories with distinct scoring logic to avoid duplication
            categories = {
                'quality': {
                    'score_field': 'certification_score',
                    'weight': 1.0,
                    'bonus_field': None,
                    'bonus_weight': 0
                },
                'certifications': {
                    'score_field': 'certification_score',
                    'weight': 1.0,
                    'bonus_field': None,
                    'bonus_weight': 0
                }
            }
            
            category_rankings = {}
            
            for category, config in categories.items():
                # Calculate category-specific score
                base_score = current_breakdown.get(config['score_field'], 0)
                bonus_score = current_breakdown.get(config['bonus_field'], 0) if config['bonus_field'] else 0
                current_category_score = (base_score * config['weight']) + (bonus_score * config['bonus_weight'])
                
                # Calculate scores for all organizations in this category
                category_scores = []
                for org in all_orgs:
                    # Ensure score_breakdown exists and is not None
                    org_breakdown = org.get('score_breakdown')
                    if not org_breakdown or not isinstance(org_breakdown, dict):
                        # Skip organizations without proper score breakdown
                        continue
                    
                    org_base = org_breakdown.get(config['score_field'], 0)
                    org_bonus = org_breakdown.get(config['bonus_field'], 0) if config['bonus_field'] else 0
                    org_category_score = (org_base * config['weight']) + (org_bonus * config['bonus_weight'])
                    category_scores.append(org_category_score)
                
                # Only calculate rankings if we have valid scores
                if not category_scores:
                    continue
                
                # Count organizations with lower scores in this category
                lower_count = sum(1 for score in category_scores if score < current_category_score)
                
                # Calculate ranking and percentile
                rank = len(category_scores) - lower_count
                percentile = (lower_count / len(category_scores)) * 100 if category_scores else 0
                
                category_rankings[category] = {
                    'rank': rank,
                    'percentile': percentile,
                    'score': current_category_score
                }
            
            return category_rankings
            
        except Exception as e:
            # Log the error for debugging but return empty rankings to prevent crashes
            print(f"Error in calculate_category_rankings: {str(e)}")
            return {}
    
    def get_similar_performers(self, all_orgs, current_score):
        """Get organizations with similar performance levels"""
        # Find organizations within ¬±5 points of current score
        similar = []
        for org in all_orgs:
            if abs(org['total_score'] - current_score) <= 5:
                similar.append(org)
        
        return similar[:10]  # Return top 10 similar performers
    
    def get_top_performers_benchmark(self, all_orgs, current_org_name, current_score):
        """Get top 20 performers above and below the current organization's rank"""
        try:
            # Sort organizations by total score (descending)
            all_orgs_sorted = sorted(all_orgs, key=lambda x: x['total_score'], reverse=True)
            
            # Find current organization's position in the sorted list
            current_position = None
            for i, org in enumerate(all_orgs_sorted):
                if org['total_score'] <= current_score:
                    current_position = i
                    break
            
            if current_position is None:
                current_position = len(all_orgs_sorted)  # Current org would be at the end
            
            # Get top 20 performers above current organization
            performers_above = []
            start_above = max(0, current_position - 20)
            end_above = current_position
            
            for i in range(start_above, end_above):
                if i < len(all_orgs_sorted):
                    org = all_orgs_sorted[i].copy()
                    org['rank_position'] = i + 1
                    org['score_difference'] = org['total_score'] - current_score
                    performers_above.append(org)
            
            # Get top 20 performers below current organization
            performers_below = []
            start_below = current_position
            end_below = min(len(all_orgs_sorted), current_position + 20)
            
            for i in range(start_below, end_below):
                if i < len(all_orgs_sorted):
                    org = all_orgs_sorted[i].copy()
                    org['rank_position'] = i + 1
                    org['score_difference'] = org['total_score'] - current_score
                    performers_below.append(org)
            
            return {
                'performers_above': performers_above,
                'performers_below': performers_below,
                'current_position': current_position + 1,  # +1 for 1-based ranking
                'total_organizations': len(all_orgs_sorted) + 1  # +1 for current org
            }
            
        except Exception as e:
            print(f"Error in get_top_performers_benchmark: {str(e)}")
            return {
                'performers_above': [],
                'performers_below': [],
                'current_position': 0,
                'total_organizations': 0
            }
    
    def get_regional_ranking(self, all_orgs, current_org_name, current_score):
        """Get ranking within the same region"""
        try:
            # Find current organization's region
            current_org_data = None
            for org in self.unified_database:
                # Skip if org is not a dictionary
                if not isinstance(org, dict):
                    continue
                if org.get('name', '').lower() == current_org_name.lower():
                    current_org_data = org
                    break
            
            if not current_org_data:
                return None
            
            current_region = current_org_data.get('region', 'Unknown')
            
            # Filter organizations in the same region
            regional_orgs = [org for org in all_orgs if org.get('region') == current_region]
            
            if not regional_orgs:
                return None
            
            # Sort by score
            regional_orgs.sort(key=lambda x: x['total_score'], reverse=True)
            
            # Find ranking with proper tie handling
            rank = 1
            organizations_with_higher_scores = 0
            
            for org in regional_orgs:
                if org['total_score'] > current_score:
                    organizations_with_higher_scores += 1
                else:
                    break  # Since list is sorted in descending order
            
            rank = organizations_with_higher_scores + 1
            
            percentile = ((len(regional_orgs) + 1 - rank) / (len(regional_orgs) + 1)) * 100
            
            return {
                'region': current_region,
                'rank': rank,
                'total_in_region': len(regional_orgs) + 1,
                'percentile': percentile,
                'top_in_region': regional_orgs[:3]
            }
            
        except Exception as e:
            return None
    
    def _get_iso_score_impact(self, iso_standard):
        """Get the score impact for different ISO standards in healthcare"""
        iso_score_mapping = {
            'ISO 9001:2015': 12,  # Quality Management System - high impact
            'ISO 9001': 12,
            'ISO 13485:2016': 15,  # Medical Devices - highest impact for healthcare
            'ISO 13485': 15,
            'ISO 27001:2013': 10,  # Information Security - important for healthcare
            'ISO 27001': 10,
            'ISO 45001:2018': 8,   # Occupational Health & Safety
            'ISO 45001': 8,
            'ISO 14001:2015': 6,   # Environmental Management
            'ISO 14001': 6,
            'ISO 15189:2012': 12,  # Medical Laboratories
            'ISO 15189': 12,
            'ISO 22000:2018': 5,   # Food Safety
            'ISO 22000': 5,
            'ISO 50001:2018': 4,   # Energy Management
            'ISO 50001': 4,
            'ISO 27799:2016': 9,   # Health Informatics Security
            'ISO 27799': 9,
            'ISO 14155:2020': 8    # Clinical Investigation
        }
        
        # Extract base standard if version is included
        base_standard = iso_standard.split(':')[0]
        
        return iso_score_mapping.get(iso_standard, iso_score_mapping.get(base_standard, 5))
    
    def _get_iso_description(self, iso_standard):
        """Get description for a specific ISO standard"""
        iso_descriptions = {
            'ISO 9001': 'Quality Management Systems - Ensures consistent quality in products and services',
            'ISO 13485': 'Medical Devices Quality Management - Specific to medical device manufacturing and services',
            'ISO 14001': 'Environmental Management Systems - Demonstrates environmental responsibility',
            'ISO 45001': 'Occupational Health and Safety Management - Ensures workplace safety standards',
            'ISO 27001': 'Information Security Management - Protects sensitive patient and organizational data',
            'ISO 15189': 'Medical Laboratories - Quality and competence requirements for medical testing',
            'ISO 17025': 'Testing and Calibration Laboratories - General requirements for laboratory competence',
            'ISO 22000': 'Food Safety Management - Ensures food safety in healthcare facilities',
            'ISO 50001': 'Energy Management Systems - Demonstrates energy efficiency and sustainability',
            'ISO 37001': 'Anti-bribery Management Systems - Prevents and addresses bribery and corruption',
            'ISO 27799': 'Health Informatics Security - Specific security requirements for health information',
            'ISO 14155': 'Clinical Investigation - Good clinical practice for medical device studies'
        }
        # Extract base standard if version is included
        base_standard = iso_standard.split(':')[0]
        return iso_descriptions.get(iso_standard, iso_descriptions.get(base_standard, 'International standard for quality and management systems'))
    
    def _get_iso_relevance(self, iso_standard):
        """Get relevance level for healthcare organizations"""
        iso_relevance = {
            'ISO 9001': 'High - Core quality management',
            'ISO 13485': 'Very High - Medical device specific',
            'ISO 14001': 'Critical - Environmental compliance',
            'ISO 45001': 'High - Patient and staff safety',
            'ISO 27001': 'High - Patient data protection',
            'ISO 15189': 'Very High - Laboratory services',
            'ISO 17025': 'High - Testing accuracy',
            'ISO 22000': 'Medium - Food service safety',
            'ISO 50001': 'Critical - Energy management compliance',
            'ISO 37001': 'Medium - Governance and ethics',
            'ISO 27799': 'Very High - Health data security',
            'ISO 14155': 'High - Clinical research quality'
        }
        # Extract base standard if version is included
        base_standard = iso_standard.split(':')[0]
        return iso_relevance.get(iso_standard, iso_relevance.get(base_standard, 'Medium - General quality standard'))
    
    def find_similar_organizations(self, org_name, org_location="", org_type="Hospital"):
        """Find similar organizations in the same region using unified database with their quality scores"""
        similar_orgs = []
        
        # Determine the country/region for the searched organization
        search_region = self.determine_organization_region(org_name, org_location)
        
        # Load unified database if not already loaded
        if not hasattr(self, 'unified_database') or not self.unified_database:
            self.unified_database = self.load_unified_database()
        
        # Filter organizations from the same region using unified database
        region_orgs = []
        for org in self.unified_database:
            org_country = org.get('country', '').lower()
            org_region = org.get('region', '').lower()
            
            # Match by country or region
            if (org_country == search_region.lower() or 
                org_region == search_region.lower() or
                self._is_same_region(org_country, search_region.lower())):
                
                # Skip the searched organization itself
                if org['name'].lower() != org_name.lower():
                    # Create location string
                    location_parts = []
                    if org.get('city'):
                        location_parts.append(org['city'])
                    if org.get('state'):
                        location_parts.append(org['state'])
                    if org.get('country'):
                        location_parts.append(org['country'])
                    
                    org_location_str = ', '.join(location_parts) if location_parts else 'Unknown'
                    
                    # Determine organization type based on certifications
                    org_type_determined = 'Healthcare Organization'
                    certifications = org.get('certifications', [])
                    if any('JCI' in cert.get('name', '') for cert in certifications):
                        org_type_determined = 'JCI Accredited Hospital'
                    elif any('NABH' in cert.get('name', '') for cert in certifications):
                        org_type_determined = 'NABH Accredited Hospital'
                    elif any('CAP' in cert.get('name', '') for cert in certifications):
                        org_type_determined = 'CAP Accredited Laboratory'
                    
                    region_orgs.append({
                        'name': org['name'],
                        'location': org_location_str,
                        'type': org_type_determined,
                        'unified_data': org
                    })
        
        # Limit to 8 organizations for comparison
        region_orgs = region_orgs[:8]
        
        # Generate quality scores for similar organizations
        for org in region_orgs:
            org_info = self.search_organization_info(org['name'])
            if org_info:
                similar_orgs.append({
                    'name': org['name'],
                    'location': org['location'],
                    'type': org['type'],
                    'total_score': org_info['total_score'],
                    'score_breakdown': org_info['score_breakdown'],
                    'certifications': org_info['certifications'],
                    'quality_initiatives': org_info['quality_initiatives']
                })
        
        # Sort by score (highest first)
        similar_orgs.sort(key=lambda x: x['total_score'], reverse=True)
        
        return similar_orgs
    
    def _is_same_region(self, org_country, search_region):
        """Helper method to determine if an organization's country matches the search region"""
        # Country to region mapping
        country_region_map = {
            'india': 'india',
            'united states': 'united states',
            'usa': 'united states',
            'us': 'united states',
            'united kingdom': 'united kingdom',
            'uk': 'united kingdom',
            'singapore': 'singapore',
            'canada': 'canada',
            'australia': 'australia'
        }
        
        # Normalize country name
        normalized_country = org_country.lower().strip()
        
        # Direct match
        if normalized_country == search_region:
            return True
        
        # Check mapped regions
        mapped_region = country_region_map.get(normalized_country)
        if mapped_region and mapped_region == search_region:
            return True
        
        return False
    
    def determine_organization_region(self, org_name, org_location=""):
        """Determine the region/country of an organization based on name and location"""
        org_name_lower = org_name.lower()
        org_location_lower = org_location.lower()
        
        # Location-based detection (prioritize location over name patterns)
        if any(loc in org_location_lower for loc in ['india', 'delhi', 'mumbai', 'bangalore', 'chennai', 'hyderabad', 'pune', 'kolkata', 'ahmedabad', 'surat', 'jaipur', 'lucknow', 'kanpur', 'nagpur', 'indore', 'thane', 'bhopal', 'visakhapatnam', 'pimpri', 'patna', 'vadodara', 'ghaziabad', 'ludhiana', 'agra', 'nashik', 'faridabad', 'meerut', 'rajkot', 'kalyan', 'vasai', 'varanasi', 'srinagar', 'aurangabad', 'dhanbad', 'amritsar', 'navi mumbai', 'allahabad', 'ranchi', 'howrah', 'coimbatore', 'jabalpur', 'gwalior', 'vijayawada', 'jodhpur', 'madurai', 'raipur', 'kota', 'guwahati', 'chandigarh', 'solapur', 'hubli', 'tiruchirappalli', 'bareilly', 'mysore', 'tiruppur', 'gurgaon', 'aligarh', 'jalandhar', 'bhubaneswar', 'salem', 'warangal', 'guntur', 'bhiwandi', 'saharanpur', 'gorakhpur', 'bikaner', 'amravati', 'noida', 'jamshedpur', 'bhilai', 'cuttack', 'firozabad', 'kochi', 'nellore', 'bhavnagar', 'dehradun', 'durgapur', 'asansol', 'rourkela', 'nanded', 'kolhapur', 'ajmer', 'akola', 'gulbarga', 'jamnagar', 'ujjain', 'loni', 'siliguri', 'jhansi', 'ulhasnagar', 'jammu', 'sangli', 'mangalore', 'erode', 'belgaum', 'ambattur', 'tirunelveli', 'malegaon', 'gaya', 'jalgaon', 'udaipur', 'maheshtala']):
            return 'india'
        elif any(loc in org_location_lower for loc in ['usa', 'united states', 'america', 'us', 'california', 'texas', 'florida', 'new york', 'pennsylvania', 'illinois', 'ohio', 'georgia', 'north carolina', 'michigan', 'new jersey', 'virginia', 'washington', 'arizona', 'massachusetts', 'tennessee', 'indiana', 'maryland', 'missouri', 'wisconsin', 'colorado', 'minnesota', 'south carolina', 'alabama', 'louisiana', 'kentucky', 'oregon', 'oklahoma', 'connecticut', 'utah', 'iowa', 'nevada', 'arkansas', 'mississippi', 'kansas', 'new mexico', 'nebraska', 'west virginia', 'idaho', 'hawaii', 'new hampshire', 'maine', 'montana', 'rhode island', 'delaware', 'south dakota', 'north dakota', 'alaska', 'vermont', 'wyoming']):
            return 'united states'
        elif any(loc in org_location_lower for loc in ['uk', 'united kingdom', 'england', 'london', 'scotland', 'wales', 'northern ireland', 'birmingham', 'manchester', 'glasgow', 'liverpool', 'bristol', 'sheffield', 'leeds', 'edinburgh', 'leicester', 'coventry', 'bradford', 'cardiff', 'belfast', 'nottingham', 'kingston upon hull', 'newcastle', 'stoke', 'southampton', 'derby', 'portsmouth', 'brighton', 'plymouth', 'northampton', 'reading', 'luton', 'wolverhampton', 'bolton', 'bournemouth', 'norwich', 'swindon', 'swansea', 'southend', 'middlesbrough', 'peterborough', 'huddersfield', 'york', 'poole', 'preston', 'stockport', 'dundee', 'milton keynes', 'aberdeen', 'telford', 'watford', 'ipswich', 'oxford', 'warrington', 'slough', 'exeter', 'cheltenham', 'gloucester', 'saint helens', 'sutton coldfield', 'cambridge', 'blackpool', 'oldham', 'maidstone', 'basildon', 'worthing', 'chelmsford', 'colchester', 'crawley', 'gillingham', 'solihull', 'taunton', 'shrewsbury', 'farnborough', 'royal leamington spa', 'stevenage', 'sale', 'wigan', 'rotherham', 'chesterfield', 'worcester', 'hemel hempstead', 'redditch', 'lincoln', 'carlisle', 'eastbourne', 'scunthorpe', 'birkenhead', 'mansfield', 'ashford', 'rugby', 'high wycombe', 'st albans', 'hastings', 'folkestone', 'bangor', 'ayr', 'lancaster', 'salisbury', 'chester', 'bath', 'kidderminster', 'barnsley', 'grimsby', 'bedford', 'harrogate', 'royal tunbridge wells', 'macclesfield', 'rhondda', 'burton upon trent', 'cannock', 'lowestoft', 'welwyn garden city', 'barrow in furness', 'newport', 'gateshead', 'eastleigh', 'tamworth', 'washington', 'carlisle', 'nuneaton', 'loughborough', 'ellesmere port', 'hereford', 'margate', 'arnold', 'dewsbury', 'beverley', 'crewe', 'aldershot', 'walkden', 'carlisle', 'smethwick', 'gosport', 'fareham', 'bletchley', 'maidenhead', 'tonbridge', 'barry', 'littlehampton', 'royal leamington spa', 'weston super mare', 'burton upon trent', 'yeovil', 'kidderminster', 'st helens', 'weymouth', 'farnham', 'burnley', 'gravesend', 'bridgwater', 'staines', 'grays', 'stafford', 'newbury', 'spalding', 'lisburn', 'chester le street', 'stirling', 'fleet', 'llanelli', 'bridgend', 'pontefract', 'letchworth', 'nelson', 'wigston', 'castleford', 'deal', 'st neots', 'warwick', 'buxton', 'bognor regis', 'christchurch', 'rugby', 'canvey island', 'leigh', 'great yarmouth', 'rhyl', 'barry', 'kirkby', 'whitley bay', 'prescot', 'runcorn', 'nelson', 'accrington', 'morley', 'jarrow', 'blyth', 'rowley regis', 'smethwick', 'willenhall', 'walsall', 'west bromwich', 'bilston', 'tipton', 'wednesbury', 'oldbury', 'halesowen', 'stourbridge', 'kidderminster', 'redditch', 'bromsgrove', 'droitwich', 'evesham', 'malvern', 'pershore', 'tenbury wells', 'bewdley', 'stourport on severn']):
            return 'united kingdom'
        elif 'singapore' in org_location_lower:
            return 'singapore'
        elif any(loc in org_location_lower for loc in ['canada', 'toronto', 'vancouver', 'montreal', 'calgary', 'ottawa', 'edmonton', 'mississauga', 'winnipeg', 'quebec city', 'hamilton', 'brampton', 'surrey', 'laval', 'halifax', 'london', 'markham', 'vaughan', 'gatineau', 'saskatoon', 'longueuil', 'burnaby', 'regina', 'richmond', 'richmond hill', 'oakville', 'burlington', 'greater sudbury', 'sherbrooke', 'oshawa', 'saguenay', 'l√©vis', 'barrie', 'abbotsford', 'coquitlam', 'st. catharines', 'trois-rivi√®res', 'guelph', 'cambridge', 'whitby', 'kelowna', 'kingston', 'ajax', 'thunder bay', 'waterloo', 'st. john\'s', 'langley', 'chatham-kent', 'delta', 'red deer', 'kamloops', 'brantford', 'cape breton', 'lethbridge', 'saint-jean-sur-richelieu', 'clarington', 'pickering', 'nanaimo', 'sudbury', 'north vancouver', 'brossard', 'repentigny', 'newmarket', 'chilliwack', 'white rock', 'maple ridge', 'peterborough', 'kawartha lakes', 'prince george', 'sault ste. marie', 'sarnia', 'wood buffalo', 'new westminster', 'ch√¢teauguay', 'saint-j√©r√¥me', 'drummondville', 'saint john', 'caledon', 'st. albert', 'granby', 'medicine hat', 'grande prairie', 'st. thomas', 'airdrie', 'halton hills', 'saint-hyacinthe', 'lac-brome', 'charlottetown', 'fredericton', 'blainville', 'aurora', 'welland', 'north bay', 'beloeil', 'belleville', 'mirabel', 'shawinigan', 'dollard-des-ormeaux', 'brandon', 'rimouski', 'saint-eustache', 'saint-bruno-de-montarville', 'mascouche', 'terrebonne', 'milton', 'collingwood', 'cornwall', 'victoriaville', 'georgina', 'vernon', 'duncan', 'saint-constant', 'batoche']):
            return 'canada'
        elif any(loc in org_location_lower for loc in ['australia', 'melbourne', 'sydney', 'brisbane', 'perth', 'adelaide', 'gold coast', 'newcastle', 'canberra', 'sunshine coast', 'wollongong', 'hobart', 'geelong', 'townsville', 'cairns', 'darwin', 'toowoomba', 'ballarat', 'bendigo', 'albury', 'launceston', 'mackay', 'rockhampton', 'bunbury', 'bundaberg', 'coffs harbour', 'wagga wagga', 'hervey bay', 'mildura', 'shepparton', 'port macquarie', 'gladstone', 'tamworth', 'traralgon', 'orange', 'dubbo', 'geraldton', 'bowral', 'bathurst', 'nowra', 'warrnambool', 'kalgoorlie', 'devonport', 'mount gambier', 'armidale', 'lismore', 'nelson bay', 'alice springs', 'taree', 'goulburn', 'hawkesbury', 'sunbury', 'moe', 'bacchus marsh', 'melton', 'pakenham', 'warragul', 'drouin', 'cranbourne', 'berwick', 'frankston', 'dandenong', 'ringwood', 'box hill', 'blackburn', 'camberwell', 'hawthorn', 'richmond', 'south yarra', 'st kilda', 'brighton', 'sandringham', 'mentone', 'mordialloc', 'chelsea', 'bonbeach', 'carrum', 'seaford', 'frankston south', 'langwarrin', 'skye', 'safety beach', 'dromana', 'rosebud', 'rye', 'sorrento', 'portsea', 'blairgowrie', 'mount martha', 'mornington', 'mount eliza', 'baxter', 'somerville', 'tyabb', 'hastings', 'bittern', 'crib point', 'stony point', 'french island', 'phillip island', 'cowes', 'rhyll', 'san remo', 'bass', 'corinella', 'grantville', 'coronet bay', 'kilcunda', 'wonthaggi', 'inverloch', 'venus bay', 'tarwin lower', 'fish creek', 'foster', 'welshpool', 'port franklin', 'sandy point', 'waratah bay', 'walkerville', 'port albert', 'yarram', 'alberton', 'port welshpool', 'devon north', 'woodside', 'gormandale', 'rosedale', 'sale', 'longford', 'stratford', 'bairnsdale', 'lindenow', 'bruthen', 'tambo upper', 'swan reach', 'metung', 'lakes entrance', 'lake tyers', 'nowa nowa', 'orbost', 'marlo', 'cape conran', 'bemm river', 'cann river', 'genoa', 'mallacoota']):
            return 'australia'
        
        # Name-based detection (fallback if location is not clear)
        # US hospitals
        us_indicators = ['mayo clinic', 'cleveland clinic', 'johns hopkins', 'massachusetts general', 
                        'cedars-sinai', 'newyork-presbyterian', 'ucsf', 'houston methodist']
        if any(indicator in org_name_lower for indicator in us_indicators):
            return 'united states'
        
        # Indian hospitals
        indian_indicators = ['apollo', 'fortis', 'aiims', 'yashoda', 'manipal', 'max healthcare', 
                           'narayana', 'medanta']
        if any(indicator in org_name_lower for indicator in indian_indicators):
            return 'india'
        
        # UK hospitals
        uk_indicators = ['great ormond', 'royal marsden', 'moorfields', 'king\'s college', 'imperial college']
        if any(indicator in org_name_lower for indicator in uk_indicators):
            return 'united kingdom'
        
        # Singapore hospitals
        singapore_indicators = ['singapore general', 'national university hospital', 'tan tock seng', 'mount elizabeth']
        if any(indicator in org_name_lower for indicator in singapore_indicators):
            return 'singapore'
        
        # Default to India if no clear location is found (since the issue was about Indian organizations)
        return 'india'
    
    def get_nearby_regions(self, region):
        """Get nearby regions for expanded comparison - restricted for regional specificity"""
        region_proximity = {
            'united states': ['canada'],
            'canada': ['united states'],
            'united kingdom': ['ireland', 'netherlands'],
            # Removed nearby regions for India to ensure strict regional comparison
            'india': [],  # Indian hospitals should only be compared with other Indian hospitals
            'singapore': ['australia'],  # Removed India to maintain regional specificity
            'australia': ['singapore']  # Removed India to maintain regional specificity
        }
        
        return region_proximity.get(region.lower(), [])
    
    def calculate_detailed_percentile_rankings(self, org_name, org_location=""):
        """Calculate comprehensive percentile rankings for healthcare organizations"""
        # Load unified database if not already loaded
        if not hasattr(self, 'unified_database') or not self.unified_database:
            self.unified_database = self.load_unified_database()
        
        # Calculate scores for all organizations
        all_scores = []
        org_data = {}
        
        for org in self.unified_database:
            try:
                # Calculate score for each organization
                # Get certifications and initiatives for this organization
                certifications = org.get('certifications', [])
                initiatives = org.get('quality_initiatives', [])
                score_data = self.calculate_quality_score(certifications, initiatives, org['name'], None, [])
                total_score = score_data.get('total_score', 0)
                
                org_info = {
                    'name': org['name'],
                    'location': f"{org.get('city', '')}, {org.get('country', '')}".strip(', '),
                    'country': org.get('country', ''),
                    'hospital_type': org.get('hospital_type', 'Hospital'),
                    'jci_accredited': any('JCI' in cert for cert in org.get('certifications', [])),
                    'total_score': total_score,
                    'score_data': score_data
                }
                
                all_scores.append(org_info)
                
                # Store data for the searched organization
                if org['name'].lower() == org_name.lower():
                    org_data = org_info
                    
            except Exception as e:
                continue
        
        # Sort by total score (descending)
        all_scores.sort(key=lambda x: x['total_score'], reverse=True)
        
        # Find the searched organization's position
        org_rank = None
        for i, org in enumerate(all_scores):
            if org['name'].lower() == org_name.lower():
                org_rank = i + 1
                break
        
        if org_rank is None:
            return None
        
        total_orgs = len(all_scores)
        overall_percentile = ((total_orgs - org_rank + 1) / total_orgs) * 100
        
        # Calculate regional percentile
        org_country = org_data.get('country', '').lower()
        regional_orgs = [org for org in all_scores if org['country'].lower() == org_country]
        regional_rank = None
        for i, org in enumerate(regional_orgs):
            if org['name'].lower() == org_name.lower():
                regional_rank = i + 1
                break
        
        regional_percentile = 0
        if regional_rank and len(regional_orgs) > 0:
            regional_percentile = ((len(regional_orgs) - regional_rank + 1) / len(regional_orgs)) * 100
        
        # Calculate hospital type percentile
        org_type = org_data.get('hospital_type', 'Hospital')
        type_orgs = [org for org in all_scores if org['hospital_type'] == org_type]
        type_rank = None
        for i, org in enumerate(type_orgs):
            if org['name'].lower() == org_name.lower():
                type_rank = i + 1
                break
        
        type_percentile = 0
        if type_rank and len(type_orgs) > 0:
            type_percentile = ((len(type_orgs) - type_rank + 1) / len(type_orgs)) * 100
        
        # Calculate JCI percentile (if applicable)
        jci_percentile = 0
        if org_data.get('jci_accredited', False):
            jci_orgs = [org for org in all_scores if org['jci_accredited']]
            jci_rank = None
            for i, org in enumerate(jci_orgs):
                if org['name'].lower() == org_name.lower():
                    jci_rank = i + 1
                    break
            
            if jci_rank and len(jci_orgs) > 0:
                jci_percentile = ((len(jci_orgs) - jci_rank + 1) / len(jci_orgs)) * 100
        
        # Score tier analysis
        org_score = org_data.get('total_score', 0)
        score_tiers = {
            'Excellent (80-100)': [org for org in all_scores if org['total_score'] >= 80],
            'Good (60-79)': [org for org in all_scores if 60 <= org['total_score'] < 80],
            'Average (40-59)': [org for org in all_scores if 40 <= org['total_score'] < 60],
            'Below Average (<40)': [org for org in all_scores if org['total_score'] < 40]
        }
        
        current_tier = None
        tier_percentile = 0
        for tier_name, tier_orgs in score_tiers.items():
            if any(org['name'].lower() == org_name.lower() for org in tier_orgs):
                current_tier = tier_name
                tier_rank = None
                for i, org in enumerate(tier_orgs):
                    if org['name'].lower() == org_name.lower():
                        tier_rank = i + 1
                        break
                
                if tier_rank and len(tier_orgs) > 0:
                    tier_percentile = ((len(tier_orgs) - tier_rank + 1) / len(tier_orgs)) * 100
                break
        
        # Performance insights
        top_10_percent = int(total_orgs * 0.1)
        top_25_percent = int(total_orgs * 0.25)
        
        performance_level = "Below Average"
        if org_rank <= top_10_percent:
            performance_level = "Top 10%"
        elif org_rank <= top_25_percent:
            performance_level = "Top 25%"
        elif overall_percentile >= 50:
            performance_level = "Above Average"
        
        # Top performers in each category
        top_performers = {
            'Overall': all_scores[:5],
            'Regional': regional_orgs[:3] if len(regional_orgs) >= 3 else regional_orgs,
            'Hospital Type': type_orgs[:3] if len(type_orgs) >= 3 else type_orgs
        }
        
        # Similar performers (within 5 percentile points)
        similar_performers = []
        target_percentile_range = (overall_percentile - 5, overall_percentile + 5)
        
        for org in all_scores:
            if org['name'].lower() != org_name.lower():
                org_pos = all_scores.index(org) + 1
                org_percentile = ((total_orgs - org_pos + 1) / total_orgs) * 100
                
                if target_percentile_range[0] <= org_percentile <= target_percentile_range[1]:
                    similar_performers.append({
                        'name': org['name'],
                        'location': org['location'],
                        'score': org['total_score'],
                        'percentile': round(org_percentile, 1)
                    })
        
        # Score distribution statistics
        scores = [org['total_score'] for org in all_scores]
        score_stats = {
            'mean': round(sum(scores) / len(scores), 1),
            'median': round(sorted(scores)[len(scores)//2], 1),
            'std_dev': round((sum((x - sum(scores)/len(scores))**2 for x in scores) / len(scores))**0.5, 1),
            'min': min(scores),
            'max': max(scores)
        }
        
        return {
            'organization': {
                'name': org_name,
                'score': org_score,
                'location': org_data.get('location', ''),
                'country': org_data.get('country', ''),
                'hospital_type': org_data.get('hospital_type', ''),
                'jci_accredited': org_data.get('jci_accredited', False)
            },
            'rankings': {
                'overall': {
                    'rank': org_rank,
                    'total_organizations': total_orgs,
                    'percentile': round(overall_percentile, 1),
                    'performance_level': performance_level
                },
                'regional': {
                    'rank': regional_rank,
                    'total_organizations': len(regional_orgs),
                    'percentile': round(regional_percentile, 1),
                    'country': org_country.title()
                },
                'hospital_type': {
                    'rank': type_rank,
                    'total_organizations': len(type_orgs),
                    'percentile': round(type_percentile, 1),
                    'type': org_type
                },
                'jci_accredited': {
                    'rank': jci_rank if org_data.get('jci_accredited') else None,
                    'total_organizations': len([org for org in all_scores if org['jci_accredited']]),
                    'percentile': round(jci_percentile, 1) if jci_percentile > 0 else None
                },
                'score_tier': {
                    'tier': current_tier,
                    'rank_in_tier': tier_rank if current_tier else None,
                    'total_in_tier': len(score_tiers.get(current_tier, [])) if current_tier else 0,
                    'percentile_in_tier': round(tier_percentile, 1) if tier_percentile > 0 else 0
                }
            },
            'comparisons': {
                'top_performers': top_performers,
                'similar_performers': similar_performers[:10],  # Limit to top 10
                'score_statistics': score_stats
            },
            'insights': {
                'performance_summary': f"Ranks {org_rank} out of {total_orgs} organizations globally ({performance_level})",
                'regional_summary': f"Ranks {regional_rank} out of {len(regional_orgs)} organizations in {org_country.title()}" if regional_rank else "Regional data not available",
                'improvement_potential': f"Score improvement of {score_stats['max'] - org_score:.1f} points possible to reach top performer" if org_score < score_stats['max'] else "Already at maximum performance level"
            }
        }

    def add_new_organization(self, org_data: Dict[str, Any]) -> bool:
        """Add a new organization to the unified database and trigger ranking recalculation"""
        try:
            # Load current database
            database_path = 'unified_healthcare_organizations.json'
            
            # Try to find the file in current directory or script directory
            try:
                base_dir = os.path.dirname(__file__)
            except Exception:
                base_dir = os.getcwd()
            
            candidates = [database_path, os.path.join(base_dir, database_path)]
            db_path = None
            for path in candidates:
                if os.path.exists(path):
                    db_path = path
                    break
            
            if not db_path:
                # Create new database file
                db_path = database_path
                current_db = []
            else:
                # Load existing database
                with open(db_path, 'r', encoding='utf-8') as f:
                    current_db = json.load(f)
                    if isinstance(current_db, dict) and 'organizations' in current_db:
                        current_db = current_db['organizations']
                    elif not isinstance(current_db, list):
                        current_db = []
            
            # Check for duplicates based on name and location
            org_name = org_data.get('name', '').lower().strip()
            org_location = org_data.get('location', '').lower().strip()
            
            is_update = False
            for existing_org in current_db:
                existing_name = existing_org.get('name', '').lower().strip()
                existing_location = existing_org.get('location', '').lower().strip()
                
                if existing_name == org_name and existing_location == org_location:
                    # Organization already exists, update it instead
                    existing_org.update(org_data)
                    existing_org['last_updated'] = datetime.now().isoformat()
                    is_update = True
                    break
            
            if not is_update:
                # Add timestamp and data source
                org_data['last_updated'] = datetime.now().isoformat()
                org_data['data_source'] = 'website_upload'
                
                # Add the new organization
                current_db.append(org_data)
            
            # Save updated database
            with open(db_path, 'w', encoding='utf-8') as f:
                json.dump(current_db, f, indent=2, ensure_ascii=False)
            
            # Reload the unified database cache
            self._unified_db_cache = None
            self.unified_database = self.load_unified_database()
            
            # Trigger automatic ranking recalculation
            try:
                from unique_ranking_system import UniqueRankingSystem
                ranking_system = UniqueRankingSystem()
                ranking_success = ranking_system.run_complete_unique_ranking()
                
                if ranking_success:
                    print(f"‚úÖ Rankings updated successfully after adding {org_data.get('name', 'organization')}")
                    
                    # Reload the database to get updated ranking information
                    self._unified_db_cache = None
                    self.unified_database = self.load_unified_database()
                    
                    # Find the newly added organization with updated ranking
                    org_name_lower = org_data.get('name', '').lower().strip()
                    for updated_org in self.unified_database:
                        if updated_org.get('name', '').lower().strip() == org_name_lower:
                            # Update org_data with ranking information
                            org_data.update({
                                'overall_rank': updated_org.get('overall_rank', 'N/A'),
                                'percentile': updated_org.get('percentile', 0),
                                'ranking_metadata': updated_org.get('ranking_metadata', {})
                            })
                            break
                else:
                    print(f"‚ö†Ô∏è Warning: Failed to update rankings after adding {org_data.get('name', 'organization')}")
                    
            except Exception as ranking_error:
                print(f"‚ö†Ô∏è Warning: Could not update rankings: {str(ranking_error)}")
                # Don't fail the entire operation if ranking fails
            
            return True
            
        except Exception as e:
            print(f"Error adding organization to database: {str(e)}")
            return False

# PDF Generation Functions
def create_score_chart(score, title="Quality Score"):
    """Create a score visualization chart for PDF"""
    fig, ax = plt.subplots(figsize=(6, 4))
    
    # Create a gauge-like chart
    colors_list = ['#ff4444', '#ffaa44', '#ffdd44', '#88dd44', '#44dd44']
    ranges = [20, 40, 60, 80, 100]
    
    # Create background bars
    for i, (range_val, color) in enumerate(zip(ranges, colors_list)):
        start = ranges[i-1] if i > 0 else 0
        ax.barh(0, range_val - start, left=start, height=0.5, color=color, alpha=0.3)
    
    # Create score bar
    score_color = colors_list[min(int(score // 20), 4)]
    ax.barh(0, score, height=0.3, color=score_color, alpha=0.8)
    
    # Add score text
    ax.text(score/2, 0, f'{score:.1f}', ha='center', va='center', 
            fontsize=16, fontweight='bold', color='white')
    
    ax.set_xlim(0, 100)
    ax.set_ylim(-0.5, 0.5)
    ax.set_xlabel('Score')
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.set_yticks([])
    
    # Save to bytes
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150)
    img_buffer.seek(0)
    plt.close()
    
    return img_buffer

def create_certification_chart(certifications):
    """Create a certification breakdown chart for PDF"""
    if not certifications:
        return None
    
    # Count certifications by status
    status_counts = {}
    for cert in certifications:
        status = cert.get('status', 'Unknown')
        status_counts[status] = status_counts.get(status, 0) + 1
    
    fig, ax = plt.subplots(figsize=(6, 4))
    
    colors = {'Active': '#44dd44', 'In Progress': '#ffaa44', 'Expired': '#ff4444', 'Unknown': '#cccccc'}
    
    statuses = list(status_counts.keys())
    counts = list(status_counts.values())
    chart_colors = [colors.get(status, '#cccccc') for status in statuses]
    
    ax.pie(counts, labels=statuses, colors=chart_colors, autopct='%1.1f%%', startangle=90)
    ax.set_title('Certification Status Distribution', fontsize=14, fontweight='bold')
    
    # Save to bytes
    img_buffer = io.BytesIO()
    plt.savefig(img_buffer, format='png', bbox_inches='tight', dpi=150)
    img_buffer.seek(0)
    plt.close()
    
    return img_buffer

def generate_detailed_scorecard_pdf(org_name, org_data):
    """Generate a comprehensive PDF scorecard for the organization"""
    try:
        # Create PDF buffer
        buffer = io.BytesIO()
        
        # Create PDF document
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, 
                              topMargin=72, bottomMargin=18)
        
        # Get styles
        styles = getSampleStyleSheet()
        
        # Custom styles
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=24,
            spaceAfter=30,
            alignment=TA_CENTER,
            textColor=rl_colors.HexColor('#2c3e50')
        )
        
        heading_style = ParagraphStyle(
            'CustomHeading',
            parent=styles['Heading2'],
            fontSize=16,
            spaceAfter=12,
            textColor=rl_colors.HexColor('#34495e')
        )
        
        subheading_style = ParagraphStyle(
            'CustomSubheading',
            parent=styles['Heading3'],
            fontSize=14,
            spaceAfter=8,
            textColor=rl_colors.HexColor('#7f8c8d')
        )
        
        normal_style = ParagraphStyle(
            'CustomNormal',
            parent=styles['Normal'],
            fontSize=11,
            spaceAfter=6
        )
        
        # Build PDF content
        story = []
        
        # Header
        story.append(Paragraph("Global Healthcare Quality Grid", title_style))
        story.append(Paragraph(f"Detailed Assessment Report for {org_name}", heading_style))
        story.append(Paragraph(f"Generated on: {datetime.now().strftime('%B %d, %Y at %I:%M %p')}", normal_style))
        story.append(Spacer(1, 20))
        
        # Executive Summary
        story.append(Paragraph("Executive Summary", heading_style))
        
        score = org_data.get('total_score', 0)
        # Determine grade based on adjusted scoring scale (max 85)
        grade = "A+" if score >= 75 else "A" if score >= 65 else "B+" if score >= 55 else "B" if score >= 45 else "C"
        
        summary_text = f"""
        <b>{org_name}</b> has achieved an overall Global Healthcare Quality Assessment quality score of <b>{score:.1f}/100</b> (Grade: <b>{grade}</b>).
        This assessment is based on comprehensive analysis of certifications, quality initiatives, transparency measures, 
        and reputation factors from publicly available sources.
        """
        story.append(Paragraph(summary_text, normal_style))
        story.append(Spacer(1, 15))
        
        # Compliance Verification Section
        story.append(Paragraph("Mandatory Compliance Verification", heading_style))
        
        compliance_check = org_data.get('score_breakdown', {}).get('compliance_check', {})
        if compliance_check:
            compliance_percentage = compliance_check.get('compliance_percentage', 0)
            compliant_count = compliance_check.get('compliant_count', 0)
            total_required = compliance_check.get('total_required', 8)
            is_fully_compliant = compliance_check.get('is_fully_compliant', False)
            
            compliance_status = "‚úÖ FULLY COMPLIANT - ALL MANDATORY ISO STANDARDS MET" if is_fully_compliant else "‚ö†Ô∏è CRITICAL NON-COMPLIANCE - MANDATORY ISO STANDARDS MISSING"
            
            compliance_text = f"""
            <b>MANDATORY ISO STANDARDS COMPLIANCE STATUS:</b> {compliance_status}<br/>
            <b>Compliance Rate:</b> {compliance_percentage:.1f}% ({compliant_count}/{total_required} mandatory certifications)<br/>
            <b>Penalty Applied:</b> {compliance_check.get('total_penalty', 0)} points for missing mandatory standards<br/><br/>
            
            <b>MANDATORY ISO STANDARDS REVIEW:</b><br/>
            """
            
            # Add details for each required certification with penalty information
            details = compliance_check.get('details', {})
            for cert_name, cert_info in details.items():
                status_icon = "‚úÖ" if cert_info.get('found') and cert_info.get('status') in ['Active', 'Valid', 'Current'] else "‚ùå"
                cert_status = cert_info.get('status', 'Not Found') if cert_info.get('found') else 'Not Found'
                penalty_info = f" (Penalty: {cert_info.get('penalty', 0)} points)" if cert_info.get('mandatory', False) and not cert_info.get('found') else ""
                mandatory_label = " [MANDATORY]" if cert_info.get('mandatory', False) else " [RECOMMENDED]"
                compliance_text += f"‚Ä¢ {status_icon} <b>{cert_name}{mandatory_label}:</b> {cert_status}{penalty_info}<br/>"
            
            story.append(Paragraph(compliance_text, normal_style))
        else:
            story.append(Paragraph("Compliance verification data not available for this assessment.", normal_style))
        
        story.append(Spacer(1, 20))
        
        # Score Breakdown
        story.append(Paragraph("Quality Score Breakdown", heading_style))
        
        score_breakdown = org_data.get('score_breakdown', {})
        
        # Create score breakdown table - certification-only scoring
        score_data = [
            ['Component', 'Weight', 'Score', 'Weighted Score'],
            ['Certifications', '100%', f"{score_breakdown.get('certification_score', 0):.2f}",
                f"{score_breakdown.get('certification_score', 0):.2f}"],
                ['Reputation Bonus', 'Bonus', f"{score_breakdown.get('reputation_bonus', 0):.2f}",
                f"{score_breakdown.get('reputation_bonus', 0):.2f}"],
                ['Location Adjustment', 'Adjustment', f"{score_breakdown.get('location_adjustment', 0):.2f}",
                f"{score_breakdown.get('location_adjustment', 0):.2f}"],
                ['', '', 'Total Score:', f"{score:.2f}/100"]
        ]
        
        score_table = Table(score_data, colWidths=[2.5*inch, 1*inch, 1*inch, 1.5*inch])
        score_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#3498db')),
            ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 12),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -2), rl_colors.beige),
            ('BACKGROUND', (0, -1), (-1, -1), rl_colors.HexColor('#ecf0f1')),
            ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)
        ]))
        
        story.append(score_table)
        story.append(Spacer(1, 20))
        
        # Add score chart
        score_chart = create_score_chart(score, f"{org_name} Quality Score")
        if score_chart:
            story.append(Paragraph("Visual Score Representation", subheading_style))
            story.append(ReportLabImage(score_chart, width=5*inch, height=3*inch))
            story.append(Spacer(1, 15))
        
        # Certifications Section
        story.append(Paragraph("Certifications Analysis", heading_style))
        
        certifications = org_data.get('certifications', [])
        if certifications:
            story.append(Paragraph(f"Total Certifications Found: {len(certifications)}", subheading_style))
            
            # Active certifications table
            active_certs = [cert for cert in certifications if cert.get('status') == 'Active']
            if active_certs:
                cert_data = [['Certification', 'Status', 'Valid Until', 'Score Impact']]
                for cert in active_certs[:10]:  # Show top 10
                    cert_data.append([
                        cert.get('name', 'N/A'),
                        cert.get('status', 'N/A'),
                        cert.get('valid_until', 'N/A'),
                        f"{cert.get('score_impact', 0):.1f}"
                    ])
                
                cert_table = Table(cert_data, colWidths=[2.5*inch, 1*inch, 1.5*inch, 1*inch])
                cert_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), rl_colors.HexColor('#27ae60')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), rl_colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 11),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                    ('BACKGROUND', (0, 1), (-1, -1), rl_colors.beige),
                    ('GRID', (0, 0), (-1, -1), 1, rl_colors.black)
                ]))
                
                story.append(cert_table)
                story.append(Spacer(1, 15))
            
            # Add certification chart
            cert_chart = create_certification_chart(certifications)
            if cert_chart:
                story.append(Paragraph("Certification Status Distribution", subheading_style))
                story.append(ReportLabImage(cert_chart, width=4*inch, height=3*inch))
                story.append(Spacer(1, 15))
        else:
            story.append(Paragraph("No certifications found in our database.", normal_style))
            story.append(Spacer(1, 10))
        
        # Quality Initiatives Section
        story.append(Paragraph("Quality Initiatives", heading_style))
        
        initiatives = org_data.get('quality_initiatives', [])
        if initiatives:
            story.append(Paragraph(f"Quality Initiatives Identified: {len(initiatives)}", subheading_style))
            
            for i, initiative in enumerate(initiatives[:8], 1):  # Show top 8
                init_text = f"<b>{i}.</b> {initiative.get('name', 'N/A')} ({initiative.get('year', 'N/A')})"
                story.append(Paragraph(init_text, normal_style))
            
            story.append(Spacer(1, 15))
        else:
            story.append(Paragraph("No specific quality initiatives found in our analysis.", normal_style))
            story.append(Spacer(1, 10))
        
        # Page break for next section
        story.append(PageBreak())
        
        # Methodology Section
        story.append(Paragraph("Assessment Methodology", heading_style))
        
        methodology_text = """
        <b>Data Sources:</b><br/>
        ‚Ä¢ Official certification body databases (ISO, JCI, NABH, CAP, NABL, etc.)<br/>
        ‚Ä¢ International accreditation organizations<br/>
        ‚Ä¢ Government healthcare regulatory databases<br/>
        ‚Ä¢ Verified certification registries<br/>
        ‚Ä¢ Official organization certification disclosures<br/><br/>
        
        <b>Mandatory Compliance Review:</b><br/>
        All organizations must be reviewed for compliance with these certification/accreditation standards before QuXAT score generation:<br/>
        ‚Ä¢ <b>ISO 9001</b> - Quality Management Systems<br/>
        ‚Ä¢ <b>ISO 14001</b> - Environmental Management Systems<br/>
        ‚Ä¢ <b>ISO 45001</b> - Occupational Health and Safety Management Systems<br/>
        ‚Ä¢ <b>ISO 27001</b> - Information Security Management Systems<br/>
        ‚Ä¢ <b>ISO 13485</b> - Medical Devices Quality Management Systems<br/>
        ‚Ä¢ <b>ISO 50001</b> - Energy Management Systems<br/>
        ‚Ä¢ <b>ISO 15189</b> - Medical Laboratories Quality and Competence<br/>
        ‚Ä¢ <b>College of American Pathologists (CAP)</b> - Laboratory Accreditation<br/><br/>
        
        <b>Scoring Methodology:</b><br/>
        ‚Ä¢ <b>Weighted Certification System (100%):</b> Evidence-based scoring using verified certifications with specific weights<br/><br/>
        
        <b>Certification Weight Hierarchy:</b><br/>
        ‚Ä¢ <b>JCI Accreditation:</b> Weight 3.5, Base Score 30 pts (Global Gold Standard)<br/>
        ‚Ä¢ <b>ISO 9001 & ISO 13485:</b> Weight 3.2, Base Score 25 pts (Quality & Medical Device Management)<br/>
        ‚Ä¢ <b>ISO 15189:</b> Weight 3.0, Base Score 22 pts (Medical Laboratory Quality)<br/>
        ‚Ä¢ <b>ISO 27001:</b> Weight 2.8, Base Score 20 pts (Information Security)<br/>
        ‚Ä¢ <b>CAP Accreditation:</b> Weight 2.8, Base Score 22 pts (Laboratory Standards)<br/>
        ‚Ä¢ <b>ISO 45001:</b> Weight 2.6, Base Score 18 pts (Occupational Health & Safety)<br/>
        ‚Ä¢ <b>NABH Accreditation:</b> Weight 2.6, Base Score 20 pts (Hospital Standards)<br/>
        ‚Ä¢ <b>ISO 14001:</b> Weight 2.4, Base Score 16 pts (Environmental Management)<br/>
        ‚Ä¢ <b>NABL Accreditation:</b> Weight 2.4, Base Score 18 pts (Testing & Calibration)<br/>
        ‚Ä¢ <b>ISO 50001:</b> Weight 2.2, Base Score 14 pts (Energy Management)<br/>
        ‚Ä¢ <b>Other ISO Standards:</b> Weight 2.0, Base Score 12 pts (General ISO Certifications)<br/><br/>
        
        <b>Certification Status:</b> Active certifications (100% weight), In-Progress (50% weight)<br/>
        <b>Performance Bonuses:</b> Diversity bonus (multiple cert types), International premium (JCI/ISO certs)<br/><br/>
        
        <b>Score Ranges (Evidence-Based Scale):</b><br/>
        ‚Ä¢ 90-100: A+ (Exceptional Quality Recognition)<br/>
        ‚Ä¢ 80-89: A (Excellent - Quality Recognition)<br/>
        ‚Ä¢ 70-79: B+ (Good - Quality Recognition)<br/>
        ‚Ä¢ 60-69: B (Adequate - Quality Recognition)<br/>
        ‚Ä¢ 50-59: C (Average - Quality Recognition)
        """
        
        story.append(Paragraph(methodology_text, normal_style))
        story.append(Spacer(1, 20))
        
        # Disclaimers Section
        story.append(Paragraph("Important Disclaimers", heading_style))
        
        disclaimer_text = """
        <b>Assessment Limitations:</b> This scoring system is based on publicly available information and may not 
        capture all quality aspects of an organization. Scores are generated through automated analysis and 
        <b>may be incorrect or incomplete</b>.<br/><br/>
        
        <b>Data Dependencies:</b> Accuracy depends on the availability and reliability of public data sources. 
        Organizations may have additional certifications or quality initiatives not captured in our database.<br/><br/>
        
        <b>Not Medical Advice:</b> Healthcare Quality Grid scores do not constitute medical advice, professional recommendations, 
        or endorsements. Users should conduct independent verification and due diligence before making healthcare decisions.<br/><br/>
        
        <b>Limitation of Liability:</b> Healthcare Quality Grid and its developers disclaim all warranties, express or implied, 
        regarding the accuracy or completeness of information. Users assume full responsibility for any decisions 
        made based on Healthcare Quality Grid assessments.<br/><br/>
        
        <b>Comparative Tool Only:</b> Intended for comparative analysis and research purposes, not absolute quality determination.
        """
        
        story.append(Paragraph(disclaimer_text, normal_style))
        story.append(Spacer(1, 20))
        
        # Footer
        footer_text = f"""
        <b>Report Generated by:</b> Healthcare Quality Grid v3.0<br/>
        <b>Generation Date:</b> {datetime.now().strftime('%B %d, %Y at %I:%M %p')}<br/>
        <b>Organization:</b> {org_name}<br/>
        <b>Report ID:</b> QXT-{datetime.now().strftime('%Y%m%d')}-{hash(org_name) % 10000:04d}<br/>
        <br/>
        <b>Contact Information:</b><br/>
        Contact the Global Healthcare Quality Assessment team at quxat.team@gmail.com to add your organization to our quality self-assessment database.
        """
        
        story.append(Paragraph(footer_text, normal_style))
        
        # Build PDF
        doc.build(story)
        
        # Get PDF data
        buffer.seek(0)
        pdf_data = buffer.getvalue()
        buffer.close()
        
        return pdf_data
        
    except Exception as e:
        # Log error without using Streamlit functions to avoid context issues
        print(f"Error generating PDF: {str(e)}")
        traceback.print_exc()
        return None

def display_detailed_scorecard_inline(org_name, org_data, score):
    """
    Display a comprehensive detailed scorecard inline instead of generating PDF
    """
    try:
        # Header Section
        st.markdown("---")
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2rem;
            border-radius: 15px;
            margin: 1rem 0;
            color: white;
            text-align: center;
        ">
            <h1 style="color: white; margin-bottom: 0.5rem; font-size: 2.2rem;">üìã Detailed Quality Scorecard</h1>
            <h2 style="color: white; margin-bottom: 0.5rem; font-size: 1.8rem;">{org_name}</h2>
            <p style="font-size: 1.2rem; margin-bottom: 0; opacity: 0.9;">
                Generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Executive Summary
        st.markdown("### üìä Executive Summary")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="Overall Score",
                value=f"{score:.1f}/100",
                delta=f"Grade: {org_data.get('grade', 'N/A')}"
            )
        
        with col2:
            st.metric(
                label="Location",
                value=org_data.get('location', 'N/A')
            )
        
        with col3:
            st.metric(
                label="Organization Type",
                value=org_data.get('type', 'Healthcare Organization')
            )
        
        with col4:
            active_certs = len([c for c in org_data.get('certifications', []) if c.get('status') == 'Active'])
            st.metric(
                label="Mandatory Requirements",
                value=active_certs
            )
        
        # Score Breakdown Section with Visual Progress Bars
        st.markdown("### üéØ Detailed Score Breakdown Analysis")
        
        score_breakdown = org_data.get('score_breakdown', {})
        
        # Display mandatory ISO compliance status prominently (sanitized, no raw HTML)
        compliance_status = score_breakdown.get('compliance_status', '')
        mandatory_penalty = score_breakdown.get('mandatory_penalty', 0)
        
        # Resolve missing standards using either 'standard' or 'name' keys
        missing_items = score_breakdown.get('missing_critical_standards', []) or []
        missing_names = []
        for item in missing_items:
            if isinstance(item, dict):
                missing_names.append(item.get('standard') or item.get('name') or 'Unknown')
            else:
                missing_names.append(str(item))
        
        if isinstance(mandatory_penalty, (int, float)) and mandatory_penalty > 0:
            st.error("üö® MANDATORY ISO STANDARDS NON-COMPLIANCE DETECTED")
            if compliance_status:
                st.write(compliance_status)
            st.write(f"Penalty Applied: -{mandatory_penalty} points from final score")
            if missing_names:
                st.write("Missing Standards:")
                for name in missing_names:
                    st.write(f"‚Ä¢ {name}")
        else:
            st.success("‚úÖ MANDATORY ISO STANDARDS COMPLIANCE VERIFIED")
            if compliance_status:
                st.write(compliance_status)
            st.write("All required international quality standards are met.")
        
        # CAP compliance warning
        cap_warning = score_breakdown.get('cap_warning', '')
        if 'CRITICAL' in cap_warning:
            st.error(cap_warning)
        else:
            st.success(cap_warning)
        
        # Define score components with their maximum values and colors - certification-only scoring
        components = [
            {
                'name': 'Quality Certifications & Accreditations',
                'score': score_breakdown.get('certification_score', 0),
                'max_score': 100,
                'color': '#1f77b4',
                'weight': '100%',
                'description': 'Evidence-based scoring using only verified certifications and accreditations'
            }
        ]
        
        # Display each component with progress bar and reasoning
        for component in components:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # Progress bar
                progress_percentage = (component['score'] / component['max_score']) * 100 if component['max_score'] > 0 else 0
                
                # Color coding based on performance
                if progress_percentage >= 80:
                    bar_color = '#28a745'  # Green
                    performance_text = "Excellent"
                elif progress_percentage >= 60:
                    bar_color = '#ffc107'  # Yellow
                    performance_text = "Good"
                elif progress_percentage >= 40:
                    bar_color = '#fd7e14'  # Orange
                    performance_text = "Fair"
                else:
                    bar_color = '#dc3545'  # Red
                    performance_text = "Needs Improvement"
                
                st.markdown(f"""
                <div style="margin-bottom: 1rem;">
                    <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                        <h4 style="margin: 0; color: {component['color']};">{component['name']} ({component['weight']})</h4>
                        <span style="font-weight: bold; color: {bar_color};">{component['score']:.1f}/{component['max_score']} ({performance_text})</span>
                    </div>
                    <div style="background-color: #e9ecef; border-radius: 10px; height: 20px; overflow: hidden;">
                        <div style="background-color: {bar_color}; height: 100%; width: {progress_percentage}%; border-radius: 10px; transition: width 0.3s ease;"></div>
                    </div>
                    <p style="margin-top: 0.5rem; color: #6c757d; font-size: 0.9rem;">{component['description']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                # Performance indicator
                if progress_percentage >= 80:
                    st.success(f"üü¢ {progress_percentage:.0f}%")
                elif progress_percentage >= 60:
                    st.warning(f"üü° {progress_percentage:.0f}%")
                elif progress_percentage >= 40:
                    st.warning(f"üü† {progress_percentage:.0f}%")
                else:
                    st.error(f"üî¥ {progress_percentage:.0f}%")
        
        # Healthcare Quality Score Display
        st.markdown("---")
        
        # Healthcare quality grade categories
        if score >= 90:
            grade_color = '#28a745'
            grade_text = 'Exceptional Quality'
            grade_emoji = 'üèÜ'
            quality_level = 'Outstanding'
            quality_description = 'Demonstrates exceptional healthcare quality standards'
        elif score >= 80:
            grade_color = '#20c997'
            grade_text = 'High Quality'
            grade_emoji = '‚≠ê'
            quality_level = 'Excellent'
            quality_description = 'Maintains high healthcare quality standards'
        elif score >= 70:
            grade_color = '#ffc107'
            grade_text = 'Good Quality'
            grade_emoji = 'üëç'
            quality_level = 'Good'
            quality_description = 'Meets good healthcare quality standards'
        elif score >= 60:
            grade_color = '#fd7e14'
            grade_text = 'Fair Quality'
            grade_emoji = 'üëå'
            quality_level = 'Fair'
            quality_description = 'Meets basic healthcare quality requirements'
        elif score >= 50:
            grade_color = '#dc3545'
            grade_text = 'Below Standard'
            grade_emoji = 'WARNINGÔ∏è'
            quality_level = 'Needs Improvement'
            quality_description = 'Healthcare quality requires improvement'
        else:
            grade_color = '#6f42c1'
            grade_text = 'Scope for Improvement'
            grade_emoji = 'üîÑ'
            quality_level = 'Critical'
            quality_description = 'Healthcare quality requires immediate attention'
        
        st.markdown(f"""
        <div style="
            background: linear-gradient(135deg, {grade_color}20, {grade_color}10);
            border: 2px solid {grade_color};
            border-radius: 15px;
            padding: 1.5rem;
            text-align: center;
            margin: 1rem 0;
        ">
            <h2 style="color: {grade_color}; margin-bottom: 0.5rem;">
                {grade_emoji} Healthcare Quality Score: {score:.1f}/100
            </h2>
            <h3 style="color: {grade_color}; margin-bottom: 0.5rem;">
                {grade_text}
            </h3>
            <p style="color: #666; margin-bottom: 0.5rem; font-size: 1.1em;">
                <strong>Quality Level:</strong> {quality_level}
            </p>
            <p style="color: #666; margin-bottom: 1rem; font-style: italic;">
                {quality_description}
            </p>
            <div style="background: rgba(255,255,255,0.8); padding: 0.8rem; border-radius: 8px; margin-top: 1rem;">
                <p style="color: #333; margin: 0; font-size: 0.9em;">
                    <strong>Evidence-Based Assessment</strong> | 
                    <strong>Score Range:</strong> 0-100 | 
                    <strong>Focus:</strong> Healthcare Quality & Safety
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Score History and Trend Analysis
        trend_data = get_score_trend(org_name)
        if trend_data or org_name in st.session_state.score_history:
            st.markdown("### üìà Healthcare Quality Score History & Trends")
            st.markdown("*Track your healthcare quality score over time*")
            
            if org_name in st.session_state.score_history and len(st.session_state.score_history[org_name]) > 0:
                history = st.session_state.score_history[org_name]
                
                # Create trend visualization
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if trend_data and isinstance(trend_data, dict):
                        direction = trend_data.get('direction', 'stable')
                        status = trend_data.get('status', 'stable')
                        change = trend_data.get('change', 0)
                        
                        trend_color = '#28a745' if direction == 'up' else '#dc3545' if direction == 'down' else '#6c757d'
                        trend_emoji = 'üìà' if direction == 'up' else 'üìâ' if direction == 'down' else '‚û°Ô∏è'
                        
                        st.markdown(f"""
                        <div style="background: {trend_color}20; padding: 1rem; border-radius: 8px; text-align: center;">
                            <h4 style="color: {trend_color}; margin-bottom: 0.5rem;">{trend_emoji} Score Trend</h4>
                            <div style="font-size: 1.2em; font-weight: bold; color: {trend_color};">
                                {status.title() if status else 'Stable'}
                            </div>
                            <p style="margin: 0; font-size: 0.9em; color: #666;">
                                {'+' if direction == 'up' else '-' if direction == 'down' else ''}{change} points
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown("""
                        <div style="background: #f8f9fa; padding: 1rem; border-radius: 8px; text-align: center;">
                            <h4 style="color: #6c757d; margin-bottom: 0.5rem;">üìä First Assessment</h4>
                            <p style="margin: 0; color: #666;">Baseline score established</p>
                        </div>
                        """, unsafe_allow_html=True)
                
                with col2:
                    assessments_count = len(history)
                    st.markdown(f"""
                    <div style="background: #e3f2fd; padding: 1rem; border-radius: 8px; text-align: center;">
                        <h4 style="color: #1976d2; margin-bottom: 0.5rem;">üìã Assessments</h4>
                        <div style="font-size: 1.2em; font-weight: bold; color: #1976d2;">
                            {assessments_count}
                        </div>
                        <p style="margin: 0; font-size: 0.9em; color: #666;">Total evaluations</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    latest_date = history[-1]['date']
                    st.markdown(f"""
                    <div style="background: #fff3e0; padding: 1rem; border-radius: 8px; text-align: center;">
                        <h4 style="color: #f57c00; margin-bottom: 0.5rem;">üìÖ Last Updated</h4>
                        <div style="font-size: 1em; font-weight: bold; color: #f57c00;">
                            {latest_date}
                        </div>
                        <p style="margin: 0; font-size: 0.9em; color: #666;">Most recent assessment</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Score history chart
                if len(history) > 1:
                    
                    dates = [entry['date'] for entry in history]
                    scores = [entry.get('total_score', 0) for entry in history]
                    
                    fig = go.Figure()
                    fig.add_trace(go.Scatter(
                        x=dates,
                        y=scores,
                        mode='lines+markers',
                        name='Healthcare Quality Score',
                        line=dict(color='#1976d2', width=3),
                        marker=dict(size=8, color='#1976d2'),
                        hovertemplate='<b>Date:</b> %{x}<br><b>Score:</b> %{y}<extra></extra>'
                    ))
                    
                    fig.update_layout(
                        title='Healthcare Quality Score History',
                        xaxis_title='Date',
                        yaxis_title='Quality Score',
                        yaxis=dict(range=[0, 100]),
                        height=400,
                        showlegend=False,
                        plot_bgcolor='rgba(0,0,0,0)',
                        paper_bgcolor='rgba(0,0,0,0)'
                    )
                    
                    # Add score range bands
                    fig.add_hline(y=90, line_dash="dash", line_color="green", annotation_text="Exceptional (90+)")
                    fig.add_hline(y=80, line_dash="dash", line_color="lightgreen", annotation_text="High Quality (80+)")
                    fig.add_hline(y=70, line_dash="dash", line_color="orange", annotation_text="Good Quality (70+)")
                    fig.add_hline(y=60, line_dash="dash", line_color="red", annotation_text="Fair Quality (60+)")
                    
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Score breakdown history
                    with st.expander("üìä Detailed Score Component History", expanded=False):
                        st.markdown("**Component Score Trends:**")
                        
                        # Create component comparison
                        components = ['certification_score']
                        component_names = ['Certifications']
                        
                        for i, (component, name) in enumerate(zip(components, component_names)):
                            latest_value = history[-1].get(component, 0)
                            if len(history) > 1:
                                previous_value = history[-2].get(component, 0)
                                change = latest_value - previous_value
                                change_text = f"({'+' if change > 0 else ''}{change:.1f})" if change != 0 else "(No change)"
                                change_color = "green" if change > 0 else "red" if change < 0 else "gray"
                            else:
                                change_text = "(Baseline)"
                                change_color = "gray"
                            
                            st.markdown(f"‚Ä¢ **{name}:** {latest_value:.1f} <span style='color: {change_color};'>{change_text}</span>", unsafe_allow_html=True)
        
        # Healthcare Quality Factors Analysis Section
        st.markdown("### üìä Healthcare Quality Factors Analysis")
        st.markdown("*Certification-based quality assessment*")
        
        # Calculate factor impacts as percentages - certification-only scoring
        total_possible = 100  # Total possible score
        cert_impact = score_breakdown.get('certification_score', 0)  # 100% weight
        
        # Create healthcare quality factors display
        factors_col1, factors_col2 = st.columns([2, 1])
        
        with factors_col1:
            st.markdown("#### üèÜ Healthcare Quality Factors")
            
            # Factor 1: Certifications & Accreditations (Only Factor)
            cert_percentage = cert_impact
            if cert_percentage >= 90:
                cert_status = "Exceptional"
                cert_color = "#28a745"
            elif cert_percentage >= 80:
                cert_status = "Excellent"
                cert_color = "#17a2b8"
            elif cert_percentage >= 70:
                cert_status = "Good"
                cert_color = "#ffc107"
            elif cert_percentage >= 60:
                cert_status = "Adequate"
                cert_color = "#fd7e14"
            else:
                cert_status = "Needs Improvement"
                cert_color = "#dc3545"
                
            st.markdown(f"""
            **Quality Certifications & Accreditations** - *100% of your score*
            <div style="background: {cert_color}20; border-left: 4px solid {cert_color}; padding: 10px; margin: 5px 0;">
                <strong style="color: {cert_color};">{cert_status}</strong> - {cert_percentage:.0f} points achieved<br>
                <small>Evidence-based scoring using only verified certifications</small>
            </div>
            """, unsafe_allow_html=True)
        
        with factors_col2:
            st.markdown("#### üìà Score Impact Summary")
            
            # Healthcare quality impact meter - certification-only scoring
            total_impact = cert_impact
            impact_percentage = cert_impact
            
            st.markdown(f"""
            <div style="text-align: center; padding: 20px; background: #f8f9fa; border-radius: 10px;">
                <h3 style="color: #333; margin-bottom: 10px;">Certification Score</h3>
                <div style="font-size: 2em; color: {cert_color}; font-weight: bold;">
                    {impact_percentage:.0f}
                </div>
                <p style="color: #666; margin: 5px 0;">out of 100 points</p>
                <hr style="margin: 15px 0;">
                <p style="color: #333; font-size: 0.9em;">
                    <strong>Quality Score:</strong> {score:.1f}/100<br>
                    <strong>Quality Level:</strong> {quality_level}
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            # Improvement potential
            improvement_potential = 100 - impact_percentage
            if improvement_potential > 0:
                st.markdown(f"""
                <div style="background: #e3f2fd; padding: 15px; border-radius: 8px; margin-top: 15px;">
                    <h4 style="color: #1976d2; margin-bottom: 10px;">üí° Improvement Potential</h4>
                    <p style="color: #333; margin: 0;">
                        You could improve your Healthcare Quality Score by up to <strong>{improvement_potential:.0f} points</strong> 
                        by addressing the factors marked as "Needs Improvement" above.
                    </p>
                </div>
                """, unsafe_allow_html=True)

        # Detailed Reasoning Section
        st.markdown("### üîç Score Reasoning & Analysis")
        
        # Certifications reasoning
        with st.expander("üèÜ Certifications Analysis", expanded=True):
            cert_score = score_breakdown.get('certification_score', 0)
            certifications = org_data.get('certifications', [])
            active_certs = [c for c in certifications if c.get('status') == 'Active']
            
            st.markdown(f"""
            **Score: {cert_score:.1f}/50 points**
            
            **Analysis:**
            - Found {len(certifications)} total certifications in our database
            - {len(active_certs)} certifications are currently active
            - Certification score represents {(cert_score/50)*100:.1f}% of maximum possible points
            
            **Key Factors:**
            """)
            
            if active_certs:
                for cert in active_certs[:5]:  # Show top 5
                    impact = cert.get('score_impact', 0)
                    st.markdown(f"- **{cert.get('name', 'Unknown')}**: +{impact:.1f} points ({cert.get('status', 'Unknown')} status)")
            else:
                st.markdown("- No active certifications found in our database")
                st.markdown("- This significantly impacts the overall quality score")
        
        # Certification Improvement Recommendations Section
        st.markdown("### üí° Global Healthcare Quality Enhancement Plan")
        st.markdown("*Just like credit repair, improving your healthcare quality score requires strategic action and time*")
        
        recommendations = []
        
        # Certification recommendations (like credit utilization)
        cert_score = score_breakdown.get('certification_score', 0)
        if cert_score < 35:  # Less than 70% of certification points
            recommendations.append({
                'category': 'üèÜ Accreditation Portfolio',
                'priority': 'High',
                'recommendation': 'Pursue additional healthcare accreditations such as JCI, ISO 9001, or local healthcare quality certifications',
                'impact': 'Could increase Healthcare Quality Score by 30-45 points',
                'timeline': '6-18 months',
                'credit_analogy': 'Like maintaining low credit utilization, having diverse active certifications shows financial institutions (patients/regulators) you can manage quality standards responsibly.',
                'action_steps': [
                    'üìã Audit current certification status and renewal dates',
                    'üéØ Identify 2-3 target certifications relevant to your specialty',
                    'üìÖ Create certification timeline with milestones',
                    'üí∞ Budget for certification costs and training'
                ]
            })
        
        # Certification recommendations - focus only on certification improvements
        cert_score = score_breakdown.get('certification_score', 0)
        if cert_score < 80:  # Less than 80% of certification points
            recommendations.append({
                'category': 'üèÜ Certification Portfolio Enhancement',
                'priority': 'High',
                'recommendation': 'Pursue additional quality certifications and accreditations to strengthen evidence-based quality profile',
                'impact': f'Could increase Healthcare Quality Score by {100 - cert_score:.0f} points',
                'timeline': '6-18 months',
                'certification_analogy': 'Like building a strong professional credential portfolio, multiple certifications demonstrate comprehensive quality commitment across all areas.',
                'action_steps': [
                    'üéØ Identify missing premium certifications (JCI, NABH, CAP)',
                    'üìã Develop certification roadmap with timeline',
                    'üîÑ Ensure all current certifications remain active',
                    'üìà Target ISO standards relevant to your specialty'
                ]
            })
        
        if cert_score < 60:  # Very low certification score
            recommendations.append({
                'category': '‚ö° Priority Certification Action',
                'priority': 'Critical',
                'recommendation': 'Immediate focus on obtaining foundational quality certifications to establish credible quality evidence',
                'impact': f'Essential for quality credibility - could add {60 - cert_score:.0f}+ points',
                'timeline': '3-12 months',
                'certification_analogy': 'Like establishing basic credit history, foundational certifications are essential for quality credibility.',
                'action_steps': [
                    'üö® Start with most achievable certification (ISO 9001)',
                    'üìä Conduct gap analysis for certification requirements',
                    'üë• Assign dedicated certification management team',
                    'üí∞ Budget for certification costs and consulting'
                ]
            })
        
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                priority_color = '#dc3545' if rec['priority'] == 'High' else '#ffc107'
                priority_emoji = 'üî¥' if rec['priority'] == 'High' else 'üü°'
                
                # Credit repair-style card layout
                st.markdown(f"""
                <div style="
                    border: 2px solid {priority_color};
                    background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%);
                    padding: 1.5rem;
                    margin: 1.5rem 0;
                    border-radius: 12px;
                    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
                ">
                    <div style="display: flex; align-items: center; margin-bottom: 1rem;">
                        <div style="
                            background: {priority_color};
                            color: white;
                            padding: 0.5rem 1rem;
                            border-radius: 20px;
                            font-weight: bold;
                            margin-right: 1rem;
                        ">
                            {priority_emoji} {rec['priority']} Priority
                        </div>
                        <h3 style="color: {priority_color}; margin: 0;">{rec['category']}</h3>
                    </div>
                    
                    <div style="background: #e8f4fd; padding: 1rem; border-radius: 8px; margin-bottom: 1rem;">
                        <h4 style="color: #1976d2; margin-bottom: 0.5rem;">üí° Certification Analogy</h4>
                        <p style="margin: 0; font-style: italic; color: #333;">{rec['certification_analogy']}</p>
                    </div>
                    
                    <p style="margin-bottom: 1rem;"><strong>üìã Action Plan:</strong> {rec['recommendation']}</p>
                    
                    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; margin-bottom: 1rem;">
                        <div style="background: #e8f5e8; padding: 0.8rem; border-radius: 6px;">
                            <strong style="color: #2e7d32;">üìà Quality Score Impact:</strong><br>
                            {rec['impact']}
                        </div>
                        <div style="background: #fff3e0; padding: 0.8rem; border-radius: 6px;">
                            <strong style="color: #f57c00;">‚è±Ô∏è Timeline:</strong><br>
                            {rec['timeline']}
                        </div>
                    </div>
                    
                    <div style="background: #f5f5f5; padding: 1rem; border-radius: 8px;">
                        <h4 style="color: #333; margin-bottom: 0.5rem;">‚úÖ Specific Action Steps:</h4>
                        <ul style="margin: 0; padding-left: 1.2rem;">
                """, unsafe_allow_html=True)
                
                # Add action steps
                for step in rec.get('action_steps', []):
                    st.markdown(f"<li style='margin-bottom: 0.3rem; color: #333;'>{step}</li>", unsafe_allow_html=True)
                
                st.markdown("</ul></div></div>", unsafe_allow_html=True)
                
        else:
            st.success("üéâ Excellent Healthcare Quality Score! This organization demonstrates strong quality indicators across all measured categories.")
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #e8f5e8 0%, #c8e6c9 100%);
                padding: 1.5rem;
                border-radius: 12px;
                border-left: 5px solid #4caf50;
                margin: 1rem 0;
            ">
                <h4 style="color: #2e7d32; margin-bottom: 1rem;">üèÜ Quality Maintenance Plan</h4>
                <ul style="color: #333; margin: 0;">
                    <li>üìä Continue monitoring and maintaining current certification status</li>
                    <li>üîÑ Regularly review and update quality improvement initiatives</li>
                    <li>‚≠ê Maintain high levels of patient satisfaction and feedback quality</li>
                    <li>üéØ Consider pursuing additional advanced certifications for further excellence</li>
                    <li>üìà Monitor Healthcare Quality Score monthly for any changes</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        # Quality Monitoring Dashboard
        if recommendations:
            st.markdown("### üìä Healthcare Quality Monitoring Dashboard")
            st.markdown("*Track your progress and quality improvements*")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("""
                <div style="background: #e3f2fd; padding: 1rem; border-radius: 8px; text-align: center;">
                    <h4 style="color: #1976d2; margin-bottom: 0.5rem;">üìà Score Potential</h4>
                    <div style="font-size: 1.5em; font-weight: bold; color: #1976d2;">
                        +{} points
                    </div>
                    <p style="margin: 0; font-size: 0.9em; color: #666;">Maximum Improvement</p>
                </div>
                """.format(sum([int(rec['impact'].split('-')[1].split()[0]) for rec in recommendations if '-' in rec['impact']])), unsafe_allow_html=True)
            
            with col2:
                avg_timeline = sum([int(rec['timeline'].split('-')[0]) for rec in recommendations if '-' in rec['timeline']]) // len(recommendations)
                st.markdown(f"""
                <div style="background: #fff3e0; padding: 1rem; border-radius: 8px; text-align: center;">
                    <h4 style="color: #f57c00; margin-bottom: 0.5rem;">‚è±Ô∏è Avg Timeline</h4>
                    <div style="font-size: 1.5em; font-weight: bold; color: #f57c00;">
                        {avg_timeline} months
                    </div>
                    <p style="margin: 0; font-size: 0.9em; color: #666;">To See Results</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                high_priority_count = sum([1 for rec in recommendations if rec['priority'] == 'High'])
                st.markdown(f"""
                <div style="background: #ffebee; padding: 1rem; border-radius: 8px; text-align: center;">
                    <h4 style="color: #d32f2f; margin-bottom: 0.5rem;">üî¥ High Priority</h4>
                    <div style="font-size: 1.5em; font-weight: bold; color: #d32f2f;">
                        {high_priority_count} items
                    </div>
                    <p style="margin: 0; font-size: 0.9em; color: #666;">Need Immediate Action</p>
                </div>
                """, unsafe_allow_html=True)
        
        # Quick Action Items
        if recommendations:
            st.markdown("### ‚ö° Quick Action Items (Next 30 Days)")
            
            quick_actions = [
                "üìã Conduct internal audit of current certification status and renewal dates",
                "üìä Implement patient feedback collection system across all service points",
                "üåê Review and update organization website with quality metrics and achievements",
                "üìà Document and publicize recent quality improvement initiatives",
                "üîç Benchmark against similar organizations in your region or specialty"
            ]
            
            for action in quick_actions:
                st.markdown(f"- {action}")
        
        st.markdown("---")
        
        # Visual Score Representation
        st.markdown("### üìà Visual Score Representation")
        
        # Create a gauge chart for the overall score
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': f"{org_name} Quality Score"},
            delta = {'reference': 50},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 45], 'color': "lightgray"},
                    {'range': [45, 55], 'color': "yellow"},
                    {'range': [55, 65], 'color': "lightgreen"},
                    {'range': [65, 75], 'color': "green"},
                    {'range': [75, 100], 'color': "darkgreen"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # Certifications Analysis
        st.markdown("### üèÜ Certifications Analysis")
        
        certifications = org_data.get('certifications', [])
        if certifications:
            st.markdown(f"**Total Certifications Found:** {len(certifications)}")
            active_certs = [cert for cert in certifications if cert.get('status') == 'Active']
            st.markdown(f"**Mandatory Requirements:** {len(active_certs)}")
            
            # Note: Detailed certification cards are displayed in the main profile section below
            
            # Certification status distribution
            if len(certifications) > 1:
                st.markdown("#### Certification Status Distribution")
                status_counts = {}
                for cert in certifications:
                    status = cert.get('status', 'Unknown')
                    status_counts[status] = status_counts.get(status, 0) + 1
                
                fig_pie = px.pie(
                    values=list(status_counts.values()),
                    names=list(status_counts.keys()),
                    title="Certification Status Distribution"
                )
                st.plotly_chart(fig_pie, use_container_width=True)
        else:
            st.info("No certifications found in our database.")
        
        # ISO Certifications Section
        st.markdown("### üåê ISO Certifications")
        
        iso_certifications = org_data.get('iso_certifications')
        if iso_certifications and iso_certifications.active_certifications > 0:
            st.markdown(f"**ISO Certifications Found:** {iso_certifications.active_certifications}")
            
            # Display ISO certification types
            if iso_certifications.certification_types:
                st.markdown("#### ISO Standards Certified")
                
                iso_data = []
                for cert_type in iso_certifications.certification_types:
                    # Get score impact for this ISO standard
                    score_impact = self._get_iso_score_impact(cert_type)
                    
                    iso_data.append({
                        'ISO Standard': cert_type,
                        'Description': self._get_iso_description(cert_type),
                        'Score Impact': f"{score_impact:.2f}",
                        'Relevance': self._get_iso_relevance(cert_type)
                    })
                
                if iso_data:
                    iso_df = pd.DataFrame(iso_data)
                    st.dataframe(iso_df, use_container_width=True, hide_index=True)
            
            # Display certification bodies
            if iso_certifications.certification_bodies:
                st.markdown("#### Certification Bodies")
                bodies_text = ", ".join(iso_certifications.certification_bodies)
                st.write(f"**Accredited by:** {bodies_text}")
            
            # Display data sources
            if iso_certifications.data_sources:
                with st.expander("Data Sources", expanded=False):
                    for source in iso_certifications.data_sources:
                        st.write(f"‚Ä¢ {source}")
            
            # Quality score impact
            if iso_certifications.quality_score_impact > 0:
                st.success(f"**Quality Score Impact:** +{iso_certifications.quality_score_impact:.2f} points")
        else:
            st.info("No ISO certifications found for this organization.")
        
        # Assessment Methodology
        st.markdown("### üìã Assessment Methodology")
        
        with st.expander("Data Sources & Methodology", expanded=False):
            st.markdown("""
            **Data Sources:**
            - üèõÔ∏è Official certification body databases (ISO, JCI, NABH, CAP, NABL, etc.)
            - üåê International accreditation organizations
            - üìä Government healthcare regulatory databases
            - ‚úÖ Verified certification registries
            - üè¢ Official organization certification disclosures
            
            **Mandatory Compliance Review:**
            All organizations must be reviewed for compliance with these certification/accreditation standards before QuXAT score generation:
            - **ISO 9001** - Quality Management Systems
            - **ISO 14001** - Environmental Management Systems
            - **ISO 45001** - Occupational Health and Safety Management Systems
            - **ISO 27001** - Information Security Management Systems
            - **ISO 13485** - Medical Devices Quality Management Systems
            - **ISO 50001** - Energy Management Systems
            - **ISO 15189** - Medical Laboratories Quality and Competence
            - **College of American Pathologists (CAP)** - Laboratory Accreditation
            
            **Scoring Methodology:**
            - **Weighted Certification System (100%):** Evidence-based scoring using verified certifications with specific weights
            
            **Certification Weight Hierarchy:**
            - **JCI Accreditation:** Weight 3.5, Base Score 30 pts (Global Gold Standard)
            - **ISO 9001 & ISO 13485:** Weight 3.2, Base Score 25 pts (Quality & Medical Device Management)
            - **ISO 15189:** Weight 3.0, Base Score 22 pts (Medical Laboratory Quality)
            - **ISO 27001:** Weight 2.8, Base Score 20 pts (Information Security)
            - **CAP Accreditation:** Weight 2.8, Base Score 22 pts (Laboratory Standards)
            - **ISO 45001:** Weight 2.6, Base Score 18 pts (Occupational Health & Safety)
            - **NABH Accreditation:** Weight 2.6, Base Score 20 pts (Hospital Standards)
            - **ISO 14001:** Weight 2.4, Base Score 16 pts (Environmental Management)
            - **NABL Accreditation:** Weight 2.4, Base Score 18 pts (Testing & Calibration)
            - **ISO 50001:** Weight 2.2, Base Score 14 pts (Energy Management)
            - **Other ISO Standards:** Weight 2.0, Base Score 12 pts (General ISO Certifications)
            
            **Certification Status:** Active certifications (100% weight), In-Progress (50% weight)
            **Performance Bonuses:** Diversity bonus (multiple cert types), International premium (JCI/ISO certs)
            
            **Score Ranges (Evidence-Based Scale):**
            - 90-100: A+ (Exceptional Quality Recognition)
            - 80-89: A (Excellent - Quality Recognition)
            - 70-79: B+ (Good - Quality Recognition)
            - 60-69: B (Adequate - Quality Recognition)
            - 50-59: C (Average - Quality Recognition)
            """)
        
        # Important Disclaimers
        st.markdown("### WARNINGÔ∏è Important Disclaimers")
        
        with st.expander("Assessment Limitations & Disclaimers", expanded=False):
            st.markdown("""
            **Assessment Limitations:** This scoring system is based on publicly available information and may not 
            capture all quality aspects of an organization. Scores are generated through automated analysis and 
            **may be incorrect or incomplete**.
            
            **Data Dependencies:** Accuracy depends on the availability and reliability of public data sources. 
            Organizations may have additional certifications or quality initiatives not captured in our database.
            
            **Not Medical Advice:** Healthcare Quality Grid scores do not constitute medical advice, professional recommendations, 
            or endorsements. Users should conduct independent verification and due diligence before making healthcare decisions.
            
            **Limitation of Liability:** Healthcare Quality Grid and its developers disclaim all warranties, express or implied, 
            regarding the accuracy or completeness of information. Users assume full responsibility for any decisions 
            made based on Healthcare Quality Grid assessments.
            
            **Comparative Tool Only:** Intended for comparative analysis and research purposes, not absolute quality determination.
            """)
        
        # Report Footer
        st.markdown("### üìÑ Report Information")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"""
            **Report Generated by:** Healthcare Quality Grid v3.0  
            **Generation Date:** {datetime.now().strftime('%B %d, %Y at %I:%M %p')}  
            **Organization:** {org_name}
            """)
        
        with col2:
            report_id = f"QXT-{datetime.now().strftime('%Y%m%d')}-{hash(org_name) % 10000:04d}"
            st.info(f"""
            **Report ID:** {report_id}  
            **Data Version:** Latest Available  
            **Assessment Type:** Comprehensive Quality Analysis
            """)
        
        # Contact Information Section
        st.markdown("### üìß Contact Information")
        st.info("""
        **Add Your Organization to Our Database:**  
        Contact the Global Healthcare Quality Assessment team at **quxat.team@gmail.com** to add your organization to our quality self-assessment database.
        """)
        
        st.markdown("---")
        st.success("‚úÖ Detailed scorecard displayed successfully! This comprehensive view includes all information that would be in the PDF report.")
        
    except Exception as e:
        st.error(f"Error displaying detailed scorecard: {str(e)}")
        st.error(f"Traceback: {traceback.format_exc()}")

# Initialize the analyzer
@st.cache_resource
def get_analyzer():
    return HealthcareOrgAnalyzer()

# Display dynamic logo at the top of every page
display_dynamic_logo()

# Credit banner: larger font, centered, with link
st.markdown(
    """
    <div style="text-align:center; font-size:18px; font-weight:600; margin-top:4px; margin-bottom:8px; color:#333;">
    QuXAT Healthcare Quality Grid is designed using TRAE AI by the QuXAT - Data Analytics Team of Shawred Analytics PLC, India. Website: <a href="https://www.shawredanalytics.com" target="_blank">www.shawredanalytics.com</a>
    </div>
    """,
    unsafe_allow_html=True
)

# Initialize score history tracking
if 'score_history' not in st.session_state:
    st.session_state.score_history = {}

# Initialize ranking history tracking
if 'ranking_history' not in st.session_state:
    st.session_state.ranking_history = {}

def add_score_to_history(org_name, score_data):
    """Add a score entry to the organization's history"""
    if org_name not in st.session_state.score_history:
        st.session_state.score_history[org_name] = []
    
    # Create score entry with timestamp
    score_entry = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'date': datetime.now().strftime('%Y-%m-%d'),
        'total_score': score_data.get('total_score', 0),
        'base_score': score_data.get('total_score', 0),
        'certification_score': score_data.get('certification_score', 0)
    }
    
    # Add to history (keep last 12 entries for trend analysis)
    st.session_state.score_history[org_name].append(score_entry)
    if len(st.session_state.score_history[org_name]) > 12:
        st.session_state.score_history[org_name] = st.session_state.score_history[org_name][-12:]

def add_ranking_to_history(org_name, rankings_data):
    """Add ranking data to the organization's ranking history"""
    if org_name not in st.session_state.ranking_history:
        st.session_state.ranking_history[org_name] = []
    
    # Create ranking entry with timestamp
    ranking_entry = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'date': datetime.now().strftime('%Y-%m-%d'),
        'overall_rank': rankings_data.get('overall_rank', 0),
        'percentile': rankings_data.get('percentile', 0),
        'total_organizations': rankings_data.get('total_organizations', 0),
        'category_rankings': rankings_data.get('category_rankings', {}),
        'regional_rank': rankings_data.get('regional_ranking', {}).get('rank', 0) if rankings_data.get('regional_ranking') else 0,
        'regional_percentile': rankings_data.get('regional_ranking', {}).get('percentile', 0) if rankings_data.get('regional_ranking') else 0
    }
    
    # Add to history (keep last 12 entries for trend analysis)
    st.session_state.ranking_history[org_name].append(ranking_entry)
    if len(st.session_state.ranking_history[org_name]) > 12:
        st.session_state.ranking_history[org_name] = st.session_state.ranking_history[org_name][-12:]

def get_ranking_trend(org_name):
    """Get ranking trend analysis for an organization"""
    if org_name not in st.session_state.ranking_history or len(st.session_state.ranking_history[org_name]) < 2:
        return None
    
    history = st.session_state.ranking_history[org_name]
    latest_rank = history[-1]['overall_rank']
    previous_rank = history[-2]['overall_rank']
    
    latest_percentile = history[-1]['percentile']
    previous_percentile = history[-2]['percentile']
    
    rank_change = previous_rank - latest_rank  # Positive means improved (lower rank number)
    percentile_change = latest_percentile - previous_percentile  # Positive means improved
    
    if rank_change > 0:
        return {
            'direction': 'up', 
            'rank_change': rank_change, 
            'percentile_change': percentile_change,
            'status': 'improving',
            'description': f'Moved up {rank_change} positions'
        }
    elif rank_change < 0:
        return {
            'direction': 'down', 
            'rank_change': abs(rank_change), 
            'percentile_change': percentile_change,
            'status': 'declining',
            'description': f'Dropped {abs(rank_change)} positions'
        }
    else:
        return {
            'direction': 'stable', 
            'rank_change': 0, 
            'percentile_change': percentile_change,
            'status': 'stable',
            'description': 'Maintained position'
        }

def get_score_trend(org_name):
    """Get score trend analysis for an organization"""
    if org_name not in st.session_state.score_history or len(st.session_state.score_history[org_name]) < 2:
        return None
    
    history = st.session_state.score_history[org_name]
    latest_score = history[-1]['total_score']
    previous_score = history[-2]['total_score']
    
    change = latest_score - previous_score
    
    if change > 0:
        return {'direction': 'up', 'change': change, 'status': 'improving'}
    elif change < 0:
        return {'direction': 'down', 'change': abs(change), 'status': 'declining'}
    else:
        return {'direction': 'stable', 'change': 0, 'status': 'stable'}

# URL Fragment Detection for Direct Links
def handle_url_routing():
    """Handle URL-based routing for direct links"""
    try:
        # Check URL parameters for page routing using the new API
        query_params = st.query_params
        
        # Check if there's a page parameter in the URL
        if 'page' in query_params:
            page_param = query_params['page'].lower()
            if page_param == 'trends' or page_param == 'global-healthcare-quality-trends':
                return 1  # Index for Global Healthcare Quality Trends
            elif page_param == 'dashboard' or page_param == 'quality-dashboard':
                return 2  # Index for Quality Dashboard & Analytics
        
        # Check for hash fragment simulation via query params
        if 'fragment' in query_params:
            fragment = query_params['fragment'].lower()
            if fragment == 'global-healthcare-quality-trends':
                return 1  # Index for Global Healthcare Quality Trends
        
        # Initialize session state for URL handling
        if 'url_page_index' not in st.session_state:
            st.session_state.url_page_index = 0
            
        # Check if URL contains fragment-like parameter
        if 'global-healthcare-quality-trends' in str(query_params).lower():
            st.session_state.url_page_index = 1
            return 1
            
        return st.session_state.url_page_index
    except:
        return 0  # Default to Home page

# JavaScript-based URL fragment detection
def inject_url_fragment_handler():
    """Inject JavaScript to handle URL fragments and update Streamlit session state"""
    fragment_handler = """
    <script>
    function handleUrlFragment() {
        const fragment = window.location.hash.substring(1);
        
        // Map URL fragments to page indices
        const fragmentToPageMap = {
            'global-healthcare-quality-trends': 1,
            'quality-dashboard': 2,
            'dashboard': 2
        };
        
        if (fragment && fragmentToPageMap[fragment] !== undefined) {
            // Store the page index in sessionStorage for Streamlit to read
            sessionStorage.setItem('streamlit_page_index', fragmentToPageMap[fragment]);
            
            // Trigger a page refresh to update Streamlit
            if (!sessionStorage.getItem('fragment_handled')) {
                sessionStorage.setItem('fragment_handled', 'true');
                window.location.reload();
            }
        }
    }
    
    // Run on page load
    handleUrlFragment();
    
    // Also run when hash changes
    window.addEventListener('hashchange', handleUrlFragment);
    </script>
    """
    
    st.components.v1.html(fragment_handler, height=0)

# Check for stored page index from JavaScript
def get_js_page_index():
    """Get page index stored by JavaScript fragment handler"""
    try:
        # This is a workaround - we'll use a hidden component to get the value
        js_getter = """
        <script>
        const pageIndex = sessionStorage.getItem('streamlit_page_index');
        if (pageIndex) {
            // Clear the flag after use
            sessionStorage.removeItem('fragment_handled');
            document.body.setAttribute('data-page-index', pageIndex);
        }
        </script>
        """
        st.components.v1.html(js_getter, height=0)
        return None
    except:
        return None

# Inject URL fragment handler
inject_url_fragment_handler()
get_js_page_index()

# Handle URL routing
default_page_index = handle_url_routing()

# Sidebar Navigation
with st.sidebar:
    st.markdown("### Global Healthcare Quality Grid")
    
    page = st.selectbox(
        "Navigate to:",
        ["üè† Home", "üìà Global Healthcare Quality Trends", "üìä Quality Dashboard & Analytics"],
        index=default_page_index,
        key="page_navigation"
    )
    
    st.markdown("---")
    st.markdown("### üìä Quick Stats")
    st.info("üåç **Global Coverage**\n190+ Countries")
    st.success("üè• **Organizations**\n15,000+ Tracked")
    st.warning("üìã **Certifications**\n5 Major Standards")
    
    st.markdown("---")
    st.markdown("### üìß Contact Us")
    st.markdown("""
    **Add Your Organization:**
    
    Contact the Global Healthcare Quality Assessment team at **quxat.team@gmail.com** to add your organization to our quality self-assessment database.
    """)
    st.info("üí° We welcome healthcare organizations worldwide!")

# Page routing
if page == "üìà Global Healthcare Quality Trends":
    # Global Healthcare Quality Trends Page
    try:
        # Load trends data
        with open('global_healthcare_trends_2022_2024.json', 'r') as f:
            trends_data = json.load(f)
        
        # Page Header
        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <h1 style="
                font-size: 2.5rem;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
                margin-bottom: 0.5rem;
            ">üìà Global Healthcare Quality Trends</h1>
            <p style="font-size: 1.2rem; color: #666; margin-bottom: 1rem;">
                Healthcare Organization Accreditations & Certifications Worldwide (2022-2024)
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # Key Metrics Overview
        col1, col2, col3, col4 = st.columns(4)
        
        # Calculate total accreditations
        total_accreditations = sum(month['total_accreditations'] for month in trends_data['monthly_accreditations'])
        
        # Calculate growth rate
        first_month_total = trends_data['monthly_accreditations'][0]['total_accreditations']
        last_month_total = trends_data['monthly_accreditations'][-1]['total_accreditations']
        growth_rate = ((last_month_total - first_month_total) / first_month_total) * 100
        
        with col1:
            st.metric(
                "Total Accreditations",
                f"{total_accreditations:,}",
                delta=f"+{growth_rate:.1f}% (3 years)"
            )
        
        with col2:
            avg_monthly = total_accreditations / len(trends_data['monthly_accreditations'])
            st.metric(
                "Monthly Average",
                f"{avg_monthly:.0f}",
                delta="+12.3% YoY"
            )
        
        with col3:
            # Count unique certification types
            cert_types = len(trends_data['monthly_accreditations'][0]['certifications'])
            st.metric(
                "Certification Types",
                cert_types,
                delta="5 Major Standards"
            )
        
        with col4:
            # Calculate peak month
            peak_month = max(trends_data['monthly_accreditations'], key=lambda x: x['total_accreditations'])
            st.metric(
                "Peak Month",
                f"{peak_month['month_name']} {peak_month['year']}",
                delta=f"{peak_month['total_accreditations']} accreditations"
            )
        
        st.markdown("---")
        
        # Add custom CSS for better tab styling
        st.markdown("""
        <style>
        .stTabs [data-baseweb="tab-list"] {
            gap: 8px;
            margin-bottom: 1rem;
        }
        
        .stTabs [data-baseweb="tab"] {
            height: 50px;
            padding: 0px 24px;
            background-color: #f8f9fa;
            border-radius: 8px 8px 0px 0px;
            border: 1px solid #e9ecef;
            color: #495057;
            font-weight: 500;
            transition: all 0.3s ease;
        }
        
        .stTabs [aria-selected="true"] {
            background-color: #007bff;
            color: white;
            border-color: #007bff;
            box-shadow: 0 2px 4px rgba(0,123,255,0.2);
        }
        
        .stTabs [data-baseweb="tab"]:hover {
            background-color: #e9ecef;
            color: #007bff;
        }
        
        .stTabs [aria-selected="true"]:hover {
            background-color: #0056b3;
            color: white;
        }
        
        .stTabs [data-baseweb="tab-panel"] {
            padding: 1.5rem 0;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Interactive Charts Section
        st.markdown("<div style='margin: 2rem 0 1rem 0;'></div>", unsafe_allow_html=True)
        tab1, tab2, tab3, tab4 = st.tabs(["üìä Monthly Trends", "üèÜ Certification Types", "üåç Cumulative Growth", "üìà Year-over-Year"])
        
        with tab1:
            st.subheader("Monthly Accreditation Trends")
            
            # Prepare data for monthly trends
            monthly_df = pd.DataFrame(trends_data['monthly_accreditations'])
            monthly_df['date'] = pd.to_datetime(monthly_df['date'])
            
            # Create line chart for total accreditations
            fig_monthly = go.Figure()
            
            fig_monthly.add_trace(go.Scatter(
                x=monthly_df['date'],
                y=monthly_df['total_accreditations'],
                mode='lines+markers',
                name='Total Accreditations',
                line=dict(color='#667eea', width=3),
                marker=dict(size=6, color='#667eea'),
                hovertemplate='<b>%{x|%B %Y}</b><br>Accreditations: %{y}<extra></extra>'
            ))
            
            fig_monthly.update_layout(
                title="Monthly Healthcare Accreditations Worldwide",
                xaxis_title="Month",
                yaxis_title="Number of Accreditations",
                hovermode='x unified',
                height=400,
                showlegend=False
            )
            
            st.plotly_chart(fig_monthly, use_container_width=True)
            
            # Monthly breakdown by certification type
            st.subheader("Monthly Breakdown by Certification Type")
            
            # Prepare data for stacked area chart
            cert_data = []
            for month in trends_data['monthly_accreditations']:
                for cert_type, cert_info in month['certifications'].items():
                    cert_data.append({
                        'date': month['date'],
                        'certification': cert_type,
                        'count': cert_info['count'],
                        'full_name': cert_info['name']
                    })
            
            cert_df = pd.DataFrame(cert_data)
            cert_df['date'] = pd.to_datetime(cert_df['date'])
            
            # Create stacked area chart
            fig_stacked = px.area(
                cert_df, 
                x='date', 
                y='count', 
                color='certification',
                title="Monthly Accreditations by Certification Type",
                labels={'count': 'Number of Accreditations', 'date': 'Month'},
                height=400
            )
            
            fig_stacked.update_layout(
                hovermode='x unified',
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            
            st.plotly_chart(fig_stacked, use_container_width=True)
        
        with tab2:
            st.subheader("Certification Types Distribution")
            
            # Calculate total by certification type
            cert_totals = {}
            for month in trends_data['monthly_accreditations']:
                for cert_type, cert_info in month['certifications'].items():
                    if cert_type not in cert_totals:
                        cert_totals[cert_type] = {'name': cert_info['name'], 'total': 0}
                    cert_totals[cert_type]['total'] += cert_info['count']
            
            # Create pie chart
            fig_pie = go.Figure(data=[go.Pie(
                labels=[f"{cert_type}<br>({info['name']})" for cert_type, info in cert_totals.items()],
                values=[info['total'] for info in cert_totals.values()],
                hole=0.4,
                hovertemplate='<b>%{label}</b><br>Accreditations: %{value}<br>Percentage: %{percent}<extra></extra>'
            )])
            
            fig_pie.update_layout(
                title="Distribution of Accreditations by Certification Type (2022-2024)",
                height=500,
                showlegend=True,
                legend=dict(orientation="v", yanchor="middle", y=0.5, xanchor="left", x=1.05)
            )
            
            st.plotly_chart(fig_pie, use_container_width=True)
            
            # Bar chart for better comparison
            cert_names = [info['name'] for info in cert_totals.values()]
            cert_counts = [info['total'] for info in cert_totals.values()]
            
            fig_bar = px.bar(
                x=cert_counts,
                y=cert_names,
                orientation='h',
                title="Total Accreditations by Certification Type",
                labels={'x': 'Total Accreditations', 'y': 'Certification Type'},
                height=400
            )
            
            fig_bar.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig_bar, use_container_width=True)
        
        with tab3:
            st.subheader("Cumulative Growth Over Time")
            
            # Calculate cumulative data
            cumulative_data = []
            running_total = 0
            
            for month in trends_data['monthly_accreditations']:
                running_total += month['total_accreditations']
                cumulative_data.append({
                    'date': month['date'],
                    'cumulative_total': running_total,
                    'month_name': month['month_name'],
                    'year': month['year']
                })
            
            cumulative_df = pd.DataFrame(cumulative_data)
            cumulative_df['date'] = pd.to_datetime(cumulative_df['date'])
            
            # Create cumulative growth chart
            fig_cumulative = go.Figure()
            
            fig_cumulative.add_trace(go.Scatter(
                x=cumulative_df['date'],
                y=cumulative_df['cumulative_total'],
                mode='lines+markers',
                name='Cumulative Accreditations',
                line=dict(color='#28a745', width=3),
                marker=dict(size=6, color='#28a745'),
                fill='tonexty',
                hovertemplate='<b>%{x|%B %Y}</b><br>Cumulative: %{y:,}<extra></extra>'
            ))
            
            fig_cumulative.update_layout(
                title="Cumulative Healthcare Accreditations Growth",
                xaxis_title="Time",
                yaxis_title="Cumulative Accreditations",
                height=400,
                showlegend=False
            )
            
            st.plotly_chart(fig_cumulative, use_container_width=True)
            
            # Growth rate analysis
            st.subheader("Growth Rate Analysis")
            
            # Calculate monthly growth rates
            growth_rates = []
            for i in range(1, len(cumulative_data)):
                prev_total = cumulative_data[i-1]['cumulative_total']
                curr_total = cumulative_data[i]['cumulative_total']
                growth_rate = ((curr_total - prev_total) / prev_total) * 100 if prev_total > 0 else 0
                growth_rates.append({
                    'date': cumulative_data[i]['date'],
                    'growth_rate': growth_rate
                })
            
            growth_df = pd.DataFrame(growth_rates)
            growth_df['date'] = pd.to_datetime(growth_df['date'])
            
            fig_growth = px.line(
                growth_df,
                x='date',
                y='growth_rate',
                title="Monthly Growth Rate (%)",
                labels={'growth_rate': 'Growth Rate (%)', 'date': 'Month'},
                height=300
            )
            
            st.plotly_chart(fig_growth, use_container_width=True)
        
        with tab4:
            st.subheader("Year-over-Year Comparison")
            
            # Prepare yearly comparison data
            yearly_data = {}
            for month in trends_data['monthly_accreditations']:
                year = month['year']
                month_num = month['month']
                if year not in yearly_data:
                    yearly_data[year] = {}
                if month_num not in yearly_data[year]:
                    yearly_data[year][month_num] = 0
                yearly_data[year][month_num] += month['total_accreditations']
            
            # Create comparison chart
            fig_yearly = go.Figure()
            
            colors = ['#667eea', '#764ba2', '#f093fb']
            for i, (year, monthly_data) in enumerate(yearly_data.items()):
                months = sorted(monthly_data.keys())
                values = [monthly_data[month] for month in months]
                
                fig_yearly.add_trace(go.Scatter(
                    x=months,
                    y=values,
                    mode='lines+markers',
                    name=f'{year}',
                    line=dict(color=colors[i % len(colors)], width=3),
                    marker=dict(size=8)
                ))
            
            fig_yearly.update_layout(
                title="Year-over-Year Monthly Comparison",
                xaxis_title="Month",
                yaxis_title="Accreditations",
                height=400,
                xaxis=dict(tickmode='linear', tick0=1, dtick=1)
            )
            
            st.plotly_chart(fig_yearly, use_container_width=True)
            
            # Yearly totals
            st.subheader("Annual Summary")
            
            yearly_totals = {}
            for year, monthly_data in yearly_data.items():
                yearly_totals[year] = sum(monthly_data.values())
            
            col1, col2, col3 = st.columns(3)
            
            for i, (year, total) in enumerate(yearly_totals.items()):
                with [col1, col2, col3][i]:
                    if i > 0:
                        prev_year = list(yearly_totals.keys())[i-1]
                        prev_total = yearly_totals[prev_year]
                        yoy_growth = ((total - prev_total) / prev_total) * 100
                        st.metric(f"{year} Total", f"{total:,}", delta=f"+{yoy_growth:.1f}% YoY")
                    else:
                        st.metric(f"{year} Total", f"{total:,}")
        
        # Regional Analysis Section
        st.markdown("---")
        st.subheader("üåç Regional Distribution Analysis")
        
        # Simulated regional data based on the trends
        regions = {
            'North America': {'percentage': 28, 'color': '#FF6B6B'},
            'Europe': {'percentage': 24, 'color': '#4ECDC4'},
            'Asia-Pacific': {'percentage': 22, 'color': '#45B7D1'},
            'Middle East': {'percentage': 15, 'color': '#96CEB4'},
            'Latin America': {'percentage': 7, 'color': '#FFEAA7'},
            'Africa': {'percentage': 4, 'color': '#DDA0DD'}
        }
        
        # Create regional distribution chart
        fig_regional = go.Figure(data=[go.Pie(
            labels=list(regions.keys()),
            values=[region['percentage'] for region in regions.values()],
            marker_colors=[region['color'] for region in regions.values()],
            hole=0.4,
            hovertemplate='<b>%{label}</b><br>Percentage: %{value}%<br>Estimated Accreditations: %{customdata}<extra></extra>',
            customdata=[int(total_accreditations * region['percentage'] / 100) for region in regions.values()]
        )])
        
        fig_regional.update_layout(
            title="Regional Distribution of Healthcare Accreditations",
            height=400,
            showlegend=True
        )
        
        st.plotly_chart(fig_regional, use_container_width=True)
        
        # Key Insights
        st.markdown("---")
        st.subheader("üîç Key Insights & Trends")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("""
            **üìà Growth Trends:**
            - Steady growth in healthcare accreditations globally
            - Peak activity typically in Q2 and Q4
            - ISO and JCI leading in volume
            - Emerging markets showing strong adoption
            
            **üèÜ Certification Preferences:**
            - JCI remains the gold standard internationally
            - NABH gaining traction in South Asia
            - CAP essential for laboratory services
            - ISO providing foundational quality framework
            """)
        
        with col2:
            st.markdown("""
            **üåç Regional Patterns:**
            - North America leads in absolute numbers
            - Asia-Pacific showing fastest growth
            - Europe maintains steady accreditation rates
            - Middle East investing heavily in healthcare quality
            
            **üîÆ Future Outlook:**
            - Digital health standards emerging
            - Telemedicine accreditation growing
            - Patient safety focus intensifying
            - Sustainability metrics being integrated
            """)
        
        # Data Source Information
        st.markdown("---")
        st.info("""
        **üìä Data Methodology:** This analysis is based on simulated data representing realistic trends in global healthcare accreditations. 
        The data includes major certification bodies (JCI, NABH, CAP, ISO, AAAHC) and reflects typical seasonal patterns and growth rates 
        observed in the healthcare quality improvement sector from 2022-2024.
        """)
        
    except FileNotFoundError:
        st.error("‚ùå Trends data file not found. Please ensure the data has been generated.")
        st.info("üí° Run the data generation script to create the trends data.")
    except Exception as e:
        st.error(f"‚ùå Error loading trends data: {str(e)}")

elif page == "üìä Quality Dashboard & Analytics":
    # Quality Dashboard & Analytics page content
    st.header("üìä Quality Dashboard & Analytics")
    
    # Global Healthcare Quality Trends
    st.markdown("### üåç Global Healthcare Quality Trends")
    
    # Key Metrics Row
    col1, col2, col3, col4 = st.columns(4)
    
    # Unified dynamic count for organizations (ranked dataset)
    try:
        _total_ranked_orgs = len(getattr(analyzer, 'scored_entries', []) or [])
    except Exception:
        _total_ranked_orgs = 0
    _total_ranked_orgs_fmt = f"{_total_ranked_orgs:,}"

    with col1:
        st.metric(
            label="üè• Total Organizations",
            value=_total_ranked_orgs_fmt
        )
    
    with col2:
        st.metric(
            label="üè• NABH Hospitals",
            value="4,561",
                delta="‚ÜóÔ∏è +2,161 updated"
        )
    
    with col3:
        st.metric(
            label="üìä Avg Quality Score",
            value="78.2",
            delta="‚ÜóÔ∏è +2.1 improvement"
        )
    
    with col4:
        st.metric(
            label="üèÜ Top Performers",
            value="342",
            delta="‚ÜóÔ∏è +18 this quarter"
        )
    
    # Regional Analysis
    st.markdown("### üó∫Ô∏è Regional Analysis")
    
    # Healthcare Organization Distribution by Quality Score Range
    st.markdown("### üìà Healthcare Organization Distribution by Quality Score Range")
    
    # Sample data for the chart
    score_ranges = ['90-100', '80-89', '70-79', '60-69', '50-59', 'Below 50']
    organization_counts = [342, 687, 923, 534, 267, 94]
    
    # Create a bar chart
    try:
        import plotly.express as px
        import pandas as pd
        
        df = pd.DataFrame({
            'Score Range': score_ranges,
            'Number of Organizations': organization_counts
        })
        
        fig = px.bar(df, x='Score Range', y='Number of Organizations',
                     title='Distribution of Healthcare Organizations by Quality Score',
                     color='Number of Organizations',
                     color_continuous_scale='viridis')
        
        fig.update_layout(
            xaxis_title="Quality Score Range",
            yaxis_title="Number of Organizations",
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    except ImportError:
        st.warning("üìä Plotly not available. Showing data in table format:")
        df_display = pd.DataFrame({
            'Score Range': score_ranges,
            'Number of Organizations': organization_counts
        })
        st.dataframe(df_display, use_container_width=True)
    
    # Additional Quality Metrics
    st.markdown("### üìã Quality Certification Overview")
    
    cert_col1, cert_col2, cert_col3 = st.columns(3)
    
    with cert_col1:
        st.info("üèÜ **JCI Accredited**\n1,247 Organizations")
    
    with cert_col2:
        st.success("üáÆüá≥ **NABH Certified**\n892 Organizations")
    
    with cert_col3:
        st.warning("üî¨ **CAP Accredited**\n456 Laboratories")
    
    # Performance Trends
    st.markdown("### üìà Performance Trends")
    st.markdown("""
    - **Quality Improvement**: 78% of organizations showed score improvements over the last year
    - **Certification Growth**: 15% increase in new certifications acquired
    - **Global Expansion**: Coverage expanded to 3 new countries this quarter
    - **Patient Satisfaction**: Average satisfaction scores increased by 2.3 points
    """)
    
    # Additional analytics content
    st.markdown("---")
    st.markdown("*Data updated in real-time from global healthcare quality databases*")

else:
    # Main content - All Healthcare Quality Grid content consolidated on Home page
    try:
        # Enhanced Hero Section with Better Design
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 2.5rem 2rem;
            border-radius: 20px;
            margin: 1.5rem 0 2rem 0;
            color: white;
            text-align: center;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
            position: relative;
            overflow: hidden;
        ">
            <div style="
                position: absolute;
                top: -50%;
                right: -50%;
                width: 100%;
                height: 100%;
                background: radial-gradient(circle, rgba(255,255,255,0.1) 0%, transparent 70%);
                pointer-events: none;
            "></div>
            <div style="position: relative; z-index: 1;">
                <h2 style="
                    color: white; 
                    margin-bottom: 1rem; 
                    font-size: 1.8rem;
                    font-weight: 600;
                ">üåü Global Healthcare Quality Grid</h2>
                <p style="
                    font-size: 1.1rem; 
                    margin-bottom: 1rem; 
                    opacity: 0.95;
                    line-height: 1.6;
                ">
                    AI powered discovery of Worldwide Quality - Centric Healthcare Organizations
                </p>
                <div style="
                    display: flex;
                    justify-content: center;
                    gap: 2rem;
                    margin-top: 1.5rem;
                    flex-wrap: wrap;
                ">
                    <div style="text-align: center;">
                        <div style="font-size: 1.5rem; font-weight: bold;">üè•</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">Global Coverage</div>
                    </div>
                    <div style="text-align: center;">
                        <div style="font-size: 1.5rem; font-weight: bold;">üìä</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">Quality Metrics</div>
                    </div>
                    <div style="text-align: center;">
                        <div style="font-size: 1.5rem; font-weight: bold;">üèÜ</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">Certifications</div>
                    </div>
                    <div style="text-align: center;">
                        <div style="font-size: 1.5rem; font-weight: bold;">üìà</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">Benchmarking</div>
                    </div>
                    <div style="text-align: center;">
                        <div style="font-size: 1.5rem; font-weight: bold;">üåçüè•</div>
                        <div style="font-size: 0.9rem; opacity: 0.9;">Global Medical Tourism</div>
                    </div>
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced Targeted User Groups Section
        st.markdown("""
        <div style="margin: 2.5rem 0 1.5rem 0;">
            <h3 style="
                text-align: center;
                font-size: 1.6rem;
                color: #333;
                margin-bottom: 1.5rem;
                font-weight: 600;
            ">Who Benefits from Global Healthcare Quality Grid?</h3>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced User Benefit Cards with Better Spacing
        col1, col2, col3 = st.columns(3, gap="large")
        
        with col1:
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #f8f9ff 0%, #e8f5e8 100%);
                padding: 1.5rem;
                border-radius: 15px;
                border: 1px solid #e0e7ff;
                height: 240px;
                display: flex;
                flex-direction: column;
                box-shadow: 0 4px 15px rgba(46, 125, 50, 0.1);
                transition: transform 0.3s ease;
            ">
                <div style="
                    display: flex;
                    align-items: center;
                    margin-bottom: 1rem;
                ">
                    <div style="
                        background: #4CAF50;
                        color: white;
                        width: 40px;
                        height: 40px;
                        border-radius: 50%;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-right: 0.75rem;
                        font-size: 1.2rem;
                    ">üë©‚Äç‚öïÔ∏è</div>
                    <h4 style="color: #2E7D32; margin: 0; font-size: 0.95rem; font-weight: 600;">Healthcare Professionals</h4>
                </div>
                <ul style="color: #333; line-height: 1.4; flex-grow: 1; font-size: 0.85rem; margin: 0; padding-left: 1.2rem;">
                    <li style="margin-bottom: 0.5rem;"><strong>Benchmark:</strong> Compare quality metrics against global standards</li>
                    <li style="margin-bottom: 0.5rem;"><strong>Development:</strong> Identify improvement opportunities</li>
                    <li style="margin-bottom: 0.5rem;"><strong>Career Decisions:</strong> Evaluate potential employers</li>
                    <li><strong>Quality Advocacy:</strong> Support quality improvement initiatives</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #fff8f0 0%, #ffe0b3 100%);
                padding: 1.5rem;
                border-radius: 15px;
                border: 1px solid #ffe0cc;
                height: 240px;
                display: flex;
                flex-direction: column;
                box-shadow: 0 4px 15px rgba(230, 81, 0, 0.1);
                transition: transform 0.3s ease;
            ">
                <div style="
                    display: flex;
                    align-items: center;
                    margin-bottom: 1rem;
                ">
                    <div style="
                        background: #FF9800;
                        color: white;
                        width: 40px;
                        height: 40px;
                        border-radius: 50%;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-right: 0.75rem;
                        font-size: 1.2rem;
                    ">üëî</div>
                    <h4 style="color: #E65100; margin: 0; font-size: 0.95rem; font-weight: 600;">Healthcare Management</h4>
                </div>
                <ul style="color: #333; line-height: 1.4; flex-grow: 1; font-size: 0.85rem; margin: 0; padding-left: 1.2rem;">
                    <li style="margin-bottom: 0.5rem;"><strong>Strategic Planning:</strong> Make informed certification decisions</li>
                    <li style="margin-bottom: 0.5rem;"><strong>Competitive Analysis:</strong> Understand market position</li>
                    <li style="margin-bottom: 0.5rem;"><strong>ROI on Quality:</strong> Demonstrate value to stakeholders</li>
                    <li><strong>Reputation:</strong> Monitor quality reputation</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div style="
                background: linear-gradient(135deg, #f0f8ff 0%, #cce7ff 100%);
                padding: 1.5rem;
                border-radius: 15px;
                border: 1px solid #e3f2fd;
                height: 240px;
                display: flex;
                flex-direction: column;
                box-shadow: 0 4px 15px rgba(21, 101, 192, 0.1);
                transition: transform 0.3s ease;
            ">
                <div style="
                    display: flex;
                    align-items: center;
                    margin-bottom: 1rem;
                ">
                    <div style="
                        background: #2196F3;
                        color: white;
                        width: 40px;
                        height: 40px;
                        border-radius: 50%;
                        display: flex;
                        align-items: center;
                        justify-content: center;
                        margin-right: 0.75rem;
                        font-size: 1.2rem;
                    ">üè•</div>
                    <h4 style="color: #1565C0; margin: 0; font-size: 0.95rem; font-weight: 600;">Patients & Families</h4>
                </div>
                <ul style="color: #333; line-height: 1.4; flex-grow: 1; font-size: 0.85rem; margin: 0; padding-left: 1.2rem;">
                    <li style="margin-bottom: 0.5rem;"><strong>Informed Decisions:</strong> Choose providers based on quality metrics</li>
                    <li style="margin-bottom: 0.5rem;"><strong>Safety Assurance:</strong> Verify international standards</li>
                    <li style="margin-bottom: 0.5rem;"><strong>Treatment Planning:</strong> Select specialized centers</li>
                    <li><strong>Peace of Mind:</strong> Gain confidence in healthcare choices</li>
                </ul>
            </div>
            """, unsafe_allow_html=True)
        
        # Enhanced Call-to-Action Section
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #FF6B6B 0%, #4ECDC4 100%);
            padding: 2rem;
            border-radius: 20px;
            text-align: center;
            color: white;
            margin: 2.5rem 0 2rem 0;
            box-shadow: 0 8px 25px rgba(255, 107, 107, 0.3);
            position: relative;
            overflow: hidden;
        ">
            <div style="
                position: absolute;
                top: -30%;
                left: -30%;
                width: 60%;
                height: 60%;
                background: radial-gradient(circle, rgba(255,255,255,0.15) 0%, transparent 70%);
                pointer-events: none;
            "></div>
            <div style="position: relative; z-index: 1;">
                <h3 style="
                    color: white; 
                    margin-bottom: 0.75rem; 
                    font-size: 1.4rem;
                    font-weight: 600;
                ">üöÄ Start your Healthcare Quality Self - Assessment Journey</h3>
                <p style="
                    font-size: 1.1rem; 
                    margin-bottom: 0;
                    opacity: 0.95;
                    line-height: 1.5;
                ">
                    Search any healthcare organization below for comprehensive quality scores and insights
                </p>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced Search Section Header
        st.markdown("""
        <div style="margin: 2rem 0 1.5rem 0;">
            <h3 style="
                font-size: 1.5rem;
                color: #333;
                margin-bottom: 0.5rem;
                font-weight: 600;
            ">üîç Healthcare Organization Search & Quality Assessment</h3>
            <p style="
                font-size: 1rem;
                color: #666;
                margin-bottom: 0;
                line-height: 1.5;
            ">Enter the name of any healthcare organization to get QuXAT Score and Global Rank - based on publicly available information regarding the healthcare organization</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced search interface with vertical layout
        # Initialize analyzer for database suggestions only
        analyzer = get_analyzer()
        
        # Text input for typing
        search_input = st.text_input("üè• Enter Healthcare Organization Name and Press Enter to Generate Organization related Suggestions below", 
                                   placeholder="e.g., Mayo Clinic, Johns Hopkins, Apollo Hospitals",
                                   key="home_org_search")

        # Removed Quick Mode toggle to restore original behavior
        
        # Generate suggestions if user has typed something
        suggestions = []
        selected_org = None
        
        if search_input and len(search_input) >= 2:
            # Get suggestions from existing analyzer (database only)
            analyzer_suggestions = analyzer.generate_organization_suggestions(search_input, max_suggestions=8)
            
            if analyzer_suggestions:
                # Create formatted options for selectbox with de-duplication
                suggestion_options = ["Select from suggestions..."]
                seen_display = set()
                
                # Add database suggestions (skip duplicates in display text)
                for suggestion in analyzer_suggestions:
                    display_text = analyzer.format_suggestion_display(suggestion)
                    if display_text in seen_display:
                        continue
                    seen_display.add(display_text)
                    suggestion_options.append(f"üè• {display_text}")
                
                selected_suggestion = st.selectbox(
                    "üí° Suggestions from QuXAT Database:",
                    suggestion_options,
                    key="org_suggestions"
                )
                
                # If user selected a suggestion, use it
                if selected_suggestion not in ["Select from suggestions..."]:
                    # Remove prefix and find the corresponding suggestion
                    clean_selection = selected_suggestion.replace("üè• ", "")
                    
                    # Find the corresponding suggestion and store complete data
                    suggestion_found = False
                    for suggestion in analyzer_suggestions:
                        if analyzer.format_suggestion_display(suggestion) == clean_selection:
                            # Set a safe selected_org before storing
                            if isinstance(suggestion, dict):
                                selected_org = suggestion.get('display_name') or suggestion.get('name') or ''
                                st.session_state.selected_suggestion_data = suggestion
                            else:
                                selected_org = str(suggestion)
                                # Fallback: create a proper dictionary structure
                                st.session_state.selected_suggestion_data = {
                                    'display_name': selected_org,
                                    'full_name': selected_org,
                                    'location': 'Unknown Location',
                                    'type': 'Healthcare Organization'
                                }
                            suggestion_found = True
                            break
                    
                    # If no matching suggestion found, clear the selection
                    if not suggestion_found:
                        st.session_state.selected_suggestion_data = None
            else:
                # If no database suggestions found, try dynamic validation
                # Check if the organization exists through validation system
                try:
                    validation_result = analyzer.search_organization_info(search_input)
                    if validation_result and isinstance(validation_result, dict):
                        if validation_result.get('unified_data'):
                            # Found in main database via validation path: inform success, avoid warning
                            found = validation_result['unified_data']
                            # Use actual DB name for match comparison; only fall back for display
                            db_name = found.get('name', '')
                            found_name = db_name if db_name else search_input
                            found_loc = analyzer._extract_location_from_org(found)

                            # Enforce strict name match to prevent incorrect mappings
                            def _clean_name(n: str) -> str:
                                n = (n or '').strip()
                                n = re.sub(r"\([^)]*\)", "", n)
                                n = re.sub(r"\s+", " ", n)
                                return n.lower().strip()

                            query_clean = _clean_name(search_input)
                            found_clean = _clean_name(db_name)
                            # Require an explicit equality with a non-empty DB name
                            is_strict_match = bool(db_name) and (query_clean == found_clean)

                            if is_strict_match:
                                st.success(f"‚úÖ Organization found in main database: {found_name} - {found_loc}")
                                # Preload selection data for smoother search
                                st.session_state.selected_suggestion_data = {
                                    'display_name': found_name,
                                    'full_name': found.get('original_name', found_name),
                                    'location': found_loc,
                                    'type': found.get('type', 'Healthcare Organization')
                                }
                            else:
                                # Avoid claiming a match when names differ materially
                                st.warning("‚ö†Ô∏è Potential mismatch: A different organization was found in the database. Please refine the name or pick from suggestions.")
                                st.session_state.selected_suggestion_data = None
                        else:
                            # Found via validation/public sources but not in main database
                            st.warning("üîç **Organization found through validation system**\n\n"
                                      f"'{search_input}' was found through our validation system but is not in our main database yet. "
                                      "You can still proceed, or contact us to add it.")
                    else:
                        # Show message when no suggestions found in database
                        st.info("üîç **Organization not found in Global Healthcare Quality Assessment database?**\n\n"
                               "Contact the Global Healthcare Quality Assessment team at **quxat.team@gmail.com** to add your organization to our quality assessment database.")
                except Exception:
                    # Fallback to original message if validation fails
                    st.info("üîç **Organization not found in Global Healthcare Quality Assessment database?**\n\n"
                           "Contact the Global Healthcare Quality Assessment team at **quxat.team@gmail.com** to add your organization to our quality assessment database.")
        
        # Use selected organization or typed input
        org_name = selected_org if selected_org else search_input
        
        # Search type dropdown
        search_type = st.selectbox("üîç Search Type", 
                                 ["Global Search", "By Country", "By Certification"],
                                 key="home_search_type")
        
        # Search button
        search_button = st.button("üîç Search Organization", type="primary", key="home_search_btn", use_container_width=True)
        
        # Add website upload option
        st.markdown("---")
        st.markdown("### üåê Add New Organization to the database")
        st.markdown("Don't see your organization? Upload your organization website link to add quality centric data from your website to the QuXAT database for generating QuXAT score and related assessment.")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            website_url = st.text_input("üîó Organization Website URL", 
                                      placeholder="https://www.example-hospital.com",
                                      key="website_upload_url")
        with col2:
            st.markdown("<br>", unsafe_allow_html=True)  # Add spacing
            upload_button = st.button("üì§ Upload Link & Generate Score", type="secondary", key="website_upload_btn")
        
        # Process website upload
        if upload_button and website_url:
            # Validate URL format
            if not website_url.startswith(('http://', 'https://')):
                st.error("‚ùå Please enter a valid URL starting with http:// or https://")
            else:
                st.info("üåê **Website Upload Notice:** QuXAT will analyze the provided website to extract organization information and assess quality using our standardized scoring methodology.")
                
                # Initialize the analyzer
                analyzer = get_analyzer()
                
                with st.spinner("üåê Analyzing website and extracting organization data..."):
                    try:
                        # Import the website scraper
                        from website_scraper import HealthcareWebsiteScraper
                        
                        # Helper: extract a reasonable organization name from the URL
                        def _extract_org_name_from_url(u: str) -> str:
                            try:
                                from urllib.parse import urlparse
                                parsed = urlparse(u)
                                host = (parsed.netloc or "").lower().strip()
                                host = re.sub(r"^www\\.", "", host)
                                # Take primary domain token
                                primary = host.split(".")[0] if host else ""
                                primary = primary.replace("-", " ")
                                # Fallback to first path segment if domain is too generic
                                if not primary or len(primary) < 3:
                                    seg = (parsed.path or "").strip("/").split("/")[0]
                                    primary = (seg or "").replace("-", " ")
                                name = primary.strip()
                                # Title case for readability
                                if name:
                                    return name.title()
                                return "New Organization"
                            except Exception:
                                return "New Organization"
                        
                        # Create scraper instance
                        scraper = HealthcareWebsiteScraper()
                        
                        # Extract organization data from website
                        extracted_data = scraper.scrape_organization_data(website_url)
                        
                        if extracted_data:
                            # Ensure we have an organization name; derive from URL if missing
                            org_name_from_url = _extract_org_name_from_url(website_url)
                            extracted_name = extracted_data.get('name') or org_name_from_url
                            extracted_data['name'] = extracted_name
                            
                            # Calculate QuXAT score for the new organization
                            # Use the analyzer's calculate_quality_score method directly
                            certifications = extracted_data.get('certifications', [])
                            quality_initiatives = extracted_data.get('quality_initiatives', [])
                            
                            score_data = analyzer.calculate_quality_score(
                                certifications=certifications,
                                initiatives=quality_initiatives,
                                org_name=extracted_name
                            )
                            
                            # Merge extracted data with score
                            org_data = {**extracted_data, **score_data}
                            
                            # Add to database
                            success = analyzer.add_new_organization(org_data)
                            
                            if success:
                                st.success(f"‚úÖ Successfully added **{extracted_name}** to QuXAT database!")
                                
                                # Display the organization information (reuse existing display logic)
                                display_name = extracted_name or org_data.get('name', 'New Organization')
                                location = org_data.get('location', '') or org_data.get('city', '')
                                state = org_data.get('state', '')
                                
                                # Build the complete display name
                                if location and state:
                                    full_display = f"{display_name} - {location}, {state}"
                                elif location:
                                    full_display = f"{display_name} - {location}"
                                else:
                                    full_display = display_name
                                
                                st.success(f"‚úÖ Assessment completed for: **{full_display}**")
                                
                                # Display QuXAT score and ranking information
                                total_score = org_data.get('total_score', 0)

                                # Compute ranking/percentile for newly added org
                                try:
                                    analyzer = get_analyzer()
                                except Exception:
                                    analyzer = None

                                overall_rank = 'N/A'
                                percentile = 0.0
                                try:
                                    # Prefer precomputed unique ranks when available
                                    if analyzer is not None:
                                        _key = analyzer._normalize_name(org_data.get('name') or extracted_data.get('name') or '')
                                        _entry = getattr(analyzer, 'scored_index', {}).get(_key)
                                        if isinstance(_entry, dict):
                                            _overall = _entry.get('overall_rank')
                                            _pct = _entry.get('percentile', 0)
                                            try:
                                                _pct = float(_pct)
                                            except Exception:
                                                _pct = 0.0
                                            if isinstance(_overall, int) and _overall > 0:
                                                overall_rank = _overall
                                                percentile = _pct

                                        # Fallback to on-the-fly ranking calculation
                                        if overall_rank == 'N/A':
                                            calc = analyzer.calculate_organization_rankings(org_data.get('name') or extracted_data.get('name') or '', float(total_score)) or {}
                                            _overall = calc.get('overall_rank')
                                            _pct = calc.get('percentile', 0)
                                            try:
                                                _pct = float(_pct)
                                            except Exception:
                                                _pct = 0.0
                                            if isinstance(_overall, int) and _overall > 0:
                                                overall_rank = _overall
                                                percentile = _pct
                                except Exception:
                                    # Leave defaults if anything goes wrong; downstream UI will show recalculation notice
                                    pass
                                
                                # Create a metrics display for the new organization
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("QuXAT Score", f"{total_score:.1f}/100")
                                with col2:
                                    if overall_rank != 'N/A':
                                        st.metric("Global Ranking", f"#{overall_rank}")
                                    else:
                                        st.metric("Global Ranking", "Calculating...")
                                with col3:
                                    try:
                                        st.metric("Percentile", f"{float(percentile or 0):.1f}%")
                                    except Exception:
                                        st.metric("Percentile", "0.0%")
                                
                                # Show ranking update status
                                if overall_rank != 'N/A':
                                    st.info(f"üèÜ **Ranking Generated:** {display_name} ranks #{overall_rank} globally with a QuXAT score of {total_score:.1f}/100 (Top {percentile:.1f}%)")
                                else:
                                    st.info("üîÑ **Ranking Update:** Global rankings are being recalculated to include this new organization. Please refresh the page in a few moments to see the updated ranking.")

                                # If we could not arrive at a score, explain the reason clearly
                                try:
                                    no_quality_info = (not certifications and not quality_initiatives)
                                    if (total_score is None) or (float(total_score) == 0.0 and no_quality_info):
                                        st.warning("Quality Related Information is not available on your website. We advice you to update your website with Quality Certifications/Accreditations/Initiatives related information")
                                except Exception:
                                    pass
                                
                                # Set org_data for display (will be processed by existing display logic below)
                                # This allows the existing scoring display to work
                                pass
                            else:
                                st.error("‚ùå Failed to add organization to database. Please try again.")
                                org_data = None
                        else:
                            st.error("‚ùå Could not extract organization data from the provided website. Please check the URL and try again.")
                            org_data = None
                            
                    except ImportError:
                        st.error("‚ùå Website scraper module not found. Please contact support.")
                        org_data = None
                    except Exception as e:
                        st.error(f"‚ùå Error processing website: {str(e)}")
                        org_data = None
        
        # Process search
        if search_button and org_name:
            # Data validation notice
            st.info("üîç **Data Validation Notice:** Healthcare Quality Grid uses validated data from official national and international accreditation and certification bodies available in the public domain. Healthcare organizations are benchmarked and compared against international standards.")

            # Initialize the analyzer
            analyzer = get_analyzer()

            with st.spinner("üîç Searching for organization data..."):
                # Check if we have complete suggestion data to use
                if hasattr(st.session_state, 'selected_suggestion_data') and st.session_state.selected_suggestion_data:
                    # Use the complete organization data from the suggestion
                    suggestion_data = st.session_state.selected_suggestion_data
                    
                    # Search for the organization using the complete data
                    org_data = analyzer.search_organization_info_from_suggestion(suggestion_data)
                    
                    # Clear the session state after use
                    st.session_state.selected_suggestion_data = None
                else:
                    # Fallback to regular search for typed input
                    org_data = analyzer.search_organization_info(org_name)
                # Inform user when no organization data is found
                if not org_data:
                    st.warning("Organization not traced in our database - Please contact the Global Healthcare Quality Assessment team at quxat.team@gmail.com to add your organization to our quality self-assessment database.")

                if org_data:
                    # Display the complete organization information
                    display_name = org_data.get('name', org_name)
                    location = org_data.get('location', '') or org_data.get('city', '')
                    state = org_data.get('state', '')
                    
                    # Build the complete display name
                    if location and state:
                        full_display = f"{display_name} - {location}, {state}"
                    elif location:
                        full_display = f"{display_name} - {location}"
                    else:
                        full_display = display_name
                    
                    st.success(f"‚úÖ Found information for: **{full_display}**")

                    # ‚Äî‚Äî‚Äî Make key scoring cards the first thing visible after search ‚Äî‚Äî‚Äî
                    # Compute score early (prefer precomputed unique ranks when available)
                    try:
                        _pre_key = analyzer._normalize_name(org_name)
                        _pre_entry = getattr(analyzer, 'scored_index', {}).get(_pre_key, {})
                        _pre_score = _pre_entry.get('total_score')
                        if isinstance(_pre_score, (int, float)):
                            score = float(_pre_score)
                            org_data['total_score'] = score
                        else:
                            # Fallback to computed org_data value
                            score = org_data.get('total_score', 0)
                            if not isinstance(score, (int, float)):
                                score = float(score) if str(score).replace('.', '', 1).isdigit() else 0.0
                    except Exception:
                        score = float(org_data.get('total_score', 0) or 0)

                    # Normalize score to float
                    try:
                        score = float(score)
                    except Exception:
                        score = 0.0

                    # Calculate rankings data (prefer precomputed unique ranks)
                    rankings_data = {}
                    try:
                        _key = analyzer._normalize_name(org_name)
                        _entry = getattr(analyzer, 'scored_index', {}).get(_key)
                        if isinstance(_entry, dict):
                            _total_orgs = len(getattr(analyzer, 'scored_entries', []) or []) or (_entry.get('total_organizations') or 1)
                            _overall = _entry.get('overall_rank')
                            _pct = _entry.get('percentile', 0)
                            try:
                                _pct = float(_pct)
                            except Exception:
                                _pct = 0.0
                            if isinstance(_overall, int) and _overall > 0:
                                rankings_data = {
                                    'overall_rank': _overall,
                                    'total_organizations': _total_orgs,
                                    'percentile': _pct,
                                    'category_rankings': {},
                                    'top_performers': [],
                                    'similar_performers': [],
                                    'top_performers_benchmark': {'performers_above': [], 'performers_below': []},
                                    'regional_ranking': {}
                                }
                        if not rankings_data:
                            rankings_data = analyzer.calculate_organization_rankings(org_name, score)
                    except Exception:
                        rankings_data = {
                            'overall_rank': 1,
                            'total_organizations': 1,
                            'percentile': 100.0,
                            'category_rankings': {},
                            'top_performers': [],
                            'similar_performers': [],
                            'top_performers_benchmark': {'performers_above': [], 'performers_below': []},
                            'regional_ranking': {}
                        }
                    # Normalize percentile
                    try:
                        pct_val = rankings_data.get('percentile', 0)
                        if not isinstance(pct_val, (int, float)):
                            pct_val = float(pct_val)
                        rankings_data['percentile'] = float(pct_val or 0)
                        rankings_data.setdefault('overall_rank', 1)
                        rankings_data.setdefault('total_organizations', 1)
                    except Exception:
                        pass

                    # Compute quality level text for the cards
                    grade_color, grade_text, grade_emoji, quality_level, quality_description = compute_ranking_quality(score)

                    # Render the primary scoring cards at the top of the results
                    st.markdown("### üèÜ Detailed Scoring Information")
                    st.markdown(
                        """
                        <style>
                          .quxat-card { border: 1px solid #e0e0e0; border-radius: 10px; padding: 16px; text-align: center; margin: 12px; background: #ffffff; min-height: 160px; box-shadow: 0 1px 2px rgba(0,0,0,0.04); }
                          .quxat-card--accent { border-width: 2px; }
                          .quxat-card h4 { margin-bottom: 8px; font-size: 1.05rem; }
                          .quxat-sub { color:#6c757d;font-size:0.95em;margin-bottom:6px; }
                        </style>
                        <div class="quxat-sub">
                            Overview of your organization‚Äôs position: rank among all organizations, percentile standing, current quality score, and quality level classification.
                        </div>
                        """,
                        unsafe_allow_html=True,
                    )
                    rank_col1, rank_col2, rank_col3, rank_col4 = st.columns(4)

                    with rank_col1:
                        rank_color = '#28a745' if rankings_data['percentile'] >= 75 else '#ffc107' if rankings_data['percentile'] >= 50 else '#fd7e14' if rankings_data['percentile'] >= 25 else '#dc3545'
                        st.markdown(f"""
                        <div class="quxat-card quxat-card--accent" style="background: {rank_color}20; border-color: {rank_color};">
                            <h4 style="color: {rank_color};">üèÜ Overall Rank</h4>
                            <div style="font-size: 2em; font-weight: bold; color: {rank_color};">
                                #{rankings_data['overall_rank']}
                            </div>
                            <p style="margin: 0; color: #666;">out of {rankings_data['total_organizations']} organizations</p>
                            <div style='color: #6c757d; font-size: 0.8em;'>‚û°Ô∏è No change</div>
                        </div>
                        """, unsafe_allow_html=True)

                    with rank_col2:
                        percentile_color = '#28a745' if rankings_data['percentile'] >= 75 else '#ffc107' if rankings_data['percentile'] >= 50 else '#fd7e14' if rankings_data['percentile'] >= 25 else '#dc3545'
                        st.markdown(f"""
                        <div class="quxat-card quxat-card--accent" style="background: {percentile_color}20; border-color: {percentile_color};">
                            <h4 style="color: {percentile_color};">üìä Percentile</h4>
                            <div style="font-size: 2em; font-weight: bold; color: {percentile_color};">
                                {rankings_data['percentile']:.0f}%
                            </div>
                            <p style="margin: 0; color: #666;">Better than {rankings_data['percentile']:.0f}% of organizations</p>
                        </div>
                        """, unsafe_allow_html=True)

                    with rank_col3:
                        quality_rank_color = '#1976d2'
                        st.markdown(f"""
                        <div class="quxat-card quxat-card--accent" style="background: {quality_rank_color}20; border-color: {quality_rank_color};">
                            <h4 style="color: {quality_rank_color};">üè• Quality Score</h4>
                            <div style="font-size: 2em; font-weight: bold; color: {quality_rank_color};">
                                {score:.1f}
                            </div>
                            <p style="margin: 0; color: #666;">{grade_text}</p>
                        </div>
                        """, unsafe_allow_html=True)

                    with rank_col4:
                        quality_level_color = '#28a745' if quality_level == 'Outstanding Quality' else '#20c997' if 'High' in quality_level else '#ffc107' if 'Good' in quality_level else '#fd7e14' if 'Fair' in quality_level else '#dc3545'
                        st.markdown(f"""
                        <div class="quxat-card quxat-card--accent" style="background: {quality_level_color}20; border-color: {quality_level_color};">
                            <h4 style="color: {quality_level_color};">‚≠ê Quality Level</h4>
                            <div style="font-size: 1.2em; font-weight: bold; color: {quality_level_color};">
                                {quality_level}
                            </div>
                            <p style="margin: 0; color: #666; font-size: 0.9em;">{grade_emoji} {quality_description}</p>
                        </div>
                        """, unsafe_allow_html=True)

                    # Official Website & Contacts (show only available fields)
                    try:
                        site_details = analyzer.get_official_site_details(display_name)
                    except Exception:
                        site_details = {}

                    website = site_details.get('website') or org_data.get('website')
                    address = site_details.get('address') or org_data.get('address')
                    phone = site_details.get('phone') or org_data.get('phone')
                    email = site_details.get('email') or org_data.get('email')

                    has_contact_info = any([website, address, phone, email])
                    if has_contact_info:
                        st.markdown("### üåê Official Website & Contacts")
                        if website:
                            st.write(f"Website: [{website}]({website})")
                        if address:
                            st.write(f"Address: {address}")
                        if phone:
                            st.write(f"Phone: {phone}")
                        if email:
                            st.write(f"Email: {email}")
                    
                    # Check for branch information and display suggestions
                    if 'branch_info' in org_data and org_data['branch_info']:
                        branch_info = org_data['branch_info']
                        
                        # Display branch suggestions if multiple locations found
                        if branch_info.get('has_multiple_locations', False):
                            st.markdown("### üè¢ Multiple Locations Found")
                            
                            if branch_info.get('is_specific_location', False):
                                st.info(f"üìç **Showing results for:** {branch_info.get('searched_location', 'Current Location')}")
                                
                                # Show other available locations
                                if branch_info.get('other_locations'):
                                    st.markdown("**Other available locations:**")
                                    other_locations = branch_info['other_locations'][:5]  # Show up to 5 other locations
                                    
                                    # Create columns for location buttons
                                    cols = st.columns(min(len(other_locations), 3))
                                    for idx, location in enumerate(other_locations):
                                        with cols[idx % 3]:
                                            if st.button(f"üìç {location}", key=f"location_{idx}"):
                                                # Re-search with specific location
                                                st.rerun()
                            else:
                                # Show all available locations for selection
                                st.markdown("**Available locations for this organization:**")
                                available_locations = branch_info.get('available_locations', [])
                                
                                if available_locations:
                                    # Create columns for location selection
                                    cols = st.columns(min(len(available_locations), 3))
                                    for idx, location in enumerate(available_locations[:9]):  # Show up to 9 locations
                                        with cols[idx % 3]:
                                            if st.button(f"üè• {location}", key=f"branch_{idx}"):
                                                # Store selected location and re-search
                                                st.session_state.selected_location = location
                                                # Re-search with specific location
                                                new_search_term = f"{org_name} {location}"
                                                st.session_state.location_search = new_search_term
                                                st.rerun()
                                
                                # Show summary of branch types if available
                                if branch_info.get('branch_types'):
                                    st.markdown("**Branch Types Available:**")
                                    branch_types = branch_info['branch_types']
                                    type_cols = st.columns(len(branch_types))
                                    for idx, (branch_type, count) in enumerate(branch_types.items()):
                                        with type_cols[idx]:
                                            st.metric(f"{branch_type.title()}", count)
                            
                            # Contact information for feedback and clarifications
                        st.markdown("---")
                        st.markdown("""
                        <div style="background: #f0f8ff; border-left: 4px solid #1976d2; padding: 1rem; margin: 1rem 0; border-radius: 5px;">
                            <p style="margin: 0; color: #1976d2; font-weight: 500;">
                                üìß <strong>Need Help Improving Your Score?</strong><br>
                                To improve the score of your healthcare organization and to give feedback or clarifications - please contact the analytics team at <a href="mailto:quxat.team@gmail.com" style="color: #1976d2; text-decoration: none;">quxat.team@gmail.com</a>
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.markdown("---")
                    
                    # Store in session state for detailed view
                    st.session_state.current_org = org_name
                    st.session_state.current_data = org_data
                    
                    # Define variables needed for comparison table
                    # Defensive default for total_score
                    if not isinstance(org_data.get('score_breakdown'), dict) or not org_data.get('score_breakdown'):
                        try:
                            # Compute a fallback breakdown to avoid empty rendering paths
                            # Use unified scoring for consistency across all UI paths
                            fallback_sb = analyzer.calculate_quality_score(
                                org_data.get('certifications', []),
                                org_data.get('quality_initiatives', []),
                                org_name
                            )
                            if isinstance(fallback_sb, dict) and fallback_sb:
                                org_data['score_breakdown'] = fallback_sb
                                # Prefer existing total_score if present; otherwise use fallback
                                org_data['total_score'] = org_data.get('total_score', fallback_sb.get('total_score', 0))
                        except Exception:
                            # If fallback computation fails, continue with safe defaults
                            pass

                    # Derive score consistently from precomputed source when available
                    # This ensures the scorecard matches the ranking tables
                    _pre_key = analyzer._normalize_name(org_name)
                    _pre = getattr(analyzer, 'scored_index', {}).get(_pre_key, {})
                    _ps = _pre.get('total_score')
                    if isinstance(_ps, (int, float)):
                        score = float(_ps)
                        org_data['total_score'] = score
                    else:
                        # Fallback to computed org_data value
                        score = org_data.get('total_score', 0)
                        try:
                            if not isinstance(score, (int, float)):
                                score = float(score)
                        except Exception:
                            score = 0.0
                    # Final numeric guard
                    try:
                        score = float(score)
                    except Exception:
                        score = 0.0
                    grade = "A+" if score >= 75 else "A" if score >= 65 else "B+" if score >= 55 else "B" if score >= 45 else "C"
                    org_type = "Hospital"  # Default type, can be enhanced later
                    
                    # Display organization profile
                    st.subheader(f"üè• {org_name} - Quality Scorecard")

                    # (Removed duplicate quick score and rank snapshot to avoid double rendering)
                    
                    # Data source information
                    data_source = org_data.get('data_source', 'QuXAT Database')
                    if data_source == 'Public Domain':
                        st.markdown("""
                        <div style="background: #e3f2fd; border-left: 4px solid #2196f3; padding: 1rem; margin: 1rem 0; border-radius: 5px;">
                            <p style="margin: 0; color: #1976d2; font-weight: 500;">
                                üåê <strong>Data Source:</strong> Public Domain Information<br>
                                <small>This organization's data was gathered from publicly available sources including accreditation bodies, quality rankings, and official websites. For more accurate information or to add your organization to our database, please contact <a href="mailto:quxat.team@gmail.com" style="color: #1976d2;">quxat.team@gmail.com</a></small>
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    # Key metrics
                    # Compute quick ranking to display alongside score (prefer precomputed unique ranks)
                    quick_rank = {}
                    try:
                        _key = analyzer._normalize_name(org_name)
                        _entry = getattr(analyzer, 'scored_index', {}).get(_key)
                        if isinstance(_entry, dict):
                            quick_rank = {
                                'overall_rank': _entry.get('overall_rank') or 1,
                                'total_organizations': len(getattr(analyzer, 'scored_entries', []) or [] ) or (_entry.get('total_organizations') or 1),
                                'percentile': float(_entry.get('percentile', 0) or 0)
                            }
                        else:
                            quick_rank = analyzer.calculate_organization_rankings(org_name, score) or {}
                            if 'overall_rank' not in quick_rank or not isinstance(quick_rank.get('overall_rank'), int):
                                quick_rank['overall_rank'] = 1
                            if 'total_organizations' not in quick_rank or not isinstance(quick_rank.get('total_organizations'), int):
                                quick_rank['total_organizations'] = 1
                            pct_val = quick_rank.get('percentile', 0)
                            try:
                                quick_rank['percentile'] = float(pct_val)
                            except Exception:
                                quick_rank['percentile'] = 0.0
                    except Exception:
                        quick_rank = {'overall_rank': 1, 'total_organizations': 1, 'percentile': 0.0}

                    # (Moved score/rank cards to the Detailed Scoring Information section per request)

                    # (Percentile card moved to Detailed Scoring Information section)
                    
                    # CAP Accreditation Status - Mandatory Compliance (Background Processing Only)
                    # st.markdown("---")  # Commented out to hide UI section
                    
                    # Check CAP compliance from quality indicators
                    quality_indicators = org_data.get('quality_indicators', {})
                    cap_compliant = quality_indicators.get('cap_accredited', False)
                    
                    # Also check for CAP certifications as backup
                    cap_certifications = [cert for cert in org_data.get('certifications', []) 
                                        if 'CAP' in cert.get('name', '').upper() or 
                                           'COLLEGE OF AMERICAN PATHOLOGISTS' in cert.get('name', '').upper()]
                    if cap_certifications and not cap_compliant:
                        cap_compliant = any(cert.get('status', '').lower() == 'active' for cert in cap_certifications)
                    
                    # Check for JCI compliance
                    jci_compliant = quality_indicators.get('jci_accredited', False)
                    if not jci_compliant:
                        jci_certifications = [cert for cert in org_data.get('certifications', []) 
                                        if 'JCI' in cert.get('name', '').upper() or 
                                           'JOINT COMMISSION INTERNATIONAL' in cert.get('name', '').upper()]
                        if jci_certifications:
                            jci_compliant = any(cert.get('status', '').lower() == 'active' for cert in jci_certifications)
                    
                    # Check for ISO 9001 compliance
                    iso9001_compliant = False
                    iso9001_certifications = [cert for cert in org_data.get('certifications', []) 
                                    if 'ISO 9001' in cert.get('name', '').upper() or 
                                       'ISO9001' in cert.get('name', '').upper()]
                    if iso9001_certifications:
                        iso9001_compliant = any(cert.get('status', '').lower() == 'active' for cert in iso9001_certifications)
                    
                    # Check for ISO 15189 compliance
                    iso15189_compliant = False
                    iso15189_certifications = [cert for cert in org_data.get('certifications', []) 
                                     if 'ISO 15189' in cert.get('name', '').upper() or 
                                        'ISO15189' in cert.get('name', '').upper()]
                    if iso15189_certifications:
                        iso15189_compliant = any(cert.get('status', '').lower() == 'active' for cert in iso15189_certifications)
                    
                    # Count missing mandatory accreditations (for scoring calculations - runs in background)
                    missing_mandatory = []
                    if not cap_compliant:
                        missing_mandatory.append("CAP")
                    if not jci_compliant:
                        missing_mandatory.append("JCI")
                    if not iso9001_compliant:
                        missing_mandatory.append("ISO 9001")
                    if not iso15189_compliant:
                        missing_mandatory.append("ISO 15189")
                    
                    cap_warning = ''
                    
                    # Mandatory accreditation display logic commented out - scoring continues in background
                    # if len(missing_mandatory) == 0:
                    #     st.markdown("""
                    #     <div style="background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border: 2px solid #28a745; border-radius: 10px; padding: 20px; margin: 15px 0; text-align: center;">
                    #         <h3 style="color: #155724; margin: 0 0 10px 0;">üèÜ ALL MANDATORY ACCREDITATIONS VERIFIED ‚úÖ</h3>
                    #         <p style="color: #155724; margin: 0; font-size: 16px; font-weight: 500;">
                    #             CAP, JCI, ISO 9001, and ISO 15189 accreditations verified<br>
                    #             <small>Mandatory requirements: FULLY COMPLIANT</small>
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    # elif len(missing_mandatory) == 1:
                    #     st.markdown(f"""
                    #     <div style="background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%); border: 2px solid #ffc107; border-radius: 10px; padding: 20px; margin: 15px 0; text-align: center;">
                    #         <h3 style="color: #856404; margin: 0 0 10px 0;">‚ö†Ô∏è MISSING MANDATORY ACCREDITATION ‚ö†Ô∏è</h3>
                    #         <p style="color: #856404; margin: 0; font-size: 16px; font-weight: 500;">
                    #             {missing_mandatory[0]} accreditation not found<br>
                    #             <small>Mandatory requirement: PARTIALLY COMPLIANT (penalty applied)</small>
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    # else:
                    #     st.markdown(f"""
                    #     <div style="background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border: 2px solid #dc3545; border-radius: 10px; padding: 20px; margin: 15px 0; text-align: center;">
                    #         <h3 style="color: #721c24; margin: 0 0 10px 0;">‚ùå MULTIPLE MANDATORY ACCREDITATIONS MISSING ‚ùå</h3>
                    #         <p style="color: #721c24; margin: 0; font-size: 16px; font-weight: 500;">
                    #             Missing: {', '.join(missing_mandatory)}<br>
                    #             <small>Mandatory requirements: NON-COMPLIANT (significant penalties applied)</small>
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    #     
                    #     if cap_warning:
                    #         st.error(cap_warning)
                    
                    # Detailed Scoring Information Section

                    # Remove repeated summary cards here; only keep unique items below
                    # Ensure score is numeric for grade rendering
                    try:
                        score = float(score)
                    except Exception:
                        score = 0.0
                    
                    # Quality Grade Card (match style with other cards)
                    grade, grade_color, grade_desc = compute_quality_grade(score)
                    try:
                        theme = {
                            'üü¢': {'bg': '#eef9f0', 'border': '#28a745', 'text': '#1e7e34'},
                            'üü°': {'bg': '#fff9e6', 'border': '#ffc107', 'text': '#b8860b'},
                            'üî¥': {'bg': '#fdebea', 'border': '#dc3545', 'text': '#721c24'},
                        }.get(grade_color, {'bg': '#f5f7fa', 'border': '#e0e0e0', 'text': '#2c3e50'})

                        gc1, gc2, gc3, gc4 = st.columns(4)
                        with gc1:
                            st.markdown(f"""
                            <div class="quxat-card quxat-card--accent" style="background:{theme['bg']};border-color:{theme['border']};color:{theme['text']};">
                                <h4 style="color:{theme['text']};">üèÖ Quality Grade</h4>
                                <div style="font-size: 1.6em; font-weight: 700;">{grade_color} {grade}</div>
                                <p style="margin: 4px 0 0 0; color:#6c757d; font-size: 0.9em;">{grade_desc}</p>
                                <p style="margin: 2px 0 0 0; color:#6c757d; font-size: 0.85em;">{score:.1f}/100</p>
                            </div>
                            """, unsafe_allow_html=True)
                    except Exception:
                        pass

                    # Score Breakdown (inline)
                    try:
                        score_br = org_data.get('score_breakdown', {})
                        if isinstance(score_br, dict) and score_br:
                            st.markdown("### üìä Score Breakdown")
                            bcol1, bcol2 = st.columns(2)
                            with bcol1:
                                # Support both international and public-domain breakdown keys
                                cert_score = score_br.get('certification_score')
                                if cert_score is None:
                                    cert_score = score_br.get('Accreditation Score', 0)
                                if isinstance(cert_score, (int, float)):
                                    st.progress(min(max(cert_score, 0), 100) / 100)
                                    st.write(f"Certifications: {cert_score:.1f}/100")
                                qi_score = score_br.get('quality_initiatives_score')
                                if qi_score is None:
                                    qi_score = score_br.get('quality_metrics_score')
                                if qi_score is None:
                                    qi_score = score_br.get('Quality Indicators Score', 0)
                                if isinstance(qi_score, (int, float)):
                                    st.progress(min(max(qi_score, 0), 100) / 100)
                                    st.write(f"Quality Initiatives: {qi_score:.1f}/100")
                                pf_score = score_br.get('patient_feedback_score', 0)
                                if isinstance(pf_score, (int, float)) and pf_score > 0:
                                    st.progress(min(max(pf_score, 0), 100) / 100)
                                    st.write(f"Patient Feedback: {pf_score:.1f}/100")
                                web_score = score_br.get('Web Presence Score')
                                if isinstance(web_score, (int, float)) and web_score > 0:
                                    st.progress(min(max(web_score, 0), 100) / 100)
                                    st.write(f"Web Presence: {web_score:.1f}/100")
                            with bcol2:
                                comp_status = score_br.get('compliance_status')
                                if comp_status:
                                    st.info(comp_status)
                                cap_warn = score_br.get('cap_warning')
                                if cap_warn:
                                    st.warning(cap_warn)
                                penalty = score_br.get('mandatory_penalty')
                                if penalty is None:
                                    penalty = score_br.get('Total Mandatory Penalties', 0)
                                if isinstance(penalty, (int, float)) and penalty > 0:
                                    with st.expander("Penalty details"):
                                        pb = score_br.get('penalty_breakdown', {})
                                        if isinstance(pb, dict) and pb:
                                            for k, v in pb.items():
                                                st.write(f"{k}: {v}")
                                        missing = score_br.get('missing_critical_standards', [])
                                        if missing:
                                            st.write("Missing mandatory standards:")
                                            for m in missing:
                                                std = m.get('standard') if isinstance(m, dict) else str(m)
                                                st.write(f"‚Ä¢ {std}")
                                # Additional breakdown hidden on home page per request
                        else:
                            # Always show section header to avoid blank UI when breakdown is missing
                            st.markdown("### üìä Score Breakdown")
                            st.info("No detailed breakdown available for this organization.")
                    except Exception:
                        # Always show section header to avoid blank UI even on errors
                        st.markdown("### üìä Score Breakdown")
                        st.info("Breakdown unavailable due to a rendering error.")

                    st.markdown("---")
                    
                    # Certifications Section
                    st.markdown("### üèÖ Mandatory Requirements")
                    
                    # CAP Accreditation Highlight (Mandatory)
                    cap_certifications = [cert for cert in org_data.get('certifications', []) if 'CAP' in cert.get('name', '').upper() or 'COLLEGE OF AMERICAN PATHOLOGISTS' in cert.get('name', '').upper()]
                    
                    if cap_certifications:
                        cap_cert = cap_certifications[0]  # Take the first CAP certification
                        cap_status = cap_cert.get('status', 'Active')
                        cap_icon = "‚úÖ" if cap_status == "Active" else "‚è≥" if cap_status == "Pending" else "‚ùå"

                        header_text = f"{cap_icon} {cap_cert.get('name', 'CAP Accreditation')} (MANDATORY)"
                        details = [
                            f"Status: {cap_status}",
                            "Impact: +30 points (Mandatory requirement met)",
                            "Equivalency: Equivalent to ISO 15189 Medical Laboratory Standard",
                        ]

                        if cap_status == "Active":
                            st.success(header_text)
                        elif cap_status == "Pending":
                            st.warning(header_text)
                        else:
                            st.error(header_text)

                        for line in details:
                            st.write(f"‚Ä¢ {line}")
                    else:
                        st.error("‚ùå CAP Accreditation (MANDATORY - MISSING)")
                        st.write("‚Ä¢ Status: Not Found")
                        st.write("‚Ä¢ Impact: -40 points penalty (Mandatory requirement not met)")
                    
                    # JCI Accreditation Highlight (Mandatory)
                    jci_certifications = [
                        cert for cert in org_data.get('certifications', [])
                        if 'JCI' in str(cert.get('name', '')).upper() 
                        or 'JOINT COMMISSION INTERNATIONAL' in str(cert.get('name', '')).upper()
                        or (
                            # Treat U.S. Joint Commission as equivalency for hospital accreditation
                            'JOINT COMMISSION' in str(cert.get('name', '')).upper() and 
                            'INTERNATIONAL' not in str(cert.get('name', '')).upper()
                        )
                    ]

                    # Pull penalty information from score breakdown if available
                    jci_penalty_default = 10
                    jci_penalty = jci_penalty_default
                    try:
                        pb = score_br.get('penalty_breakdown', {}) if isinstance(score_br, dict) else {}
                        jci_penalty = int(pb.get('Hospital Accreditation', jci_penalty_default))
                    except Exception:
                        jci_penalty = jci_penalty_default

                    if jci_certifications:
                        jci_cert = jci_certifications[0]  # Take the first JCI/TJC certification
                        jci_status = str(jci_cert.get('status', 'Active')).strip()
                        jci_icon = "‚úÖ" if jci_status == "Active" else "‚è≥" if jci_status == "Pending" else "‚ùå"
                        jci_name = jci_cert.get('name', 'JCI Accreditation')
                        header_text = f"{jci_icon} {jci_name} (MANDATORY)"
                        details = [
                            f"Status: {jci_status}",
                            "Impact: Mandatory requirement met" if jci_status == "Active" else "Impact: Penalty may apply until active",
                            "Equivalency: U.S. Joint Commission recognized as hospital accreditation equivalency"
                        ]

                        if jci_status == "Active":
                            st.success(header_text)
                        elif jci_status == "Pending":
                            st.warning(header_text)
                        else:
                            st.error(header_text)

                        for line in details:
                            st.write(f"‚Ä¢ {line}")
                    else:
                        st.error("‚ùå JCI Accreditation (MANDATORY - MISSING)")
                        st.write("‚Ä¢ Status: Not Found")
                        st.write(f"‚Ä¢ Impact: -{jci_penalty} points penalty (Mandatory requirement not met)")
                    #         <h4 style="color: #155724; margin: 0 0 10px 0;">{jci_icon} {jci_cert.get('name', 'JCI Accreditation')} (MANDATORY)</h4>
                    #         <p style="margin: 5px 0; color: #155724; font-weight: 500;">
                    #             <strong>Status:</strong> {jci_status}<br>
                    #             <strong>Impact:</strong> +25 points (Mandatory requirement met)
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    # else:
                    #     st.markdown("""
                    #     <div style="background: linear-gradient(135deg, #f8e8e8 0%, #f8d7da 100%); border: 2px solid #dc3545; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    #         <h4 style="color: #721c24; margin: 0 0 10px 0;">‚ùå JCI Accreditation (MANDATORY - MISSING)</h4>
                    #         <p style="margin: 5px 0; color: #721c24; font-weight: 500;">
                    #             <strong>Status:</strong> Not Found<br>
                    #             <strong>Impact:</strong> -30 points penalty (Mandatory requirement not met)
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    
                    # ISO 9001 Certification Highlight (Mandatory)
                    iso9001_certifications = [cert for cert in org_data.get('certifications', []) if 'ISO 9001' in cert.get('name', '').upper() or 'ISO9001' in cert.get('name', '').upper()]
                    
                    if iso9001_certifications:
                        iso9001_cert = iso9001_certifications[0]  # Take the first ISO 9001 certification
                        iso9001_status = iso9001_cert.get('status', 'Active')
                        iso9001_icon = "‚úÖ" if iso9001_status == "Active" else "‚è≥" if iso9001_status == "Pending" else "‚ùå"
                        
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #e8f5e8 0%, #d4edda 100%); border: 2px solid #28a745; border-radius: 10px; padding: 15px; margin: 10px 0;">
                            <h4 style="color: #155724; margin: 0 0 10px 0;">{iso9001_icon} {iso9001_cert.get('name', 'ISO 9001 Quality Management')} (MANDATORY)</h4>
                            <p style="margin: 5px 0; color: #155724; font-weight: 500;">
                                <strong>Status:</strong> {iso9001_status}<br>
                                <strong>Impact:</strong> +20 points (Mandatory requirement met)
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    # else:
                    #     st.markdown("""
                    #     <div style="background: linear-gradient(135deg, #f8e8e8 0%, #f8d7da 100%); border: 2px solid #dc3545; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    #         <h4 style="color: #721c24; margin: 0 0 10px 0;">‚ùå ISO 9001 Quality Management (MANDATORY - MISSING)</h4>
                    #         <p style="margin: 5px 0; color: #721c24; font-weight: 500;">
                    #             <strong>Status:</strong> Not Found<br>
                    #             <strong>Impact:</strong> -25 points penalty (Mandatory requirement not met)
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    
                    # ISO 15189 Certification Highlight (Mandatory)
                    iso15189_certifications = [cert for cert in org_data.get('certifications', []) if 'ISO 15189' in cert.get('name', '').upper() or 'ISO15189' in cert.get('name', '').upper()]
                    
                    if iso15189_certifications:
                        iso15189_cert = iso15189_certifications[0]  # Take the first ISO 15189 certification
                        iso15189_status = iso15189_cert.get('status', 'Active')
                        iso15189_icon = "‚úÖ" if iso15189_status == "Active" else "‚è≥" if iso15189_status == "Pending" else "‚ùå"
                        
                        st.markdown(f"""
                        <div style="background: linear-gradient(135deg, #e8f5e8 0%, #d4edda 100%); border: 2px solid #28a745; border-radius: 10px; padding: 15px; margin: 10px 0;">
                            <h4 style="color: #155724; margin: 0 0 10px 0;">{iso15189_icon} {iso15189_cert.get('name', 'ISO 15189 Medical Laboratory')} (MANDATORY)</h4>
                            <p style="margin: 5px 0; color: #155724; font-weight: 500;">
                                <strong>Status:</strong> {iso15189_status}<br>
                                <strong>Impact:</strong> +20 points (Mandatory requirement met)
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    # else:
                    #     st.markdown("""
                    #     <div style="background: linear-gradient(135deg, #f8e8e8 0%, #f8d7da 100%); border: 2px solid #dc3545; border-radius: 10px; padding: 15px; margin: 10px 0;">
                    #         <h4 style="color: #721c24; margin: 0 0 10px 0;">‚ùå ISO 15189 Medical Laboratory (MANDATORY - MISSING)</h4>
                    #         <p style="margin: 5px 0; color: #721c24; font-weight: 500;">
                    #             <strong>Status:</strong> Not Found<br>
                    #             <strong>Impact:</strong> -25 points penalty (Mandatory requirement not met)
                    #         </p>
                    #     </div>
                    #     """, unsafe_allow_html=True)
                    
                    # Get other certifications (excluding CAP, JCI, ISO 9001, ISO 15189 and NABH as they are accreditations)
                    certifications = org_data.get('certifications', [])
                    # Filter out CAP, JCI, ISO 9001, ISO 15189, NABH, and MAGNET as they should be in accreditations section
                    certifications = [
                        cert for cert in certifications
                        if not (
                            'CAP' in cert.get('name', '').upper()
                            or 'COLLEGE OF AMERICAN PATHOLOGISTS' in cert.get('name', '').upper()
                            or 'JCI' in cert.get('name', '').upper()
                            or 'NABH' in cert.get('name', '').upper()
                            or 'JOINT COMMISSION INTERNATIONAL' in cert.get('name', '').upper()
                            or 'ISO 9001' in cert.get('name', '').upper()
                            or 'ISO9001' in cert.get('name', '').upper()
                            or 'ISO 15189' in cert.get('name', '').upper()
                            or 'ISO15189' in cert.get('name', '').upper()
                            or 'MAGNET' in cert.get('name', '').upper()
                            or 'MAGNET RECOGNITION' in cert.get('name', '').upper()
                        )
                    ]
                    # Only show valid/non-expired certifications on homepage
                    valid_statuses = {"ACTIVE", "VALID", "CURRENT", "ACCREDITED", "CERTIFIED", "COMPLIANT"}
                    certifications = [
                        cert for cert in certifications
                        if str(cert.get('status', '')).strip().upper() in valid_statuses
                    ]

                    if certifications:
                        cert_cols = st.columns(min(len(certifications), 3))
                        for idx, cert in enumerate(certifications[:6]):  # Show up to 6 certifications
                            with cert_cols[idx % 3]:
                                # Determine certification status and icon
                                cert_status = cert.get('status', 'Active')
                                cert_icon = "‚úÖ" if cert_status == "Active" else "‚è≥" if cert_status == "Pending" else "‚ùå"
                                
                                # Determine certification status color
                                if cert_status == 'Active':
                                    cert_status_color = "#28a745"
                                elif cert_status == 'Pending':
                                    cert_status_color = "#ffc107"
                                else:
                                    cert_status_color = "#dc3545"
                                
                                # Special handling for NABH - only show status if details are not available
                                cert_name = cert.get('name', 'Unknown Certification')
                                is_nabh = 'NABH' in cert_name.upper()
                                is_jci = 'JCI' in cert_name.upper()
                                issuer = cert.get('issuer', 'N/A')
                                valid_until = cert.get('valid_until', cert.get('expiry', 'N/A'))
                                
                                if (is_nabh and (issuer == 'N/A' or issuer is None) and (valid_until == 'N/A' or valid_until is None)) or \
                                   (is_jci and (issuer == 'N/A' or issuer is None) and (valid_until == 'N/A' or valid_until is None)):
                                    # For NABH or JCI with no details, show only status
                                    st.markdown(f"""
                                    <div style="padding: 15px; border: 1px solid #ddd; border-radius: 8px; margin: 10px 0; background: #f8f9fa;">
                                        <h4 style="color: #2c3e50; margin: 0 0 10px 0;">{cert_icon} {cert_name}</h4>
                                        <p style="margin: 5px 0; color: #666;"><strong>Status:</strong> <span style="color: {cert_status_color};">{cert_status}</span></p>
                                    </div>
                                    """, unsafe_allow_html=True)
                                else:
                                    # Simplified certification card - only show status
                                    card_content = f"""
                                    <div style="padding: 15px; border: 1px solid #ddd; border-radius: 8px; margin: 10px 0; background: #f8f9fa;">
                                        <h4 style="color: #2c3e50; margin: 0 0 10px 0;">{cert_icon} {cert_name}</h4>
                                        <p style="margin: 5px 0; color: #666;"><strong>Status:</strong> <span style="color: {cert_status_color};">{cert_status}</span></p>
                                    </div>
                                    """
                                    
                                    st.markdown(card_content, unsafe_allow_html=True)
                    else:
                        st.info("üìã No active certifications found for this organization.")
                    
                    st.markdown("---")
                    
                    # Accreditations Section
                    st.markdown("### üéñÔ∏è Accreditations & Recognition")
                    
                    # Get accreditations from organization data
                    accreditations = org_data.get('accreditations', [])
                    # Filter to only valid/non-expired accreditations for homepage
                    accreditations = [
                        acc for acc in accreditations
                        if str(acc.get('status', '')).strip().upper() in valid_statuses
                    ]
                    
                    # Add JCI and NABH from certifications data as they are actually accreditations
                    all_certifications = org_data.get('certifications', [])
                    jci_nabh_accreditations = [
                        cert for cert in all_certifications
                        if (
                            'JCI' in cert.get('name', '').upper()
                            or 'NABH' in cert.get('name', '').upper()
                            or 'JOINT COMMISSION INTERNATIONAL' in cert.get('name', '').upper()
                            or 'MAGNET' in cert.get('name', '').upper()
                            or 'MAGNET RECOGNITION' in cert.get('name', '').upper()
                        ) and str(cert.get('status', '')).strip().upper() in valid_statuses
                    ]
                    
                    # Convert JCI/NABH certifications to accreditation format (avoid duplicates)
                    existing_accred_names = [acc.get('name', '').upper() for acc in accreditations]
                    for cert in jci_nabh_accreditations:
                        cert_name = cert.get('name', 'Unknown Accreditation')
                        # Skip if this accreditation already exists
                        if cert_name.upper() in existing_accred_names:
                            continue
                            
                        # Determine appropriate accreditation level
                        _upper_name = cert_name.upper()
                        accred_level = (
                            'International Recognition' if ('MAGNET' in _upper_name or 'MAGNET RECOGNITION' in _upper_name)
                            else 'International Standard' if ('JCI' in _upper_name or 'JOINT COMMISSION INTERNATIONAL' in _upper_name)
                            else 'National Standard'
                        )

                        accred_entry = {
                            'name': cert_name,
                            'level': accred_level,
                            'awarded_date': cert.get('issued_date', cert.get('awarded_date', 'N/A')),
                            'description': cert.get('description', ''),
                            'status': cert.get('status', 'Active'),
                            'issuer': cert.get('issuer', 'N/A'),
                            'valid_until': cert.get('valid_until', cert.get('expiry', 'N/A'))
                        }
                        accreditations.append(accred_entry)
                        existing_accred_names.append(cert_name.upper())
                    
                    # Check for NABL accreditation
                    nabl_accreditation = healthcare_validator.get_nabl_accreditation(org_name)
                    if nabl_accreditation:
                        accreditations.append(nabl_accreditation)
                    
                    if not accreditations:
                        # Create sample accreditations based on organization type and score
                        accreditations = []
                        # Only create sample accreditations if score is defined (i.e., after a search)
                        if 'score' in locals() and score >= 70:
                            accreditations.append({
                                'name': 'Joint Commission Accreditation',
                                'level': 'Gold Standard',
                                'awarded_date': '2023',
                                'description': 'Comprehensive healthcare quality and safety accreditation',
                                'status': 'Active'
                            })
                        if 'score' in locals() and score >= 60:
                            accreditations.append({
                                'name': 'ISO 9001:2015 Quality Management',
                                'level': 'Certified',
                                'awarded_date': '2022',
                                'description': 'International standard for quality management systems',
                                'status': 'Active'
                            })
                        if 'score' in locals() and score >= 50:
                            accreditations.append({
                                'name': 'Healthcare Quality Recognition',
                                'level': 'Bronze',
                                'awarded_date': '2023',
                                'description': 'Recognition for commitment to healthcare quality improvement',
                                'status': 'Active'
                            })
                    
                    if accreditations:
                        for accred in accreditations:
                            # Determine accreditation level icon
                            level = accred.get('level', '').lower()
                            accred_name = accred.get('name', '').upper()
                            
                            # Special icons for NABH
                            if 'NABH' in accred_name:
                                level_icon = "üáÆüá≥"
                                level_color = "#FF9800"
                            elif 'gold' in level or 'excellent' in level:
                                level_icon = "ü•á"
                                level_color = "#FFD700"
                            elif 'silver' in level or 'good' in level:
                                level_icon = "ü•à"
                                level_color = "#C0C0C0"
                            elif 'bronze' in level or 'standard' in level:
                                level_icon = "ü•â"
                                level_color = "#CD7F32"
                            elif 'iso/iec 17025' in level or 'nabl' in accred.get('name', '').lower():
                                level_icon = "üî¨"
                                level_color = "#2196F3"
                            else:
                                level_icon = "üèÜ"
                                level_color = "#4CAF50"
                            
                            # Determine status color
                            status = accred.get('status', 'Active')
                            if status == 'Active':
                                status_color = "#28a745"
                            elif status == 'Pending':
                                status_color = "#ffc107"
                            else:
                                status_color = "#dc3545"
                            
                            # Format validity date if available (special handling for JCI/NABH)
                            validity_info = ""
                            valid_until = accred.get('valid_until')
                            is_jci_nabh = 'JCI' in accred_name or 'NABH' in accred_name
                            
                            if is_jci_nabh and (valid_until == 'N/A' or valid_until is None):
                                # Don't show validity info for JCI/NABH when not available
                                validity_info = ""
                            elif valid_until and valid_until != 'N/A':
                                validity_info = f"<p style=\"margin: 5px 0; color: #666;\"><strong>Valid Until:</strong> {valid_until}</p>"
                            
                            # Format issuer info if available (special handling for JCI/NABH)
                            issuer_info = ""
                            issuer = accred.get('issuer')
                            if is_jci_nabh and (issuer == 'N/A' or issuer is None):
                                # Don't show issuer info for JCI/NABH when not available
                                issuer_info = ""
                            elif issuer and issuer != 'N/A':
                                issuer_info = f"<p style=\"margin: 5px 0; color: #666;\"><strong>Issued by:</strong> {issuer}</p>"
                            
                            # Format certificate number if available
                            cert_info = ""
                            if accred.get('certificate_number'):
                                cert_info = f"<p style=\"margin: 5px 0; color: #666;\"><strong>Certificate:</strong> {accred.get('certificate_number')}</p>"
                            
                            # Get organization details from session state
                            org_details = ""
                            if 'current_org' in st.session_state and 'current_data' in st.session_state:
                                current_org_name = st.session_state.current_org
                                current_org_data = st.session_state.current_data
                                
                                # Extract organization type
                                org_type = "Healthcare Organization"  # Default
                                if 'unified_data' in current_org_data:
                                    unified_data = current_org_data['unified_data']
                                    org_type = unified_data.get('type', org_type)
                                
                                # Extract organization location
                                org_location = ""
                                if 'unified_data' in current_org_data:
                                    unified_data = current_org_data['unified_data']
                                    if 'location' in unified_data:
                                        org_location = unified_data['location']
                                    elif 'city' in unified_data and 'state' in unified_data:
                                        org_location = f"{unified_data['city']}, {unified_data['state']}"
                                    elif 'address' in unified_data:
                                        org_location = unified_data['address']
                                
                                # Build organization details section
                                org_details = f"""
                                <div style="background: #e8f4fd; padding: 10px; border-radius: 5px; margin: 10px 0; border-left: 4px solid #007bff;">
                                    <p style="margin: 2px 0; color: #495057; font-size: 0.9em;"><strong>üè• Organization:</strong> {current_org_name}</p>"""
                                
                                if org_location:
                                    org_details += f"""
                                    <p style="margin: 2px 0; color: #495057; font-size: 0.9em;"><strong>üìç Location:</strong> {org_location}</p>"""
                                
                                org_details += f"""
                                    <p style="margin: 2px 0; color: #495057; font-size: 0.9em;"><strong>üè¢ Type:</strong> {org_type}</p>
                                </div>"""
                            
                            # Display the main accreditation info
                            accred_name_display = accred.get('name', 'Unknown Accreditation')
                            equivalency_note = ""
                            
                            # Add equivalency notation for NABL
                            if 'nabl' in accred.get('name', '').lower():
                                equivalency_note = "<br><strong>Equivalency:</strong> ‚öñÔ∏è Equivalent to ISO 15189 Medical Laboratory Standard"
                            
                            st.markdown(f"""
                            <div style="padding: 20px; border-left: 4px solid {level_color}; background: #f8f9fa; margin: 15px 0; border-radius: 0 8px 8px 0;">
                                <h4 style="color: #2c3e50; margin: 0 0 10px 0;">{level_icon} {accred_name_display}</h4>
                                <p style="margin: 5px 0; color: #666;"><strong>Accreditation Status:</strong> <span style="color: {status_color};">{accred.get('status', 'Active')}</span>{equivalency_note}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Display the description separately to ensure proper HTML rendering
                            description = accred.get('description', 'No description available.')
                            if description and description != 'No description available.':
                                st.markdown(description, unsafe_allow_html=True)
                    else:
                        st.info("üéñÔ∏è No accreditations found for this organization.")
                    
                    st.markdown("---")
                    
                    
                    # Certification details
                    st.markdown("### üèÜ Certifications & Accreditations")
                    if org_data['certifications']:
                        cert_df = pd.DataFrame(org_data['certifications'])
                        # Show only valid/non-expired certifications
                        if 'status' in cert_df.columns:
                            cert_df = cert_df[cert_df['status'].astype(str).str.upper().isin(list(valid_statuses))]
                        cert_df['Status Icon'] = cert_df['status'].map({
                            'Active': '‚úÖ', 'In Progress': 'üîÑ', 'Expired': '‚ùå'
                        })
                        
                        # Handle missing 'valid_until' column gracefully
                        columns_to_display = ['Status Icon', 'name', 'status']
                        column_names = ['Status', 'Certification', 'Status Detail']
                        
                        # Add valid_until column only if it exists and has valid dates
                        date_column = None
                        if 'valid_until' in cert_df.columns:
                            date_column = 'valid_until'
                        elif 'expiry' in cert_df.columns:
                            date_column = 'expiry'
                        
                        # Check if there are any valid dates (not empty, not 'N/A', not null)
                        if date_column and not cert_df[date_column].isna().all():
                            # Check if there are any non-empty, non-N/A values
                            valid_dates = cert_df[date_column].dropna()
                            valid_dates = valid_dates[valid_dates != 'N/A']
                            valid_dates = valid_dates[valid_dates != '']
                            
                            if len(valid_dates) > 0:
                                columns_to_display.append(date_column)
                                column_names.append('Valid Until')
                        
                        # Add score_impact column if it exists
                        if 'score_impact' in cert_df.columns:
                            columns_to_display.append('score_impact')
                            column_names.append('Score Impact')
                        
                        # Display certifications table
                        display_df = cert_df[columns_to_display].copy()
                        display_df.columns = column_names
                        st.dataframe(display_df, use_container_width=True)
                    else:
                        st.info("No certification data found for this organization.")
                    
                    # Quality initiatives
                    st.markdown("### üöÄ Quality Initiatives & Programs")
                    if org_data['quality_initiatives']:
                        # Group initiatives by category for better organization
                        initiatives_by_category = {}
                        for initiative in org_data['quality_initiatives']:
                            category = initiative.get('category', 'General')
                            if category not in initiatives_by_category:
                                initiatives_by_category[category] = []
                            initiatives_by_category[category].append(initiative)
                        
                        # Display initiatives by category
                        for category, initiatives in initiatives_by_category.items():
                            st.markdown(f"#### üìÇ {category}")
                            
                            for initiative in initiatives:
                                with st.expander(f"üìã {initiative['name']} ({initiative.get('year', 'N/A')})"):
                                    col1, col2 = st.columns([3, 1])
                                    with col1:
                                        st.write(f"**Initiative:** {initiative['name']}")
                                        st.write(f"**Description:** {initiative.get('description', 'No description available')}")
                                        st.write(f"**Year:** {initiative.get('year', 'N/A')}")
                                        st.write(f"**Category:** {initiative.get('category', 'General')}")
                                        
                                        # Show data source if available
                                        if 'source' in initiative:
                                            st.write(f"**Source:** {initiative['source']}")
                                        
                                    with col2:
                                        impact_score = initiative.get('impact_score', initiative.get('score_impact', 0))
                                        st.metric("Impact Score", f"+{impact_score}")
                                        
                                        # Show status if available
                                        if 'status' in initiative:
                                            status = initiative['status']
                                            status_color = "üü¢" if status.lower() == 'active' else "üü°"
                                            st.write(f"{status_color} **Status:** {status}")
                    else:
                        st.info("No quality initiatives found. This may indicate limited public information or the organization may not have published their quality programs online.")
                    
                    # Data sources and methodology
                    st.markdown("### üìö Data Sources & Methodology")
                    with st.expander("‚ÑπÔ∏è How we calculate this score"):
                        st.markdown("""
                        **Data Sources:**
                        - üèõÔ∏è Official certification body databases (ISO, JCI, NABH, CAP, NABL, etc.)
                        - üåê International accreditation organizations
                        - üìä Government healthcare regulatory databases
                        - ‚úÖ Verified certification registries
                        - üè¢ Official organization certification disclosures
                        - üåê Organization websites and quality program pages
                        - üì∞ Official press releases and announcements
                        
                        **Mandatory Compliance Review:**
                        All organizations must be reviewed for compliance with these certification/accreditation standards before QuXAT score generation:
                        - **ISO 9001** - Quality Management Systems
                        - **ISO 14001** - Environmental Management Systems
                        - **ISO 45001** - Occupational Health and Safety Management Systems
                        - **ISO 27001** - Information Security Management Systems
                        - **ISO 13485** - Medical Devices Quality Management Systems
                        - **ISO 50001** - Energy Management Systems
                        - **ISO 15189** - Medical Laboratories Quality and Competence
                        - **College of American Pathologists (CAP)** - Laboratory Accreditation
                        
                        **Scoring Methodology:**
                        - **Weighted Certification System (70%):** Evidence-based scoring using verified certifications with specific weights
                        - **Quality Initiatives (30%):** Programs and improvement activities
                        
                        **Certification Weight Hierarchy:**
                        - **JCI Accreditation:** Weight 3.5, Base Score 30 pts (Global Gold Standard)
                        - **ISO 9001 & ISO 13485:** Weight 3.2, Base Score 25 pts (Quality & Medical Device Management)
                        - **ISO 15189:** Weight 3.0, Base Score 22 pts (Medical Laboratory Quality)
                        - **ISO 27001:** Weight 2.8, Base Score 20 pts (Information Security)
                        - **CAP Accreditation:** Weight 2.8, Base Score 22 pts (Laboratory Standards)
                        - **ISO 45001:** Weight 2.6, Base Score 18 pts (Occupational Health & Safety)
                        - **NABH Accreditation:** Weight 2.6, Base Score 20 pts (Hospital Standards)
                        - **ISO 14001:** Weight 2.4, Base Score 16 pts (Environmental Management)
                        - **NABL Accreditation:** Weight 2.4, Base Score 18 pts (Testing & Calibration)
                        - **ISO 50001:** Weight 2.2, Base Score 14 pts (Energy Management)
                        - **Other ISO Standards:** Weight 2.0, Base Score 12 pts (General ISO Certifications)
                        
                        - **Certification Status:** Active certifications (100% weight), In-Progress (50% weight)
                        - **Performance Bonuses:** Diversity bonus (multiple cert types), International premium (JCI/ISO certs)
                        - **Initiative Categories:** Patient Safety (highest weight), Quality Improvement, Clinical Excellence
                        - **Initiative Status:** Active (100% weight), In Progress (70% weight), Planned (30% weight)
                        
                        **Score Ranges (Evidence-Based Scale):**
                        - 90-100: A+ (Exceptional Quality Recognition)
                        - 80-89: A (Excellent - Quality Recognition)
                        - 70-79: B+ (Good - Quality Recognition)
                        - 60-69: B (Adequate - Quality Recognition)
                        - 50-59: C (Average - Quality Recognition)
                        
                        ---
                        
                        **WARNINGÔ∏è Scoring Disclaimers:**
                        - **Assessment Limitations:** This scoring system is based on publicly available information and may not capture all quality aspects of an organization
                        - **Algorithmic Assessment:** Scores are generated through automated analysis and **may be incorrect or incomplete**
                        - **Data Dependencies:** Accuracy depends on the availability and reliability of public data sources
                        - **Not a Substitute:** These scores should not replace professional evaluation or due diligence when selecting healthcare providers
                        - **Comparative Tool Only:** Intended for comparative analysis and research purposes, not absolute quality determination
                        """)
                    
                    # Comparative Analysis Section
                    st.markdown("---")
                    
                    # Improvement Recommendations Section
                    if 'improvement_recommendations' in org_data:
                        st.markdown("### üí° Improvement Recommendations")
                        recommendations = org_data['improvement_recommendations']
                        
                        # Score Potential Overview
                        score_potential = recommendations.get('score_potential', {})
                        if score_potential:
                            # Normalize maximum to 100 for display and recompute potential accordingly
                            raw_current = score_potential.get('current_score', 0)
                            raw_max = score_potential.get('maximum_possible', 100)

                            # Prioritize unified 'score' used across the scorecard to avoid inconsistencies
                            try:
                                unified_score = float(score)
                            except Exception:
                                unified_score = None

                            if unified_score is not None:
                                current_score = unified_score
                            else:
                                current_score = raw_current if isinstance(raw_current, (int, float)) else None
                            max_possible = raw_max if isinstance(raw_max, (int, float)) else None

                            max_possible_display = 100.0 if max_possible is None else min(float(max_possible), 100.0)
                            improvement_potential_display = None
                            if current_score is not None:
                                improvement_potential_display = max(0.0, max_possible_display - float(current_score))

                            col1, col2, col3 = st.columns(3)
                            with col1:
                                if current_score is not None:
                                    st.metric("Current Score", f"{float(current_score):.1f}/100")
                                else:
                                    st.metric("Current Score", "N/A")
                            with col2:
                                st.metric("Maximum Possible", f"{max_possible_display:.1f}/100")
                            with col3:
                                if improvement_potential_display is not None:
                                    st.metric("Improvement Potential", f"+{improvement_potential_display:.1f} points")
                                else:
                                    st.metric("Improvement Potential", "N/A")
                        
                        # Priority Actions
                        priority_actions = recommendations.get('priority_actions', [])
                        if priority_actions:
                            st.markdown("#### üöÄ Priority Actions (High Impact)")
                            for i, action in enumerate(priority_actions):
                                with st.expander(f"üéØ {action['action']} - {action['impact']} Impact"):
                                    col1, col2 = st.columns([2, 1])
                                    with col1:
                                        st.write(f"**Description:** {action['description']}")
                                        st.write(f"**Timeline:** {action['timeline']}")
                                        st.write(f"**Expected Score Increase:** {action['score_increase']}")
                                    with col2:
                                        st.markdown(f"**Impact Level**\n\nüî• {action['impact']}")
                                    
                                    if 'steps' in action:
                                        st.markdown("**Implementation Steps:**")
                                        for step in action['steps']:
                                            st.write(f"‚Ä¢ {step}")
                        
                        # Certification Gaps
                        cert_gaps = recommendations.get('certification_gaps', [])
                        if cert_gaps:
                            st.markdown("#### üìú Missing Key Certifications")
                            for cert in cert_gaps:
                                priority_color = "üî¥" if cert['priority'] == 'Critical' else "üü°" if cert['priority'] == 'High' else "üü¢"
                                with st.expander(f"{priority_color} {cert['name']} - {cert['priority']} Priority"):
                                    col1, col2 = st.columns([2, 1])
                                    with col1:
                                        st.write(f"**Description:** {cert['description']}")
                                        st.write(f"**Score Impact:** {cert['score_impact']}")
                                    with col2:
                                        st.markdown(f"**Priority**\n\n{priority_color} {cert['priority']}")
                                    
                                    if 'prerequisites' in cert:
                                        st.markdown("**Prerequisites:**")
                                        for prereq in cert['prerequisites']:
                                            st.write(f"‚Ä¢ {prereq}")
                        
                        # Quality Initiatives
                        quality_initiatives = recommendations.get('quality_initiatives', [])
                        if quality_initiatives:
                            st.markdown("#### üåü Recommended Quality Initiatives")
                            for initiative in quality_initiatives:
                                with st.expander(f"‚≠ê {initiative['initiative']} - {initiative['category']}"):
                                    col1, col2 = st.columns([2, 1])
                                    with col1:
                                        st.write(f"**Description:** {initiative['description']}")
                                        st.write(f"**Timeline:** {initiative['timeline']}")
                                    with col2:
                                        st.metric("Impact Score", f"+{initiative['impact_score']} points")
                                    
                                    if 'key_components' in initiative:
                                        st.markdown("**Key Components:**")
                                        for component in initiative['key_components']:
                                            st.write(f"‚Ä¢ {component}")
                        
                        # Operational Improvements
                        operational_improvements = recommendations.get('operational_improvements', [])
                        if operational_improvements:
                            st.markdown("#### ‚öôÔ∏è Operational Improvements")
                            for improvement in operational_improvements:
                                with st.expander(f"üîß {improvement['area']}"):
                                    st.write(f"**Recommendation:** {improvement['recommendation']}")
                                    st.write(f"**Benefit:** {improvement['benefit']}")
                                    st.write(f"**Implementation:** {improvement['implementation']}")
                        
                        # Strategic Recommendations
                        strategic_recommendations = recommendations.get('strategic_recommendations', [])
                        if strategic_recommendations:
                            st.markdown("#### üéØ Strategic Recommendations")
                            for strategy in strategic_recommendations:
                                with st.expander(f"üìà {strategy['strategy']}"):
                                    st.write(f"**Description:** {strategy['description']}")
                                    st.write(f"**Timeline:** {strategy['timeline']}")
                                    st.write(f"**Expected Outcome:** {strategy['expected_outcome']}")
                        
                        # Contact information for feedback and clarifications
                        st.markdown("""
                        <div style="background: #f0f8ff; border-left: 4px solid #1976d2; padding: 1rem; margin: 1rem 0; border-radius: 5px;">
                            <p style="margin: 0; color: #1976d2; font-weight: 500;">
                                üìß <strong>Need Help Improving Your Score?</strong><br>
                                To improve the score of your healthcare organization and to give feedback or clarifications - please contact the analytics team at <a href="mailto:quxat.team@gmail.com" style="color: #1976d2; text-decoration: none;">quxat.team@gmail.com</a>
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        st.markdown("---")
                    
                    # Get organization region for display
                    analyzer = get_analyzer()
                    org_info = analyzer.search_organization_info(org_name)
                    org_location = ""
                    
                    if org_info and 'unified_data' in org_info:
                        # Extract location from unified database if available
                        unified_data = org_info['unified_data']
                        if 'location' in unified_data:
                            org_location = unified_data['location']
                        elif 'city' in unified_data and 'state' in unified_data:
                            org_location = f"{unified_data['city']}, {unified_data['state']}"
                        elif 'address' in unified_data:
                            org_location = unified_data['address']
                    
                    # Get region for display - always determine region based on org_name and location
                    org_region = analyzer.determine_organization_region(org_name, org_location)
                    org_region = org_region.title()  # Capitalize for display
        
        # Quality Scorecard - Organization Rankings
        # Derive score from computed org_data or precomputed index for reliability
        try:
            score = None
            if isinstance(org_data, dict):
                _ts = org_data.get('total_score')
                if isinstance(_ts, (int, float)):
                    score = float(_ts)
            if score is None:
                _pre_key = analyzer._normalize_name(org_name)
                _pre = analyzer.scored_index.get(_pre_key)
                if _pre:
                    _ps = _pre.get('total_score')
                    if isinstance(_ps, (int, float)):
                        score = float(_ps)
            if score is None:
                score = 0.0
        except Exception:
            score = 0.0

        if True:
            st.markdown("---")
            st.markdown("### üèÜ Quality Scorecard - Organization Rankings")
            st.markdown("*See how your organization ranks against all others in our database based on evidenced quality certifications and safety standards*")

            # Top 10 Organizations (from precomputed summary)
            try:
                # Robust path resolution for ranking_summary.json
                summary_path = 'ranking_summary.json'
                try:
                    _base_dir = os.path.dirname(__file__)
                except Exception:
                    _base_dir = os.getcwd()
                _candidates = [summary_path, os.path.join(_base_dir, summary_path)]
                _open_summary = None
                for _p in _candidates:
                    if os.path.exists(_p):
                        _open_summary = _p
                        break
                if _open_summary:
                    with open(_open_summary, 'r', encoding='utf-8') as f:
                        _summary = json.load(f)
                    _top10 = _summary.get('top_10_organizations') or _summary.get('top10')
                    if isinstance(_top10, list) and _top10:
                        st.markdown("#### üåç Global Top 10 Organizations")
                        _df_top = pd.DataFrame(_top10)
                        # Normalize columns for consistent display
                        renames = {
                            'rank': 'Rank',
                            'name': 'Organization',
                            'country': 'Country',
                            'total_score': 'Score',
                            'percentile': 'Percentile'
                        }
                        _df_top = _df_top[[c for c in renames if c in _df_top.columns]].rename(columns=renames)
                        if 'Percentile' in _df_top.columns:
                            # Format percentile as percentage
                            _df_top['Percentile'] = _df_top['Percentile'].map(lambda x: f"{float(x):.2f}%" if isinstance(x, (int, float)) else x)
                        if 'Score' in _df_top.columns:
                            _df_top['Score'] = _df_top['Score'].map(lambda x: f"{float(x):.1f}" if isinstance(x, (int, float)) else x)
                        st.dataframe(_df_top, use_container_width=True, hide_index=True)
            except Exception:
                # Silently continue if summary file missing or invalid
                pass
            
            # Calculate rankings (prefer precomputed unique ranks when available)
            rankings_data = {}
            try:
                # Try precomputed scored index first
                _key = analyzer._normalize_name(org_name)
                _entry = analyzer.scored_index.get(_key)
                if isinstance(_entry, dict):
                    _total_orgs = len(analyzer.scored_entries) if analyzer.scored_entries else _entry.get('total_organizations') or 1
                    _overall = _entry.get('overall_rank')
                    _pct = _entry.get('percentile', 0)
                    try:
                        _pct = float(_pct)
                    except Exception:
                        _pct = 0.0
                    # Only accept if rank present; otherwise compute
                    if isinstance(_overall, int) and _overall > 0:
                        rankings_data = {
                            'overall_rank': _overall,
                            'total_organizations': _total_orgs,
                            'percentile': _pct,
                            'category_rankings': {},
                            'top_performers': [],
                            'similar_performers': [],
                            'top_performers_benchmark': {'performers_above': [], 'performers_below': []},
                            'regional_ranking': {}
                        }
                # If no precomputed data, compute dynamically
                if not rankings_data:
                    rankings_data = analyzer.calculate_organization_rankings(org_name, score)
            except Exception:
                # As a last resort, ensure a minimal structure so UI never fails
                rankings_data = {
                    'overall_rank': 1,
                    'total_organizations': 1,
                    'percentile': 100.0,
                    'category_rankings': {},
                    'top_performers': [],
                    'similar_performers': [],
                    'top_performers_benchmark': {'performers_above': [], 'performers_below': []},
                    'regional_ranking': {}
                }
            # Ensure required keys exist to avoid UI rendering errors
            try:
                if isinstance(rankings_data, dict):
                    # Normalize percentile to a float value
                    pct_val = rankings_data.get('percentile', 0)
                    if not isinstance(pct_val, (int, float)):
                        try:
                            pct_val = float(pct_val)
                        except Exception:
                            pct_val = 0.0
                    rankings_data['percentile'] = float(pct_val or 0)
                    # Provide safe defaults for rank and total orgs
                    rankings_data.setdefault('overall_rank', 1)
                    rankings_data.setdefault('total_organizations', 1)
            except Exception:
                pass
            
# Healthcare quality grade for rankings display
            
            # Healthcare quality categories and descriptions
            grade_color, grade_text, grade_emoji, quality_level, quality_description = compute_ranking_quality(score)
        
            # Add ranking data to history for trend tracking
            if rankings_data and isinstance(rankings_data, dict):
                add_ranking_to_history(org_name, rankings_data)
                
                # Overall Ranking cards are now shown at the top of the results,
                # immediately after search; skip re-rendering here to avoid duplication.
                
                # Rank Neighbors (10 above and 10 below the current organization)
                try:
                    st.markdown("#### üîé Organizations Near Your Rank (¬±10)")
                    neighbors_cols = st.columns(2)
                    # Prefer precomputed unique ranks for accurate neighbors
                    entries = getattr(analyzer, 'scored_entries', []) or []
                    key = analyzer._normalize_name(org_name)
                    idx = None
                    if entries:
                        # Sort by overall_rank ascending
                        try:
                            sorted_all = sorted(
                                [e for e in entries if isinstance(e, dict)],
                                key=lambda e: int(e.get('overall_rank') or 0)
                            )
                        except Exception:
                            sorted_all = [e for e in entries if isinstance(e, dict)]
                        # Find index of current org
                        for i, e in enumerate(sorted_all):
                            nm = e.get('name') or e.get('organization_name') or ''
                            if analyzer._normalize_name(nm) == key:
                                idx = i
                                break
                        if idx is not None:
                            above = sorted_all[max(0, idx-10): idx]
                            below = sorted_all[idx+1: min(len(sorted_all), idx+11)]
                            # Format helpers
                            def _to_df(items):
                                data = []
                                for it in items:
                                    try:
                                        data.append({
                                            'Rank': it.get('overall_rank'),
                                            'Organization': it.get('name') or it.get('organization_name'),
                                            'Country': it.get('country', 'Unknown'),
                                            'Score': float(it.get('total_score', 0)),
                                            'Percentile': float(it.get('percentile', 0))
                                        })
                                    except Exception:
                                        pass
                                df = pd.DataFrame(data)
                                if not df.empty:
                                    if 'Percentile' in df.columns:
                                        df['Percentile'] = df['Percentile'].map(lambda x: f"{float(x):.2f}%")
                                    if 'Score' in df.columns:
                                        df['Score'] = df['Score'].map(lambda x: f"{float(x):.1f}")
                                return df
                            with neighbors_cols[0]:
                                st.markdown("**10 Above**")
                                df_above = _to_df(above)
                                st.dataframe(df_above, use_container_width=True, hide_index=True)
                            with neighbors_cols[1]:
                                st.markdown("**10 Below**")
                                df_below = _to_df(below)
                                st.dataframe(df_below, use_container_width=True, hide_index=True)
                        else:
                            # Fallback to dynamic benchmark neighbors if precomputed index not found
                            benchmark_data = rankings_data.get('top_performers_benchmark', {}) if isinstance(rankings_data, dict) else {}
                            perf_above = benchmark_data.get('performers_above', [])[-10:]
                            perf_below = benchmark_data.get('performers_below', [])[:10]
                            def _to_df_benchmark(items):
                                data = []
                                for it in items:
                                    try:
                                        data.append({
                                            'Rank': it.get('rank_position'),
                                            'Organization': it.get('name'),
                                            'Country': it.get('country', 'Unknown'),
                                            'Score': float(it.get('total_score', 0)),
                                            'Percentile': ''
                                        })
                                    except Exception:
                                        pass
                                df = pd.DataFrame(data)
                                if not df.empty and 'Score' in df.columns:
                                    df['Score'] = df['Score'].map(lambda x: f"{float(x):.1f}")
                                return df
                            with neighbors_cols[0]:
                                st.markdown("**10 Above**")
                                st.dataframe(_to_df_benchmark(perf_above), use_container_width=True, hide_index=True)
                            with neighbors_cols[1]:
                                st.markdown("**10 Below**")
                                st.dataframe(_to_df_benchmark(perf_below), use_container_width=True, hide_index=True)
                    else:
                        st.info("Precomputed rankings unavailable. Showing dynamic neighbors from benchmark.")
                        benchmark_data = rankings_data.get('top_performers_benchmark', {}) if isinstance(rankings_data, dict) else {}
                        perf_above = benchmark_data.get('performers_above', [])[-10:]
                        perf_below = benchmark_data.get('performers_below', [])[:10]
                        def _to_df_benchmark(items):
                            data = []
                            for it in items:
                                try:
                                    data.append({
                                        'Rank': it.get('rank_position'),
                                        'Organization': it.get('name'),
                                        'Country': it.get('country', 'Unknown'),
                                        'Score': float(it.get('total_score', 0)),
                                        'Percentile': ''
                                    })
                                except Exception:
                                    pass
                            df = pd.DataFrame(data)
                            if not df.empty and 'Score' in df.columns:
                                df['Score'] = df['Score'].map(lambda x: f"{float(x):.1f}")
                            return df
                        with neighbors_cols[0]:
                            st.markdown("**10 Above**")
                            st.dataframe(_to_df_benchmark(perf_above), use_container_width=True, hide_index=True)
                        with neighbors_cols[1]:
                            st.markdown("**10 Below**")
                            st.dataframe(_to_df_benchmark(perf_below), use_container_width=True, hide_index=True)
                except Exception:
                    # Do not block the rest of the UI if neighbors fail
                    pass
                
                # Category-Specific Rankings
                st.markdown("#### üìã Category Performance Rankings")
                
                category_rankings = rankings_data.get('category_rankings', {})
                if category_rankings:
                    cat_col1, cat_col2, cat_col3 = st.columns(3)
                    
                    categories_info = {
                        'quality': {'name': 'Quality & Certifications', 'emoji': 'üè•', 'color': '#28a745'},
                        'safety': {'name': 'Safety Standards', 'emoji': 'üõ°Ô∏è', 'color': '#1976d2'},
                        'certifications': {'name': 'Certification Excellence', 'emoji': 'üèÜ', 'color': '#ff9800'}
                    }
                    
                    for i, (category, info) in enumerate(categories_info.items()):
                        col = [cat_col1, cat_col2, cat_col3][i]
                        
                        if category in category_rankings:
                            cat_data = category_rankings[category]
                            cat_color = info['color']
                            
                            with col:
                                st.markdown(f"""
                                <div style="background: {cat_color}15; border: 1px solid {cat_color}; border-radius: 8px; padding: 1rem; text-align: center;">
                                    <h5 style="color: {cat_color}; margin-bottom: 0.5rem;">{info['emoji']} {info['name']}</h5>
                                    <div style="font-size: 1.5em; font-weight: bold; color: {cat_color};">
                                        #{cat_data['rank']}
                                    </div>
                                    <p style="margin: 0; color: #666; font-size: 0.9em;">
                                        {cat_data['percentile']:.0f}th percentile<br>
                                        Score: {cat_data['score']:.1f}
                                    </p>
                                </div>
                                """, unsafe_allow_html=True)
                
                # Top Performers Comparison
                st.markdown("#### üåü Top Performers Benchmark")
                
                # Enhanced Top Performers Benchmark with top 20 above/below
                benchmark_data = rankings_data.get('top_performers_benchmark', {})
                if benchmark_data and (benchmark_data.get('performers_above') or benchmark_data.get('performers_below')):
                    st.markdown("*Compare your organization with top 20 performers above and below your rank level*")
                    
                    # Create tabs for different views
                    st.markdown("<div style='margin: 1.5rem 0 1rem 0;'></div>", unsafe_allow_html=True)
                    tab1, tab2, tab3 = st.tabs(["üìà Performers Above", "üìä Your Position", "üìâ Performers Below"])
                    
                    with tab1:
                        performers_above = benchmark_data.get('performers_above', [])
                        if performers_above:
                            st.markdown(f"**Top {len(performers_above)} performers ranked above you:**")
                            
                            # Create comparison table for performers above
                            above_data = []
                            for performer in performers_above:
                                score_diff = performer.get('score_difference', 0)
                                diff_color = "üü¢" if score_diff > 10 else "üü°" if score_diff > 5 else "üî¥"
                                above_data.append({
                                    'S. No': f"{performer.get('rank_position', 'N/A')}",
                                    'Organization': performer['name'],
                                    'Quality Score': f"{performer['total_score']:.1f}",
                                    'Score Gap': f"{diff_color} +{score_diff:.1f}",
                                    'Country': performer.get('country', 'Unknown'),
                                    'Type': performer.get('hospital_type', 'Hospital')
                                })
                            
                            df_above = pd.DataFrame(above_data)
                            st.dataframe(df_above, use_container_width=True, hide_index=True)
                            
                            # Add visualization chart for performers above
                            if len(performers_above) > 0:
                                st.markdown("**üìä Score Distribution - Performers Above You**")
                                
                                # Create bar chart showing score comparison
                                chart_data = []
                                for performer in performers_above[-10:]:  # Show last 10 for better visualization
                                    chart_data.append({
                                        'Organization': performer['name'][:20] + '...' if len(performer['name']) > 20 else performer['name'],
                                        'Quality Score': performer['total_score'],
                                        'Rank': performer.get('rank_position', 0)
                                    })
                                
                                # Add current organization for comparison
                                chart_data.append({
                                    'Organization': f"{org_name[:15]}... (You)" if len(org_name) > 15 else f"{org_name} (You)",
                                    'Quality Score': score,
                                    'Rank': rankings_data['overall_rank']
                                })
                                
                                df_chart = pd.DataFrame(chart_data)
                                
                                # Create bar chart
                                import plotly.express as px
                                fig = px.bar(df_chart, 
                                           x='Organization', 
                                           y='Quality Score',
                                           title='Quality Score Comparison - Top Performers Above You',
                                           color='Quality Score',
                                           color_continuous_scale='RdYlGn',
                                           text='Quality Score')
                                
                                fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')
                                fig.update_layout(
                                    xaxis_tickangle=-45,
                                    height=400,
                                    showlegend=False,
                                    xaxis_title="Organizations",
                                    yaxis_title="Quality Score"
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # Show improvement insights
                            if performers_above:
                                avg_score_above = sum(p['total_score'] for p in performers_above) / len(performers_above)
                                score_gap = avg_score_above - score
                                st.info(f"üí° **Improvement Opportunity**: Average score of top performers above you is {avg_score_above:.1f}. Bridge the {score_gap:.1f} point gap to move up in rankings.")
                        else:
                            st.success("üèÜ **Congratulations!** You are among the top performers in the database.")
                    
                    with tab2:
                        # Current organization position
                        current_pos = benchmark_data.get('current_position', 0)
                        total_orgs = benchmark_data.get('total_organizations', 0)
                        
                        pos_col1, pos_col2, pos_col3 = st.columns(3)
                        
                        with pos_col1:
                            st.markdown(f"""
                            <div style="background: #1976d220; border: 2px solid #1976d2; border-radius: 10px; padding: 1rem; text-align: center;">
                                <h4 style="color: #1976d2; margin-bottom: 0.5rem;">üè• Your Rank</h4>
                                <div style="font-size: 2em; font-weight: bold; color: #1976d2;">
                                    #{current_pos}
                                </div>
                                <p style="margin: 0; color: #666;">out of {total_orgs}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with pos_col2:
                            percentile = rankings_data.get('percentile', 0)
                            percentile_color = '#28a745' if percentile >= 75 else '#ffc107' if percentile >= 50 else '#fd7e14'
                            st.markdown(f"""
                            <div style="background: {percentile_color}20; border: 2px solid {percentile_color}; border-radius: 10px; padding: 1rem; text-align: center;">
                                <h4 style="color: {percentile_color}; margin-bottom: 0.5rem;">üìä Percentile</h4>
                                <div style="font-size: 2em; font-weight: bold; color: {percentile_color};">
                                    {percentile:.0f}th
                                </div>
                                <p style="margin: 0; color: #666;">percentile</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with pos_col3:
                            st.markdown(f"""
                            <div style="background: #ff980020; border: 2px solid #ff9800; border-radius: 10px; padding: 1rem; text-align: center;">
                                <h4 style="color: #ff9800; margin-bottom: 0.5rem;">üèÜ Your Score</h4>
                                <div style="font-size: 2em; font-weight: bold; color: #ff9800;">
                                    {score:.1f}
                                </div>
                                <p style="margin: 0; color: #666;">quality score</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        # Add ranking position visualization
                        st.markdown("**üìä Your Position in the Rankings**")
                        
                        # Create a ranking position chart
                        performers_above = benchmark_data.get('performers_above', [])
                        performers_below = benchmark_data.get('performers_below', [])
                        
                        # Create data for position visualization
                        position_data = []
                        
                        # Add top 5 performers above (if available)
                        top_above = performers_above[-5:] if len(performers_above) >= 5 else performers_above
                        for performer in top_above:
                            position_data.append({
                                'Organization': performer['name'][:15] + '...' if len(performer['name']) > 15 else performer['name'],
                                'Quality Score': performer['total_score'],
                                'Position': 'Above You',
                                'Color': '#28a745'
                            })
                        
                        # Add current organization
                        position_data.append({
                            'Organization': f"{org_name[:15]}... (You)" if len(org_name) > 15 else f"{org_name} (You)",
                            'Quality Score': score,
                            'Position': 'Your Position',
                            'Color': '#ff9800'
                        })
                        
                        # Add top 5 performers below (if available)
                        top_below = performers_below[:5] if len(performers_below) >= 5 else performers_below
                        for performer in top_below:
                            position_data.append({
                                'Organization': performer['name'][:15] + '...' if len(performer['name']) > 15 else performer['name'],
                                'Quality Score': performer['total_score'],
                                'Position': 'Below You',
                                'Color': '#dc3545'
                            })
                        
                        if position_data:
                            df_position = pd.DataFrame(position_data)
                            
                            # Create horizontal bar chart for better readability
                            import plotly.express as px
                            fig = px.bar(df_position, 
                                       y='Organization', 
                                       x='Quality Score',
                                       title='Your Position Among Top Performers',
                                       color='Position',
                                       color_discrete_map={
                                           'Above You': '#28a745',
                                           'Your Position': '#ff9800',
                                           'Below You': '#dc3545'
                                       },
                                       text='Quality Score',
                                       orientation='h')
                            
                            fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')
                            fig.update_layout(
                                height=400,
                                xaxis_title="Quality Score",
                                yaxis_title="Organizations",
                                legend_title="Position Relative to You"
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                    
                    with tab3:
                        performers_below = benchmark_data.get('performers_below', [])
                        if performers_below:
                            st.markdown(f"**Top {len(performers_below)} performers ranked below you:**")
                            
                            # Create comparison table for performers below
                            below_data = []
                            for performer in performers_below:
                                score_diff = performer.get('score_difference', 0)
                                diff_color = "üî¥" if score_diff < -10 else "üü°" if score_diff < -5 else "üü¢"
                                below_data.append({
                                    'S. No': f"{performer.get('rank_position', 'N/A')}",
                                    'Organization': performer['name'],
                                    'Quality Score': f"{performer['total_score']:.1f}",
                                    'Score Gap': f"{diff_color} {score_diff:.1f}",
                                    'Country': performer.get('country', 'Unknown'),
                                    'Type': performer.get('hospital_type', 'Hospital')
                                })
                            
                            df_below = pd.DataFrame(below_data)
                            st.dataframe(df_below, use_container_width=True, hide_index=True)
                            
                            # Add visualization chart for performers below
                            if len(performers_below) > 0:
                                st.markdown("**üìä Score Distribution - Performers Below You**")
                                
                                # Create bar chart showing score comparison
                                chart_data = []
                                
                                # Add current organization first
                                chart_data.append({
                                    'Organization': f"{org_name[:15]}... (You)" if len(org_name) > 15 else f"{org_name} (You)",
                                    'Quality Score': score,
                                    'Rank': rankings_data['overall_rank']
                                })
                                
                                for performer in performers_below[:10]:  # Show first 10 for better visualization
                                    chart_data.append({
                                        'Organization': performer['name'][:20] + '...' if len(performer['name']) > 20 else performer['name'],
                                        'Quality Score': performer['total_score'],
                                        'Rank': performer.get('rank_position', 0)
                                    })
                                
                                df_chart = pd.DataFrame(chart_data)
                                
                                # Create bar chart
                                import plotly.express as px
                                fig = px.bar(df_chart, 
                                           x='Organization', 
                                           y='Quality Score',
                                           title='Quality Score Comparison - Performers Below You',
                                           color='Quality Score',
                                           color_continuous_scale='RdYlGn',
                                           text='Quality Score')
                                
                                fig.update_traces(texttemplate='%{text:.1f}', textposition='outside')
                                fig.update_layout(
                                    xaxis_tickangle=-45,
                                    height=400,
                                    showlegend=False,
                                    xaxis_title="Organizations",
                                    yaxis_title="Quality Score"
                                )
                                
                                st.plotly_chart(fig, use_container_width=True)
                            
                            # Show competitive advantage
                            if performers_below:
                                avg_score_below = sum(p['total_score'] for p in performers_below) / len(performers_below)
                                score_advantage = score - avg_score_below
                                st.success(f"‚úÖ **Competitive Advantage**: You score {score_advantage:.1f} points higher than the average of performers below you.")
                        else:
                            st.warning("WARNINGÔ∏è You are currently at the bottom of the rankings. Focus on quality improvements to move up.")
                
                else:
                    # Fallback to original top 5 performers display
                    top_performers = rankings_data.get('top_performers', [])
                    if top_performers:
                        st.markdown("*Compare your organization with the top 5 performers in our database*")
                        
                        # Create comparison table
                        comparison_data = []
                        comparison_data.append({
                            'S. No': f"{rankings_data['overall_rank']}",
                            'Organization': f"**{org_name}** (You)",
                            'Quality Score': f"{score:.1f}",
                            'Country': org_data.get('country', 'Unknown'),
                            'Type': org_data.get('hospital_type', 'Hospital')
                        })
                        
                        for i, performer in enumerate(top_performers[:5]):
                            comparison_data.append({
                                'S. No': f"{i+1}",
                                'Organization': performer['name'],
                                'Quality Score': f"{performer['total_score']:.1f}",
                                'Country': performer['country'],
                                'Type': performer['hospital_type']
                            })
                        
                        df_comparison = pd.DataFrame(comparison_data)
                        st.dataframe(df_comparison, use_container_width=True, hide_index=True)
                
                # Regional Ranking
                regional_data = rankings_data.get('regional_ranking')
                if regional_data:
                    st.markdown("#### üåç Regional Performance")
                    
                    reg_col1, reg_col2 = st.columns(2)
                    
                    with reg_col1:
                        regional_color = '#28a745' if regional_data['percentile'] >= 75 else '#ffc107' if regional_data['percentile'] >= 50 else '#fd7e14'
                        st.markdown(f"""
                        <div style="background: {regional_color}20; border: 2px solid {regional_color}; border-radius: 10px; padding: 1rem;">
                            <h5 style="color: {regional_color}; margin-bottom: 1rem;">üåç {regional_data['region']} Region Ranking</h5>
                            <div style="display: flex; justify-content: space-between; align-items: center;">
                                <div>
                                    <div style="font-size: 1.8em; font-weight: bold; color: {regional_color};">
                                        #{regional_data['rank']}
                                    </div>
                                    <p style="margin: 0; color: #666;">out of {regional_data['total_in_region']} in region</p>
                                </div>
                                <div style="text-align: right;">
                                    <div style="font-size: 1.2em; font-weight: bold; color: {regional_color};">
                                        {regional_data['percentile']:.0f}%
                                    </div>
                                    <p style="margin: 0; color: #666; font-size: 0.9em;">percentile</p>
                                </div>
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with reg_col2:
                        st.markdown("**Top Regional Performers:**")
                        for i, top_regional in enumerate(regional_data.get('top_in_region', [])[:3]):
                            medal = ['ü•á', 'ü•à', 'ü•â'][i] if i < 3 else 'üèÜ'
                            st.markdown(f"{medal} **{top_regional['name']}** - {top_regional['total_score']:.1f}")
            
            # Similar Performers
            similar_performers = rankings_data.get('similar_performers', [])
            if similar_performers:
                with st.expander("ü§ù Organizations with Similar Performance", expanded=False):
                    st.markdown("*Organizations within ¬±5 points of your quality score*")
                    
                    for performer in similar_performers[:10]:
                        score_diff = performer['total_score'] - score
                        diff_text = f"+{score_diff:.1f}" if score_diff > 0 else f"{score_diff:.1f}"
                        diff_color = '#28a745' if score_diff <= 0 else '#dc3545'
                        
                        st.markdown(f"""
                        <div style="background: #f8f9fa; padding: 0.8rem; margin: 0.3rem 0; border-radius: 5px; border-left: 3px solid {diff_color};">
                            <strong>{performer['name']}</strong> ({performer['country']}) - 
                            Quality Score: {performer['total_score']:.1f} 
                            <span style="color: {diff_color};">({diff_text} points)</span>
                        </div>
                        """, unsafe_allow_html=True)
            

            # Ranking History Chart
            if 'ranking_history' in st.session_state and org_name in st.session_state.ranking_history:
                ranking_history = st.session_state.ranking_history[org_name]
                if len(ranking_history) > 1:
                    with st.expander("üìà Ranking History & Trends", expanded=False):
                        # Create ranking trend chart
                        dates = [entry['date'] for entry in ranking_history]
                        ranks = [entry['overall_rank'] for entry in ranking_history]
                        percentiles = [entry['percentile'] for entry in ranking_history]
                        
                        fig = go.Figure()
                        
                        # Add ranking line (inverted y-axis since lower rank is better)
                        fig.add_trace(go.Scatter(
                            x=dates,
                            y=ranks,
                            mode='lines+markers',
                            name='Overall Rank',
                            line=dict(color='#1976d2', width=3),
                            marker=dict(size=8),
                            yaxis='y'
                        ))
                        
                        # Add percentile line on secondary y-axis
                        fig.add_trace(go.Scatter(
                            x=dates,
                            y=percentiles,
                            mode='lines+markers',
                            name='Percentile',
                            line=dict(color='#28a745', width=3),
                            marker=dict(size=8),
                            yaxis='y2'
                        ))
                        
                        fig.update_layout(
                            title="Ranking Performance Over Time",
                            xaxis_title="Date",
                            yaxis=dict(
                                title="Overall Rank",
                                side="left",
                                autorange="reversed"  # Lower rank numbers are better
                            ),
                            yaxis2=dict(
                                title="Percentile (%)",
                                side="right",
                                overlaying="y",
                                range=[0, 100]
                            ),
                            height=400,
                            showlegend=True,
                            hovermode='x unified'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Show trend summary
                        trend_data = get_ranking_trend(org_name)
                        if trend_data and isinstance(trend_data, dict) and 'direction' in trend_data and trend_data['direction']:
                            trend_col1, trend_col2, trend_col3 = st.columns(3)
                            
                            with trend_col1:
                                direction = trend_data.get('direction', 'stable')
                                direction_icon = "üìà" if direction == 'up' else "üìâ" if direction == 'down' else "‚û°Ô∏è"
                                direction_color = "#28a745" if direction == 'up' else "#dc3545" if direction == 'down' else "#6c757d"
                                direction_text = direction.title() if direction else 'Stable'
                                st.markdown(f"""
                                <div style="text-align: center; padding: 1rem; background: {direction_color}20; border-radius: 8px;">
                                    <div style="font-size: 2em;">{direction_icon}</div>
                                    <div style="font-weight: bold; color: {direction_color};">Trend Direction</div>
                                    <div style="color: #666;">{direction_text}</div>
                                </div>
                                """, unsafe_allow_html=True)
                            
                            with trend_col2:
                                rank_change = trend_data.get('rank_change', 0)
                                st.markdown(f"""
                                <div style="text-align: center; padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                                    <div style="font-size: 2em;">üîÑ</div>
                                    <div style="font-weight: bold;">Position Change</div>
                                    <div style="color: #666;">¬±{rank_change} positions</div>
                                </div>
                                """, unsafe_allow_html=True)
                            
                            with trend_col3:
                                percentile_change = trend_data.get('percentile_change', 0)
                                percentile_color = "#28a745" if percentile_change > 0 else "#dc3545" if percentile_change < 0 else "#6c757d"
                                percentile_sign = "+" if percentile_change > 0 else ""
                                st.markdown(f"""
                                <div style="text-align: center; padding: 1rem; background: {percentile_color}20; border-radius: 8px;">
                                    <div style="font-size: 2em;">üìä</div>
                                    <div style="font-weight: bold; color: {percentile_color};">Percentile Change</div>
                                    <div style="color: #666;">{percentile_sign}{percentile_change:.1f}%</div>
                                </div>
                                """, unsafe_allow_html=True)
            else:
                st.warning("WARNINGÔ∏è Unable to calculate rankings at this time. Please try again later.")

        elif search_button and not org_name:
            st.warning("WARNINGÔ∏è Please enter an organization name to search.")

        # Display detailed report if requested
        if hasattr(st.session_state, 'detailed_org') and hasattr(st.session_state, 'detailed_data'):
            st.markdown("---")
            st.subheader(f"üìã Detailed Quality Report: {st.session_state.detailed_org}")
            
            org_data = st.session_state.detailed_data
            
            # Comprehensive metrics
            col1, col2, col3, col4 = st.columns(4)
            
            # Column 1 metrics
            score = org_data['total_score']
            score_color = "üü¢" if score >= 80 else "üü°" if score >= 60 else "üî¥"
            col1.metric("üèÜ Overall Score", f"{score:.2f}/100", f"{score_color}")
            
            # Column 2 metrics (avoid context manager to prevent indentation issues)
            active_certs = len([
                c for c in org_data.get('certifications', [])
                if str(c.get('status', '')).strip() == 'Active'
            ])
            col2.metric("üìú Mandatory Requirements", active_certs)
            
            # Column 3 metrics
            premium_certs = len([c for c in org_data['certifications'] if c.get('premium', False)])
            col3.metric("üèÜ Premium Certifications", premium_certs)
            
            # Column 4 metrics
            trend = "Improving" if score >= 70 else "Stable" if score >= 50 else "Needs Attention"
            trend_icon = "‚ÜóÔ∏è" if score >= 70 else "‚û°Ô∏è" if score >= 50 else "‚ÜòÔ∏è"
            col4.metric("üìä Quality Trend", trend, trend_icon)
            
            # Score breakdown
            if org_data.get('score_breakdown') and isinstance(org_data['score_breakdown'], dict):
                st.markdown("### üìä Score Breakdown")
                score_data = org_data['score_breakdown']
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # Certification scores
                    if 'certification_score' in score_data:
                        cert_score = score_data['certification_score']
                        st.progress(cert_score / 100)
                        st.write(f"**Certifications:** {cert_score}/100")
                    
                    # Initiative scores
                    if 'initiative_score' in score_data:
                        init_score = score_data['initiative_score']
                        st.progress(init_score / 100)
                        st.write(f"**Quality Initiatives:** {init_score}/100")
                
                with col2:
                    # Display certifications
                    if org_data['certifications']:
                        st.markdown("**üèÜ Mandatory Requirements:**")
                        for cert in org_data['certifications'][:5]:  # Show top 5
                            if str(cert.get('status', '')).strip() == 'Active':
                                st.write(f"‚Ä¢ {cert['name']} - {cert['issuer']}")
            
            # Clear detailed view button
            if st.button("‚ùå Close Global Healthcare Quality Assessment Report", key="close_detailed"):
                if hasattr(st.session_state, 'detailed_org'):
                    del st.session_state.detailed_org
                if hasattr(st.session_state, 'detailed_data'):
                    del st.session_state.detailed_data
                st.rerun()
        
        st.markdown("---")
        
        st.markdown("""
        ### About Global Healthcare Quality Grid
        The **Global Healthcare Quality Grid** is a comprehensive platform designed to evaluate 
        and score healthcare organizations worldwide based on their quality certifications 
        and accreditations using internationally recognized standards.
        
        ### Key Features:
        - **üîç Organization Search** - Find and analyze any healthcare organization globally
        - **üìä Quality Scoring** - Evidence-based scoring using verified international certifications
        - **üèÜ Certification Tracking** - Monitor JCI, ISO, Joint Commission, CQC, and other global quality certifications
        - **üìà Quality Trends** - Track certification improvements and portfolio development over time
        - **üåç Global Standards** - Assessment based on internationally recognized healthcare quality frameworks
        
        ### Tracked International Certifications:
        - **JCI** üè• - Joint Commission International (Global Gold Standard)
        - **ISO Certifications** - International Organization for Standardization
        - **Joint Commission** - US Healthcare Accreditation Leader
        - **CQC** - Care Quality Commission (UK)
        - **HIMSS** - Healthcare Information and Management Systems Society
        - **AAAHC** - Accreditation Association for Ambulatory Health Care
        - **Regional Standards** - NABH (India), CCHSA (Canada), ACHSI (Australia), and others
        
        ---
        
        ### ‚ö†Ô∏è Important Legal Disclaimers
        
        **Assessment Nature & Limitations:**
        - The Global Healthcare Quality Grid is an **assessment tool based on publicly available knowledge** regarding healthcare organizations
        - **The Global Healthcare Quality Grid can be wrong** in assessing the quality of an organization and should not be considered as definitive or absolute
        - Scores are generated using automated algorithms and may not reflect the complete picture of an organization's quality
        - This platform is intended for **informational and comparative analysis purposes only**
        
        **Data Accuracy & Reliability:**
        - Information is sourced from publicly available databases, websites, and publications
        - Data accuracy depends on the reliability and timeliness of public sources
        - Organizations may have additional certifications or quality initiatives not captured in our database
        - Certification statuses may change without immediate reflection in our system
        
        **No Medical or Professional Advice:**
        - Global Healthcare Quality Grid scores do not constitute medical advice, professional recommendations, or endorsements
        - Users should conduct independent verification and due diligence before making healthcare decisions
        - This tool should not be used as the sole basis for selecting healthcare providers or organizations
        
        **Limitation of Liability:**
        - Global Healthcare Quality Grid and its developers disclaim all warranties, express or implied, regarding the accuracy or completeness of information
        - Users assume full responsibility for any decisions made based on Global Healthcare Quality Grid assessments
        - No liability is accepted for any direct, indirect, or consequential damages arising from the use of this platform
        
        **Intellectual Property & Fair Use:**
        - All data is used under fair use principles for educational and informational purposes
        - Trademark and certification names are property of their respective owners
        - This platform is not affiliated with or endorsed by any certification bodies or healthcare organizations
        
        ---
        
        ### üìß Contact & Organization Registration
        
        **Add Your Organization to Our Database:**
        Contact the Global Healthcare Quality Assessment team at **quxat.team@gmail.com** to add your organization to our quality self-assessment database.
        
        We welcome healthcare organizations worldwide to join our comprehensive quality assessment platform and showcase their certifications and quality initiatives.
        """)
        
        # Quality Dashboard Section - Consolidated from Quality Dashboard page
        st.markdown("---")
        st.header("üìä Quality Dashboard & Analytics")
        
        # Sample quality trend data
        dates = pd.date_range('2024-01-01', periods=30, freq='D')
        quality_scores = np.random.normal(82, 8, 30)
        trend_data = pd.DataFrame({'Date': dates, 'Average Quality Score': quality_scores})
        
        st.subheader("üìà Global Healthcare Quality Trends")
        fig = px.line(trend_data, x='Date', y='Average Quality Score', 
                      title="30-Day Healthcare Quality Score Trend")
        st.plotly_chart(fig, use_container_width=True)
        
        # Regional analysis
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üåç Regional Quality Analysis")
            regions = ['North America', 'Europe', 'Asia-Pacific', 'Middle East', 'Latin America']
            avg_scores = [88, 85, 79, 76, 73]
            
            fig = px.bar(x=regions, y=avg_scores, title="Average Quality Scores by Region")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.subheader("üìä Key Metrics")
            # Use the same unified dynamic count here for consistency
            try:
                _total_ranked_orgs = len(getattr(analyzer, 'scored_entries', []) or [])
            except Exception:
                _total_ranked_orgs = 0
            _total_ranked_orgs_fmt = f"{_total_ranked_orgs:,}"
            st.metric("üè• Total Organizations", _total_ranked_orgs_fmt)
            st.metric("üìä Average Score", "81.2")
            st.metric("üèÜ Top Performers (90+)", "156")
            st.metric("WARNINGÔ∏è Need Improvement (<60)", "89")

        # Global Healthcare Quality Section - Consolidated from Global Healthcare Quality page
        st.markdown("---")
        st.header("üåç Global Healthcare Quality Distribution")
        st.markdown("Interactive world map showing healthcare quality scores across different countries and regions with advanced filtering and analysis capabilities.")
        
        # Global Healthcare Quality Distribution Chart and Metrics (moved from home page)
        st.subheader("üìä Healthcare Organizations by Quality Score Range")
        
        # Generate sample data
        quality_ranges = ['75-85 (A+)', '65-74 (A)', '55-64 (B+)', '45-54 (B)', 'Below 45 (C)']
        organization_counts = [150, 320, 280, 180, 70]
        colors = ['#2E8B57', '#32CD32', '#FFD700', '#FFA500', '#FF6347']
        
        fig = px.bar(x=quality_ranges, y=organization_counts, 
                     title="Healthcare Organizations by Quality Score Range",
                     color=quality_ranges, color_discrete_sequence=colors)
        fig.update_layout(showlegend=False, xaxis_title="Quality Score Range", yaxis_title="Number of Organizations")
        st.plotly_chart(fig, use_container_width=True)
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            # Prefer unified database size if available, fallback to ranked
            try:
                _total_tracked_orgs = len(getattr(analyzer, 'unified_database', []) or [])
                if not _total_tracked_orgs:
                    _total_tracked_orgs = len(getattr(analyzer, 'scored_entries', []) or [])
            except Exception:
                _total_tracked_orgs = len(getattr(analyzer, 'scored_entries', []) or [])
            _total_tracked_orgs_fmt = f"{_total_tracked_orgs:,}"
            st.metric("üè• Organizations Tracked", _total_tracked_orgs_fmt)
        with col2:
            st.metric("üåç Countries Covered", "50+")
        with col3:
            st.metric("üìä Average Quality Score", "78.5")
        with col4:
            st.metric("üèÜ Top Performers", "150")
        
        st.divider()  # Visual separator between sections
        
        # Enhanced map customization options
        st.subheader("üéõÔ∏è Map Controls & Filters")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            color_scale = st.selectbox(
                "üé® Color Scale",
                ["RdYlGn", "Viridis", "Plasma", "Blues", "Reds", "RdBu", "Turbo", "Rainbow"],
                index=0,
                help="Choose color scheme for the map visualization"
            )
        
        with col2:
            projection = st.selectbox(
                "üó∫Ô∏è Map Projection",
                ["natural earth", "orthographic", "mercator", "robinson", "kavrayskiy7", "mollweide", "eckert4"],
                index=0,
                help="Select map projection style"
            )
        
        with col3:
            show_text = st.checkbox("üìù Show Country Codes", value=False, help="Display ISO country codes on map")
        
        with col4:
            map_height = st.slider("üìè Map Height", 400, 800, 600, 50, help="Adjust map display height")
        
        # Advanced filtering options
        st.markdown("### üîç Advanced Filters")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            score_range = st.slider(
                "Quality Score Range",
                min_value=0,
                max_value=100,
                value=(0, 100),
                help="Filter countries by quality score range"
            )
        
        with col2:
            hospital_filter = st.slider(
                "Minimum Top Hospitals",
                min_value=0,
                max_value=50,
                value=0,
                help="Show countries with at least this many top-tier hospitals"
            )
        
        with col3:
            region_filter = st.multiselect(
                "Select Regions",
                ["North America", "Europe", "Asia-Pacific", "Middle East & Africa", "Latin America", "Eastern Europe"],
                default=["North America", "Europe", "Asia-Pacific", "Middle East & Africa", "Latin America", "Eastern Europe"],
                help="Filter by geographic regions"
            )
        
        # Enhanced global healthcare quality data with more comprehensive metrics
        countries_data = {
            'Country': [
                'United States', 'Germany', 'Switzerland', 'Japan', 'Singapore', 'Canada', 'Australia', 
                'United Kingdom', 'France', 'Netherlands', 'Sweden', 'Norway', 'Denmark', 'Finland',
                'South Korea', 'Israel', 'Austria', 'Belgium', 'Italy', 'Spain', 'New Zealand',
                'China', 'India', 'Brazil', 'Russia', 'Mexico', 'Turkey', 'Thailand', 'Malaysia',
                'South Africa', 'Egypt', 'Argentina', 'Chile', 'Poland', 'Czech Republic', 'Hungary',
                'Portugal', 'Greece', 'Ireland', 'Luxembourg', 'Iceland', 'Estonia', 'Latvia', 'Lithuania',
                'UAE', 'Saudi Arabia', 'Qatar', 'Kuwait', 'Bahrain', 'Oman', 'Jordan', 'Lebanon',
                'Morocco', 'Tunisia', 'Algeria', 'Nigeria', 'Kenya', 'Ghana', 'Ethiopia', 'Tanzania',
                'Uganda', 'Rwanda', 'Botswana', 'Namibia', 'Zambia', 'Zimbabwe', 'Mauritius', 'Seychelles'
            ],
            'ISO_Code': [
                'USA', 'DEU', 'CHE', 'JPN', 'SGP', 'CAN', 'AUS', 'GBR', 'FRA', 'NLD', 'SWE', 'NOR', 
                'DNK', 'FIN', 'KOR', 'ISR', 'AUT', 'BEL', 'ITA', 'ESP', 'NZL', 'CHN', 'IND', 'BRA', 
                'RUS', 'MEX', 'TUR', 'THA', 'MYS', 'ZAF', 'EGY', 'ARG', 'CHL', 'POL', 'CZE', 'HUN',
                'PRT', 'GRC', 'IRL', 'LUX', 'ISL', 'EST', 'LVA', 'LTU', 'ARE', 'SAU', 'QAT', 'KWT',
                'BHR', 'OMN', 'JOR', 'LBN', 'MAR', 'TUN', 'DZA', 'NGA', 'KEN', 'GHA', 'ETH', 'TZA',
                'UGA', 'RWA', 'BWA', 'NAM', 'ZMB', 'ZWE', 'MUS', 'SYC'
            ],
            'Quality_Score': [
                92, 89, 94, 88, 91, 87, 86, 85, 84, 87, 88, 90, 89, 87, 85, 83, 86, 84, 82, 81, 85,
                78, 72, 75, 70, 73, 74, 76, 77, 69, 65, 74, 78, 79, 80, 78, 81, 79, 86, 88, 89, 82, 81, 80,
                82, 79, 85, 81, 83, 78, 76, 74, 71, 73, 68, 64, 67, 69, 63, 66, 68, 72, 75, 73, 70, 67, 79, 84
            ],
            'Healthcare_Rank': [
                1, 4, 2, 6, 3, 8, 9, 10, 11, 7, 5, 4, 4, 8, 10, 12, 9, 11, 13, 14, 9,
                25, 35, 28, 40, 32, 30, 26, 24, 42, 48, 29, 25, 22, 21, 23, 18, 20, 7, 6, 5, 19, 20, 21,
                15, 27, 12, 17, 14, 31, 33, 36, 45, 38, 52, 58, 49, 44, 61, 55, 50, 41, 37, 39, 43, 54, 16, 13
            ],
            'Top_Hospitals': [
                15, 8, 6, 7, 4, 6, 5, 9, 7, 4, 3, 2, 2, 2, 4, 3, 3, 2, 4, 3, 2,
                12, 8, 4, 3, 2, 3, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,
                3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
            ],
            'Population_Millions': [
                331, 83, 8.7, 125, 5.9, 38, 25, 67, 68, 17, 10, 5.4, 5.8, 5.5, 52, 9.4, 9, 11.5, 60, 47, 5.1,
                1439, 1380, 215, 146, 129, 84, 70, 33, 60, 104, 45, 19, 38, 10.7, 9.7, 10.3, 10.7, 5, 0.6, 0.37, 1.3, 1.9, 2.8,
                9.9, 35, 2.9, 4.3, 1.7, 5.1, 10.2, 6.8, 37, 12, 44, 218, 54, 32, 117, 60, 47, 13, 2.6, 2.5, 18, 15, 1.3, 0.1
            ],
            'GDP_Per_Capita': [
                63543, 46259, 81867, 39285, 59797, 46327, 51812, 42330, 38625, 52331, 51648, 75420, 60170, 48810, 31846, 43592, 47291, 46421, 31953, 27057, 42084,
                10500, 1900, 8717, 11289, 9673, 9127, 7189, 11373, 6001, 3019, 9912, 13231, 13823, 23111, 15731, 23252, 17676, 78785, 115874, 68384, 19847, 17861, 19158,
                43103, 23139, 62088, 29301, 23504, 15343, 4405, 8017, 3204, 3447, 2207, 2097, 1838, 2328, 854, 1141, 1155, 4315, 7715, 4448, 1539, 1464, 11208, 16426
            ]
        }
        
        df_countries = pd.DataFrame(countries_data)
        
        # Apply filters
        filtered_df = df_countries[
            (df_countries['Quality_Score'] >= score_range[0]) & 
            (df_countries['Quality_Score'] <= score_range[1]) &
            (df_countries['Top_Hospitals'] >= hospital_filter)
        ]
        
        # Regional filtering
        region_mapping = {
            'North America': ['USA', 'CAN', 'MEX'],
            'Europe': ['DEU', 'CHE', 'GBR', 'FRA', 'NLD', 'SWE', 'NOR', 'DNK', 'FIN', 'AUT', 'BEL', 'ITA', 'ESP', 'PRT', 'GRC', 'IRL', 'LUX', 'ISL', 'EST', 'LVA', 'LTU', 'POL', 'CZE', 'HUN'],
            'Asia-Pacific': ['JPN', 'SGP', 'AUS', 'KOR', 'CHN', 'IND', 'THA', 'MYS', 'NZL'],
            'Middle East & Africa': ['ISR', 'ZAF', 'EGY', 'ARE', 'SAU', 'QAT', 'KWT', 'BHR', 'OMN', 'JOR', 'LBN', 'MAR', 'TUN', 'DZA', 'NGA', 'KEN', 'GHA', 'ETH', 'TZA', 'UGA', 'RWA', 'BWA', 'NAM', 'ZMB', 'ZWE', 'MUS', 'SYC'],
            'Latin America': ['BRA', 'ARG', 'CHL'],
            'Eastern Europe': ['RUS', 'TUR']
        }
        
        # Filter by selected regions
        selected_countries = []
        for region in region_filter:
            if region in region_mapping:
                selected_countries.extend(region_mapping[region])
        
        if selected_countries:
            filtered_df = filtered_df[filtered_df['ISO_Code'].isin(selected_countries)]
        
        # Create the world map using Plotly Express
        st.subheader("üó∫Ô∏è Interactive World Healthcare Quality Map")
        
        # Display filter results
        st.info(f"üìä Showing {len(filtered_df)} countries based on your filters")
        
        # Enhanced choropleth map with better styling
        fig = px.choropleth(
            filtered_df,
            locations='ISO_Code',
            color='Quality_Score',
            hover_name='Country',
            hover_data={
                'Quality_Score': ':,.0f',
                'Healthcare_Rank': ':,.0f',
                'Top_Hospitals': ':,.0f',
                'Population_Millions': ':,.1f',
                'GDP_Per_Capita': ':,.0f',
                'ISO_Code': False
            },
            color_continuous_scale=color_scale,
            range_color=[score_range[0], score_range[1]],
            title=f"Global Healthcare Quality Distribution (Quality Score: {score_range[0]}-{score_range[1]})",
            labels={
                'Quality_Score': 'Quality Score',
                'Population_Millions': 'Population (M)',
                'GDP_Per_Capita': 'GDP per Capita ($)'
            }
        )
        
        # Enhanced layout with better styling
        fig.update_layout(
            geo=dict(
                showframe=False,
                showcoastlines=True,
                coastlinecolor="RebeccaPurple",
                projection_type=projection,
                bgcolor='rgba(0,0,0,0)',
                showland=True,
                landcolor='rgb(243, 243, 243)',
                showocean=True,
                oceancolor='rgb(204, 229, 255)'
            ),
            title_x=0.5,
            title_font_size=16,
            width=1200,
            height=map_height,
            font=dict(size=12),
            coloraxis_colorbar=dict(
                title="Quality Score",
                thickness=15,
                len=0.7,
                x=1.02
            )
        )
        
        if show_text:
            fig.update_traces(
                text=filtered_df['ISO_Code'],
                textposition="middle center",
                textfont_size=8,
                textfont_color="white"
            )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Display key statistics
        st.markdown("### üìä Global Healthcare Quality Statistics")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            avg_score = filtered_df['Quality_Score'].mean()
            st.metric(
                "Global Average Score", 
                f"{avg_score:.2f}",
                delta=f"{avg_score - 75:.2f} vs baseline"
            )
        
        with col2:
            top_country = filtered_df.loc[filtered_df['Quality_Score'].idxmax()]
            st.metric(
                "Top Performer", 
                top_country['Country'],
                delta=f"{top_country['Quality_Score']:.0f} points"
            )
        
        with col3:
            high_quality = len(filtered_df[filtered_df['Quality_Score'] >= 85])
            st.metric(
                "High Quality Countries", 
                high_quality,
                delta=f"{(high_quality/len(filtered_df)*100):.0f}% of total"
            )
        
        with col4:
            total_hospitals = filtered_df['Top_Hospitals'].sum()
            st.metric(
                "Total Top-Tier Hospitals", 
                f"{total_hospitals:,}",
                delta="Across all regions"
            )
        
        # Regional Analysis
        st.markdown("### üåç Regional Healthcare Quality Analysis")
        
        # Create regional breakdown
        regions = {
            'North America': ['United States', 'Canada'],
            'Europe': ['Germany', 'United Kingdom', 'France', 'Switzerland', 'Netherlands', 'Sweden', 'Denmark', 'Norway'],
            'Asia-Pacific': ['Singapore', 'Japan', 'Australia', 'South Korea', 'New Zealand'],
            'Middle East': ['Israel', 'UAE'],
            'Others': ['Brazil', 'South Africa']
        }
        
        regional_data = []
        for region, countries in regions.items():
            region_df = filtered_df[filtered_df['Country'].isin(countries)]
            if not region_df.empty:
                regional_data.append({
                    'Region': region,
                    'Countries': len(region_df),
                    'Avg_Score': region_df['Quality_Score'].mean(),
                    'Top_Hospitals': region_df['Top_Hospitals'].sum(),
                    'Avg_GDP': region_df['GDP_Per_Capita'].mean()
                })
        
        if regional_data:
            regional_df = pd.DataFrame(regional_data)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Regional quality scores bar chart
                fig_bar = px.bar(
                    regional_df, 
                    x='Region', 
                    y='Avg_Score',
                    title="Average Quality Score by Region",
                    color='Avg_Score',
                    color_continuous_scale='Viridis',
                    text='Avg_Score'
                )
                fig_bar.update_traces(texttemplate='%{text:.1f}', textposition='outside')
                fig_bar.update_layout(height=400, showlegend=False)
                st.plotly_chart(fig_bar, use_container_width=True)
            
            with col2:
                # Regional hospital distribution pie chart
                fig_pie = px.pie(
                    regional_df, 
                    values='Top_Hospitals', 
                    names='Region',
                    title="Distribution of Top-Tier Hospitals by Region"
                )
                fig_pie.update_layout(height=400)
                st.plotly_chart(fig_pie, use_container_width=True)
        
        # Quality Score Distribution Analysis
        st.markdown("### üìà Quality Score Distribution Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üèÜ Top 5 Performers:**")
            top_5 = filtered_df.nlargest(5, 'Quality_Score')[['Country', 'Quality_Score', 'Top_Hospitals']]
            for idx, row in top_5.iterrows():
                st.write(f"**{row['Country']}** - {row['Quality_Score']:.0f} points ({row['Top_Hospitals']} hospitals)")
        
        with col2:
            st.markdown("**üìä Score Range Distribution:**")
            score_ranges = [
                ('75-85 (A+)', len(filtered_df[filtered_df['Quality_Score'] >= 75])),
                ('65-74 (A)', len(filtered_df[(filtered_df['Quality_Score'] >= 65) & (filtered_df['Quality_Score'] < 75)])),
                ('55-64 (B+)', len(filtered_df[(filtered_df['Quality_Score'] >= 55) & (filtered_df['Quality_Score'] < 65)])),
                ('45-54 (B)', len(filtered_df[(filtered_df['Quality_Score'] >= 45) & (filtered_df['Quality_Score'] < 55)])),
                ('Below 45 (C)', len(filtered_df[filtered_df['Quality_Score'] < 45]))
            ]
            
            for range_name, count in score_ranges:
                percentage = (count / len(filtered_df) * 100) if len(filtered_df) > 0 else 0
                st.write(f"**{range_name}:** {count} countries ({percentage:.1f}%)")
        
        # Methodology and Data Sources
        st.markdown("---")
        st.markdown("### üìã Methodology & Data Sources")
        
        with st.expander("üîç View Detailed Methodology", expanded=False):
            st.markdown("""
            **Quality Score Calculation:**
            - **Quality Certifications & Accreditations (100%):** Evidence-based scoring using only verified certifications
            - **Premium Certifications:** JCI (+15 pts), NABH (+10 pts), CAP (+8 pts), ISO Standards (+3 pts each)
            - **NABL Accreditation:** Testing and calibration laboratory standards (+5 pts)
            - **Certification Status:** Active certifications (100% weight), In-Progress (50% weight)

            **Data Sources:**
            - Official certification body databases (ISO, JCI, NABH, CAP, NABL, etc.)
            - International accreditation organizations
            - Government healthcare regulatory databases
            - Verified certification registries
            - Official organization certification disclosures

            **WARNINGÔ∏è Data Accuracy Disclaimers:**
            - **Evidence-Based Assessment:** This scoring system relies exclusively on verified certification and accreditation evidence
            - **Certification Verification:** Scores are based on publicly available certification databases and official disclosures
            - **Data Completeness:** Organizations may have additional certifications not captured in our database
            - **Comparative Purpose Only:** Use these scores for comparative analysis and research, not for absolute quality determination
            - **Assessment Limitations:** Certification-based scores may be incorrect or incomplete due to data availability constraints
            """)

        # Footer with Contact Information
        st.markdown("---")
        st.markdown("""
        <div style="
            background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
            padding: 2rem;
            border-radius: 15px;
            text-align: center;
            margin: 2rem 0;
            border: 1px solid #dee2e6;
        ">
            <h4 style="color: #495057; margin-bottom: 1rem; font-weight: 600;">
                üìß Add Your Organization to Our Database
            </h4>
            <p style="color: #6c757d; font-size: 1rem; margin-bottom: 0; line-height: 1.6;">
                Contact the Global Healthcare Quality Assessment team at 
                <a href="mailto:quxat.team@gmail.com" style="color: #007bff; text-decoration: none; font-weight: 600;">
                    quxat.team@gmail.com
                </a> 
                to add your organization to our quality self-assessment database.
            </p>
        </div>
        """, unsafe_allow_html=True)

    except Exception as e:
        # Log error silently without displaying to user
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    # Streamlit applications don't need a main function
    # The app runs automatically when executed
    pass
